<?xml version="1.0" encoding="UTF-8" ?>
<ChoregrapheProject xmlns="http://www.aldebaran-robotics.com/schema/choregraphe/project.xsd" xar_version="3">
    <Box name="root" id="-1" localization="8" tooltip="Root box of Choregraphe&apos;s behavior. Highest level possible." x="0" y="0">
        <bitmap>media/images/box/root.png</bitmap>
        <script language="4">
            <content>
                <![CDATA[]]>
</content>
        </script>
        <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
        <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
        <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
        <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
        <Timeline enable="0">
            <BehaviorLayer name="behavior_layer1">
                <BehaviorKeyframe name="keyframe1" index="1">
                    <Diagram scale="84.0896">
                        <Box name="Listen for user" id="6" localization="-1" tooltip="Nao is listening for user" x="406" y="381">
                            <bitmap>media/images/box/interaction/target_sound.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.tracker = ALProxy( "ALTracker" )
        self.memory = ALProxy("ALMemory")
        try:
            self.soundLocation = ALProxy("ALSoundLocalization")
        except Exception as e:
            self.soundLocation = None
            self.logger.error(e)
        self.targetName = "Sound"
        self.distance = 0.0
        self.soundDistance = 0.5
        self.confidence = 0.0
        self.thresholdX = 0.0
        self.effector = "None"
        self.sensitivity = 0.7
        self.subscribeDone = False
        self.isRunning = False

    def onLoad(self):
        self.BIND_PYTHON(self.getName(), "setParameter")
        self.BIND_PYTHON(self.getName(), "onTargetLost")
        self.BIND_PYTHON(self.getName(), "onTargetReached")
        self.BIND_PYTHON(self.getName(), "onTargetChanged")
        if self.soundLocation:
            self.memory.subscribeToEvent("ALTracker/ActiveTargetChanged", self.getName(), "onTargetChanged")

    def onUnload(self):
        if self.subscribeDone:
            self.memory.unsubscribeToEvent("ALTracker/TargetLost", self.getName())
            self.memory.unsubscribeToEvent("ALTracker/TargetReached", self.getName())
            self.subscribeDone = False

        if self.isRunning:
            self.tracker.setEffector("None")
            self.tracker.stopTracker()
            self.tracker.unregisterTarget(self.targetName)
            self.isRunning = False

    def onInput_onStart(self):
        self.memory.subscribeToEvent("ALTracker/TargetLost", self.getName(), "onTargetLost")
        self.memory.subscribeToEvent("ALTracker/TargetReached", self.getName(), "onTargetReached")
        self.subscribeDone = False

        mode = self.getParameter("Mode")
        self.confidence = self.getParameter("Threshold to be sure of the location (%)") / 100.0
        self.distance = self.getParameter("Distance (m)")
        self.thresholdX = self.getParameter("Threshold X (m)")
        self.effector = self.getParameter("Effector")
        self.sensitivity = self.getParameter("Sensitivity")

        if self.soundLocation:
            self.soundLocation.setParameter("Sensitivity", self.sensitivity)

        self.tracker.setEffector(self.effector)

        self.tracker.registerTarget(self.targetName, [self.soundDistance, self.confidence])
        self.tracker.setRelativePosition([-self.distance, 0.0, 0.0,
                                            self.thresholdX, 0.1, 0.3])
        self.tracker.setMode(mode)

        self.tracker.track(self.targetName) #Start tracker
        self.isRunning = True

    def onInput_onStop(self):
        self.onStopped()
        self.onUnload()

    def setParameter(self, parameterName, newValue):
        GeneratedClass.setParameter(self, parameterName, newValue)
        if (parameterName == 'Mode'):
            self.tracker.setMode(newValue)
            return

        if (parameterName == "Threshold to be sure of the location (%)"):
            self.confidence = self.getParameter("Threshold to be sure of the location (%)") / 100.0
            self.tracker.registerTarget(self.targetName, [self.soundDistance, self.confidence])
            return

        if (parameterName == "Distance (m)"):
            self.distance = newValue
            self.tracker.setRelativePosition([-self.distance, 0.0, 0.0,
                                                self.thresholdX, 0.1, 0.3])
            return

        if (parameterName == "Threshold X (m)"):
            self.thresholdX = newValue
            self.tracker.setRelativePosition([-self.distance, 0.0, 0.0,
                                                self.thresholdX, 0.1, 0.3])
            return

        if(parameterName == "Effector"):
            self.tracker.setEffector(newValue)
            self.effector = newValue
            return

        if(parameterName == "Sensitivity"):
            self.sensitivity = newValue
            if self.soundLocation:
                self.soundLocation.setParameter("Sensitivity", self.sensitivity)
            return


    def onTargetLost(self, key, value, message):
        self.targetLost()

    def onTargetReached(self, key, value, message):
        self.targetReached()

    def onTargetChanged(self, key, value, message):
        if value == self.targetName and not self.subscribeDone:
            self.memory.subscribeToEvent("ALTracker/TargetLost", self.getName(), "onTargetLost")
            self.memory.subscribeToEvent("ALTracker/TargetReached", self.getName(), "onTargetReached")
            self.subscribeDone = True
        elif value != self.targetName and self.subscribeDone:
            self.memory.unsubscribeToEvent("ALTracker/TargetLost", self.getName())
            self.memory.unsubscribeToEvent("ALTracker/TargetReached", self.getName())
            self.subscribeDone = False]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
                            <Output name="targetLost" type="1" type_size="1" nature="2" inner="0" tooltip="Signal sent when the target is lost." id="5" />
                            <Output name="targetReached" type="1" type_size="1" nature="2" inner="0" tooltip="Signal sent when the target is reached." id="6" />
                            <Parameter name="Mode" inherits_from_parent="0" content_type="3" value="WholeBody" default_value="Head" custom_choice="0" tooltip="Set tracker mode" id="7">
                                <Choice value="Head" />
                                <Choice value="WholeBody" />
                                <Choice value="Move" />
                            </Parameter>
                            <Parameter name="Effector" inherits_from_parent="0" content_type="3" value="None" default_value="None" custom_choice="0" tooltip="Set effector to use for tracking. Head is always used." id="8">
                                <Choice value="None" />
                                <Choice value="Arms" />
                                <Choice value="LArm" />
                                <Choice value="RArm" />
                            </Parameter>
                            <Parameter name="Threshold to be sure of the location (%)" inherits_from_parent="0" content_type="1" value="50" default_value="50" min="1" max="100" tooltip="If a sound is localized with a threshold higher than this value, then the sound&#x0A;location will be sent on the output. Else, the robot will consider that the sound is not&#x0A;localized at the right location and he will not take it into account." id="9" />
                            <Parameter name="Distance (m)" inherits_from_parent="0" content_type="2" value="0.3" default_value="0.3" min="0.01" max="5" tooltip="Distance the robot will try to maintain from its target in move modes." id="10" />
                            <Parameter name="Threshold X (m)" inherits_from_parent="0" content_type="2" value="0.1" default_value="0.1" min="0.01" max="1" tooltip="Threshold above which the robot will move to track its target in move modes." id="11" />
                            <Parameter name="Sensitivity" inherits_from_parent="0" content_type="2" value="0.7" default_value="0.7" min="0.01" max="1" tooltip="Sensitivity to adjust the capacity of the robot to locate quiet sounds." id="12" />
                        </Box>
                        <Box name="Look at sound" id="9" localization="-1" tooltip="Nao looks at sound it has heard " x="284" y="37">
                            <bitmap>media/images/box/movement/move_head.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.tracker = ALProxy( "ALTracker" )

        self.x = 0.0
        self.y = 0.0
        self.z = 0.0

        self.maxSpeed = 0.5

        self.useWholeBody = False
        self.frame = 0 #FRAME TORSO

    def onLoad(self):
        self.BIND_PYTHON(self.getName(), "setParameter")

    def onUnload(self):
        pass

    def onInput_onStart(self):
        self.x = self.getParameter("X (m)")
        self.y = self.getParameter("Y (m)")
        self.z = self.getParameter("Z (m)")

        self.maxSpeed = self.getParameter("Speed (%)") / 100.0
        self.useWholeBody = self.getParameter("WholeBody")

        frameStr = self.getParameter("Frame")
        if frameStr == "Torso":
            self.frame = 0
        elif frameStr == "World":
            self.frame = 1
        elif frameStr == "Robot":
            self.frame = 2

        self.tracker.lookAt([self.x, self.y, self.z], self.frame, self.maxSpeed, self.useWholeBody)
        self.onStopped()

    def onInput_onStop(self):
        self.onUnload()
        pass

    def setParameter(self, parameterName, newValue):
        GeneratedClass.setParameter(self, parameterName, newValue)

        if (parameterName == "X (m)"):
            self.x = newValue
            self.tracker.lookAt([self.x, self.y, self.z], self.frame, self.maxSpeed, self.useWholeBody)
            self.onStopped()
            return

        if (parameterName == "Y (m)"):
            self.y = newValue
            self.tracker.lookAt([self.x, self.y, self.z], self.frame, self.maxSpeed, self.useWholeBody)
            self.onStopped()
            return

        if (parameterName == "Z (m)"):
            self.z = newValue
            self.tracker.lookAt([self.x, self.y, self.z], self.frame, self.maxSpeed, self.useWholeBody)
            self.onStopped()
            return

        if (parameterName == "Speed (%)"):
            self.maxSpeed = newValue / 100.0
            return

        if (parameterName == "WholeBody"):
            self.useWholeBody = newValue
            return

        if (parameterName == "Frame"):
            if(newValue == "Torso"):
                self.frame = 0
            elif newValue == "World":
                self.frame = 1
            elif newValue == "Robot":
                self.frame = 2]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
                            <Parameter name="X (m)" inherits_from_parent="0" content_type="2" value="1" default_value="1" min="0.001" max="10" tooltip="X coordinate of the target to look at." id="5" />
                            <Parameter name="Y (m)" inherits_from_parent="0" content_type="2" value="0" default_value="0" min="-10" max="10" tooltip="Y coordinate of the target to look at." id="6" />
                            <Parameter name="Z (m)" inherits_from_parent="0" content_type="2" value="0" default_value="0" min="-10" max="10" tooltip="Z coordinate of the target to look at." id="7" />
                            <Parameter name="Speed (%)" inherits_from_parent="0" content_type="1" value="50" default_value="50" min="1" max="100" tooltip="Speed to move the head towards the desired position." id="8" />
                            <Parameter name="WholeBody" inherits_from_parent="0" content_type="0" value="0" default_value="0" tooltip="Use whole body constraints" id="9" />
                            <Parameter name="Frame" inherits_from_parent="0" content_type="3" value="Torso" default_value="Torso" custom_choice="0" tooltip="Select the frame of target." id="10">
                                <Choice value="Torso" />
                                <Choice value="World" />
                                <Choice value="Robot" />
                            </Parameter>
                        </Box>
                        <Box name="Go to position Stand" id="2" localization="8" tooltip="Robot will go to the position Stand&lt;br/&gt;Position description : Standing position with low power consumption. " x="632" y="47">
                            <bitmap>media/images/positions/Stand.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[#~ This script was generated automatically by drang&drop from Position Library
class MyClass(GeneratedClass):
    def __init__(self):
        try: # disable autoBind
          GeneratedClass.__init__(self, False)
        except TypeError: # if NAOqi < 1.14
          GeneratedClass.__init__( self )

    def onLoad(self):
        self.postureProxy = None
        try:
            self.postureProxy = ALProxy("ALRobotPosture")
        except:
            self.logger.error("Module 'ALRobotPosture' not found.")

    def onUnload(self):
        if(self.postureProxy != None):
            self.postureProxy.stopMove()

    def onInput_onStart(self):
        if(self.postureProxy != None):
            result = self.postureProxy.goToPosture("Stand", 0.8)
            if(result):
                self.success()
            else:
                self.logger.error("Posture Stand is not a part of the standard posture library or robot cannot reach the posture")
                self.failure()
        else:
            self.failure()

    def onInput_onStop(self):
        self.onUnload() #~ it is recommanded to call onUnload of this box in a onStop method,               as the code written in onUnload is used to stop the box as well
        pass]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Output name="success" type="1" type_size="1" nature="1" inner="0" tooltip="Stimulated if the posture has been reached." id="4" />
                            <Output name="failure" type="1" type_size="1" nature="1" inner="0" tooltip="Stimulated if the posture could not be reached." id="5" />
                            <Resource name="All motors" type="Lock" timeout="0" />
                            <Resource name="Stiffness" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Begin greeting" id="3" localization="8" tooltip="Nao introduces itself and greets user " x="788" y="14">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean." id="6" />
                            <Parameter name="Body language mode" inherits_from_parent="0" content_type="3" value="contextual" default_value="contextual" custom_choice="0" tooltip="Change the body language mode during the speech.&#x0A;disabled: The robot will only play the animations given by the user. ex: ^start(...) or ^tag(...)&#x0A;random: During time the robot has no animation to play, he will launch random neutral animations.&#x0A;contextual: During time the robot has no animation to play, he will try to launch a new one accordingly to the saying text. Every time the robot can&apos;t find a contextual animation he will launch a random neutral animation." id="7">
                                <Choice value="disabled" />
                                <Choice value="random" />
                                <Choice value="contextual" />
                            </Parameter>
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Animated Say Text" id="2" localization="8" tooltip="Say the text received on its input and move during its speech." x="422" y="65">
                                                <bitmap>media/images/box/interaction/say.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.animSpeech = ALProxy('ALAnimatedSpeech')

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.animSpeech.stop(id)
            except:
                pass

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            configuration =\
            {"bodyLanguageMode":self.getParameter("Body language mode")}
            id = self.animSpeech.post.say(str(sentence), configuration)
            self.ids.append(id)
            self.animSpeech.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                                                <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                                                <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                                                <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                                                <Parameter name="Body language mode" inherits_from_parent="1" content_type="3" value="contextual" default_value="contextual" custom_choice="0" tooltip="Change the body language mode during the speech.&#x0A;disabled: The robot will only play the animations given by the user. ex: ^start(...) or ^tag(...)&#x0A;random: During time the robot has no animation to play, he will launch random neutral animations.&#x0A;contextual: During time the robot has no animation to play, he will try to launch a new one accordingly to the saying text. Every time the robot can&apos;t find a contextual animation he will launch a random neutral animation." id="7">
                                                    <Choice value="disabled" />
                                                    <Choice value="random" />
                                                    <Choice value="contextual" />
                                                </Parameter>
                                            </Box>
                                            <Box name="Localized Text" id="5" localization="8" tooltip="Send on the output the text associated with the robot&apos;s current voice language.&#x0A;You can display and edit the text associated with any language by&#x0A;selecting the language in the combobox.&#x0A;&#x0A;!!Warning!! The text sent on the output is NOT the displayed one but the one&#x0A;associated with the robot&apos;s current voice language." plugin="localizationbox_plugin" x="72" y="56">
                                                <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		try: # disable autoBind
			GeneratedClass.__init__(self, False)
		except TypeError: # if NAOqi < 1.14
			GeneratedClass.__init__( self )

		self.tts = ALProxy("ALTextToSpeech")
		self.sentences = {
			"Arabic" : "  ",
			"Czech" : " ^start(animations/Stand/Gestures/Hey_1) Ahoj ^wait(animations/Stand/Gestures/Hey_1) ",
			"Danish" : " ^start(animations/Stand/Gestures/Hey_1) Hej ^wait(animations/Stand/Gestures/Hey_1) ",
			"German" : " ^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1) ",
			"Greek" : "  ",
			"English" : " Hello I am Nao V5. elcome ot the best place for a massage in all of Cardiff ",
			"Spanish" : " ^start(animations/Stand/Gestures/Hey_1) Hola ^wait(animations/Stand/Gestures/Hey_1) ",
			"Finnish" : " ^start(animations/Stand/Gestures/Hey_1) Hei ^wait(animations/Stand/Gestures/Hey_1) ",
			"French" : " ^start(animations/Stand/Gestures/Hey_1) Bonjour ^wait(animations/Stand/Gestures/Hey_1) ",
			"Italian" : " ^start(animations/Stand/Gestures/Hey_1) Ciao ^wait(animations/Stand/Gestures/Hey_1) ",
			"Japanese" : " ^start(animations/Stand/Gestures/Hey_1) こんにちは ^wait(animations/Stand/Gestures/Hey_1) ",
			"Korean" : " ^start(animations/Stand/Gestures/Hey_1) 안녕하세요 ^wait(animations/Stand/Gestures/Hey_1) ",
			"Dutch" : " ^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1) ",
			"Norwegian" : "  ",
			"Polish" : " ^start(animations/Stand/Gestures/Hey_1) Cześć ^wait(animations/Stand/Gestures/Hey_1) ",
			"Brazilian" : " ^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1) ",
			"Portuguese" : " ^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1) ",
			"Russian" : " ^start(animations/Stand/Gestures/Hey_1) Привет ^wait(animations/Stand/Gestures/Hey_1) ",
			"Swedish" : " ^start(animations/Stand/Gestures/Hey_1) Hallå ^wait(animations/Stand/Gestures/Hey_1) ",
			"Turkish" : " ^start(animations/Stand/Gestures/Hey_1) Merhaba ^wait(animations/Stand/Gestures/Hey_1) ",
			"Chinese" : "  "
		}

	def onInput_onStart(self):
		sDefaultLang = self.tts.getLanguage()
		self.onStopped(self.sentences[sDefaultLang])]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <![CDATA[]]>
</arabic>
                                                    <czech>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Ahoj ^wait(animations/Stand/Gestures/Hey_1)]]>
</czech>
                                                    <danish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hej ^wait(animations/Stand/Gestures/Hey_1)]]>
</danish>
                                                    <german>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1)]]>
</german>
                                                    <greek>
                                                        <![CDATA[]]>
</greek>
                                                    <english>
                                                        <![CDATA[Hello I am Nao V5. elcome ot the best place for a massage in all of Cardiff]]>
</english>
                                                    <spanish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hola ^wait(animations/Stand/Gestures/Hey_1)]]>
</spanish>
                                                    <finnish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hei ^wait(animations/Stand/Gestures/Hey_1)]]>
</finnish>
                                                    <french>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Bonjour ^wait(animations/Stand/Gestures/Hey_1)]]>
</french>
                                                    <italian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Ciao ^wait(animations/Stand/Gestures/Hey_1)]]>
</italian>
                                                    <japanese>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) こんにちは ^wait(animations/Stand/Gestures/Hey_1)]]>
</japanese>
                                                    <korean>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) 안녕하세요 ^wait(animations/Stand/Gestures/Hey_1)]]>
</korean>
                                                    <dutch>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1)]]>
</dutch>
                                                    <norwegian>
                                                        <![CDATA[]]>
</norwegian>
                                                    <polish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Cześć ^wait(animations/Stand/Gestures/Hey_1)]]>
</polish>
                                                    <brazilian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1)]]>
</brazilian>
                                                    <portuguese>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1)]]>
</portuguese>
                                                    <russian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Привет ^wait(animations/Stand/Gestures/Hey_1)]]>
</russian>
                                                    <swedish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallå ^wait(animations/Stand/Gestures/Hey_1)]]>
</swedish>
                                                    <turkish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Merhaba ^wait(animations/Stand/Gestures/Hey_1)]]>
</turkish>
                                                    <chinese>
                                                        <![CDATA[]]>
</chinese>
                                                    <language>9</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Data is sent on the output when this input is stimulated." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Data sent when asked." id="3" />
                                            </Box>
                                            <Link inputowner="0" indexofinput="4" outputowner="2" indexofoutput="4" />
                                            <Link inputowner="5" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="2" indexofinput="2" outputowner="5" indexofoutput="3" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Language selection" id="5" localization="8" tooltip="Nao asks user if they want to use english or cymraeg " x="975" y="22">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean." id="6" />
                            <Parameter name="Body language mode" inherits_from_parent="0" content_type="3" value="contextual" default_value="contextual" custom_choice="0" tooltip="Change the body language mode during the speech.&#x0A;disabled: The robot will only play the animations given by the user. ex: ^start(...) or ^tag(...)&#x0A;random: During time the robot has no animation to play, he will launch random neutral animations.&#x0A;contextual: During time the robot has no animation to play, he will try to launch a new one accordingly to the saying text. Every time the robot can&apos;t find a contextual animation he will launch a random neutral animation." id="7">
                                <Choice value="disabled" />
                                <Choice value="random" />
                                <Choice value="contextual" />
                            </Parameter>
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Animated Say Text" id="2" localization="8" tooltip="Say the text received on its input and move during its speech." x="422" y="65">
                                                <bitmap>media/images/box/interaction/say.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.animSpeech = ALProxy('ALAnimatedSpeech')

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.animSpeech.stop(id)
            except:
                pass

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            configuration =\
            {"bodyLanguageMode":self.getParameter("Body language mode")}
            id = self.animSpeech.post.say(str(sentence), configuration)
            self.ids.append(id)
            self.animSpeech.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                                                <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                                                <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                                                <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                                                <Parameter name="Body language mode" inherits_from_parent="1" content_type="3" value="contextual" default_value="contextual" custom_choice="0" tooltip="Change the body language mode during the speech.&#x0A;disabled: The robot will only play the animations given by the user. ex: ^start(...) or ^tag(...)&#x0A;random: During time the robot has no animation to play, he will launch random neutral animations.&#x0A;contextual: During time the robot has no animation to play, he will try to launch a new one accordingly to the saying text. Every time the robot can&apos;t find a contextual animation he will launch a random neutral animation." id="7">
                                                    <Choice value="disabled" />
                                                    <Choice value="random" />
                                                    <Choice value="contextual" />
                                                </Parameter>
                                            </Box>
                                            <Box name="Localized Text" id="5" localization="8" tooltip="Send on the output the text associated with the robot&apos;s current voice language.&#x0A;You can display and edit the text associated with any language by&#x0A;selecting the language in the combobox.&#x0A;&#x0A;!!Warning!! The text sent on the output is NOT the displayed one but the one&#x0A;associated with the robot&apos;s current voice language." plugin="localizationbox_plugin" x="72" y="56">
                                                <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		try: # disable autoBind
			GeneratedClass.__init__(self, False)
		except TypeError: # if NAOqi < 1.14
			GeneratedClass.__init__( self )

		self.tts = ALProxy("ALTextToSpeech")
		self.sentences = {
			"Arabic" : "  ",
			"Czech" : " ^start(animations/Stand/Gestures/Hey_1) Ahoj ^wait(animations/Stand/Gestures/Hey_1) ",
			"Danish" : " ^start(animations/Stand/Gestures/Hey_1) Hej ^wait(animations/Stand/Gestures/Hey_1) ",
			"German" : " ^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1) ",
			"Greek" : "  ",
			"English" : " Would you like to continue in English or cymraeg. For english tap my left hand for cymraeg tap my right hand  ",
			"Spanish" : " ^start(animations/Stand/Gestures/Hey_1) Hola ^wait(animations/Stand/Gestures/Hey_1) ",
			"Finnish" : " ^start(animations/Stand/Gestures/Hey_1) Hei ^wait(animations/Stand/Gestures/Hey_1) ",
			"French" : " ^start(animations/Stand/Gestures/Hey_1) Bonjour ^wait(animations/Stand/Gestures/Hey_1) ",
			"Italian" : " ^start(animations/Stand/Gestures/Hey_1) Ciao ^wait(animations/Stand/Gestures/Hey_1) ",
			"Japanese" : " ^start(animations/Stand/Gestures/Hey_1) こんにちは ^wait(animations/Stand/Gestures/Hey_1) ",
			"Korean" : " ^start(animations/Stand/Gestures/Hey_1) 안녕하세요 ^wait(animations/Stand/Gestures/Hey_1) ",
			"Dutch" : " ^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1) ",
			"Norwegian" : "  ",
			"Polish" : " ^start(animations/Stand/Gestures/Hey_1) Cześć ^wait(animations/Stand/Gestures/Hey_1) ",
			"Brazilian" : " ^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1) ",
			"Portuguese" : " ^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1) ",
			"Russian" : " ^start(animations/Stand/Gestures/Hey_1) Привет ^wait(animations/Stand/Gestures/Hey_1) ",
			"Swedish" : " ^start(animations/Stand/Gestures/Hey_1) Hallå ^wait(animations/Stand/Gestures/Hey_1) ",
			"Turkish" : " ^start(animations/Stand/Gestures/Hey_1) Merhaba ^wait(animations/Stand/Gestures/Hey_1) ",
			"Chinese" : "  "
		}

	def onInput_onStart(self):
		sDefaultLang = self.tts.getLanguage()
		self.onStopped(self.sentences[sDefaultLang])]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <![CDATA[]]>
</arabic>
                                                    <czech>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Ahoj ^wait(animations/Stand/Gestures/Hey_1)]]>
</czech>
                                                    <danish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hej ^wait(animations/Stand/Gestures/Hey_1)]]>
</danish>
                                                    <german>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1)]]>
</german>
                                                    <greek>
                                                        <![CDATA[]]>
</greek>
                                                    <english>
                                                        <![CDATA[Would you like to continue in English or cymraeg. For english tap my left hand for cymraeg tap my right hand ]]>
</english>
                                                    <spanish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hola ^wait(animations/Stand/Gestures/Hey_1)]]>
</spanish>
                                                    <finnish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hei ^wait(animations/Stand/Gestures/Hey_1)]]>
</finnish>
                                                    <french>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Bonjour ^wait(animations/Stand/Gestures/Hey_1)]]>
</french>
                                                    <italian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Ciao ^wait(animations/Stand/Gestures/Hey_1)]]>
</italian>
                                                    <japanese>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) こんにちは ^wait(animations/Stand/Gestures/Hey_1)]]>
</japanese>
                                                    <korean>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) 안녕하세요 ^wait(animations/Stand/Gestures/Hey_1)]]>
</korean>
                                                    <dutch>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1)]]>
</dutch>
                                                    <norwegian>
                                                        <![CDATA[]]>
</norwegian>
                                                    <polish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Cześć ^wait(animations/Stand/Gestures/Hey_1)]]>
</polish>
                                                    <brazilian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1)]]>
</brazilian>
                                                    <portuguese>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1)]]>
</portuguese>
                                                    <russian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Привет ^wait(animations/Stand/Gestures/Hey_1)]]>
</russian>
                                                    <swedish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallå ^wait(animations/Stand/Gestures/Hey_1)]]>
</swedish>
                                                    <turkish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Merhaba ^wait(animations/Stand/Gestures/Hey_1)]]>
</turkish>
                                                    <chinese>
                                                        <![CDATA[]]>
</chinese>
                                                    <language>5</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Data is sent on the output when this input is stimulated." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Data sent when asked." id="3" />
                                            </Box>
                                            <Link inputowner="0" indexofinput="4" outputowner="2" indexofoutput="4" />
                                            <Link inputowner="5" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="2" indexofinput="2" outputowner="5" indexofoutput="3" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Confirm langauge selection (english)" id="12" localization="8" tooltip="Nao confirms the language selection the user has made" x="1071" y="168">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean." id="6" />
                            <Parameter name="Body language mode" inherits_from_parent="0" content_type="3" value="contextual" default_value="contextual" custom_choice="0" tooltip="Change the body language mode during the speech.&#x0A;disabled: The robot will only play the animations given by the user. ex: ^start(...) or ^tag(...)&#x0A;random: During time the robot has no animation to play, he will launch random neutral animations.&#x0A;contextual: During time the robot has no animation to play, he will try to launch a new one accordingly to the saying text. Every time the robot can&apos;t find a contextual animation he will launch a random neutral animation." id="7">
                                <Choice value="disabled" />
                                <Choice value="random" />
                                <Choice value="contextual" />
                            </Parameter>
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Animated Say Text" id="2" localization="8" tooltip="Say the text received on its input and move during its speech." x="422" y="93">
                                                <bitmap>media/images/box/interaction/say.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.animSpeech = ALProxy('ALAnimatedSpeech')

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.animSpeech.stop(id)
            except:
                pass

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            configuration =\
            {"bodyLanguageMode":self.getParameter("Body language mode")}
            id = self.animSpeech.post.say(str(sentence), configuration)
            self.ids.append(id)
            self.animSpeech.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                                                <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                                                <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                                                <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                                                <Parameter name="Body language mode" inherits_from_parent="1" content_type="3" value="contextual" default_value="contextual" custom_choice="0" tooltip="Change the body language mode during the speech.&#x0A;disabled: The robot will only play the animations given by the user. ex: ^start(...) or ^tag(...)&#x0A;random: During time the robot has no animation to play, he will launch random neutral animations.&#x0A;contextual: During time the robot has no animation to play, he will try to launch a new one accordingly to the saying text. Every time the robot can&apos;t find a contextual animation he will launch a random neutral animation." id="7">
                                                    <Choice value="disabled" />
                                                    <Choice value="random" />
                                                    <Choice value="contextual" />
                                                </Parameter>
                                            </Box>
                                            <Box name="Localized Text" id="5" localization="8" tooltip="Send on the output the text associated with the robot&apos;s current voice language.&#x0A;You can display and edit the text associated with any language by&#x0A;selecting the language in the combobox.&#x0A;&#x0A;!!Warning!! The text sent on the output is NOT the displayed one but the one&#x0A;associated with the robot&apos;s current voice language." plugin="localizationbox_plugin" x="114" y="68">
                                                <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		try: # disable autoBind
			GeneratedClass.__init__(self, False)
		except TypeError: # if NAOqi < 1.14
			GeneratedClass.__init__( self )

		self.tts = ALProxy("ALTextToSpeech")
		self.sentences = {
			"Arabic" : "  ",
			"Czech" : " ^start(animations/Stand/Gestures/Hey_1) Ahoj ^wait(animations/Stand/Gestures/Hey_1) ",
			"Danish" : " ^start(animations/Stand/Gestures/Hey_1) Hej ^wait(animations/Stand/Gestures/Hey_1) ",
			"German" : " ^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1) ",
			"Greek" : "  ",
			"English" : " english selected ",
			"Spanish" : " ^start(animations/Stand/Gestures/Hey_1) Hola ^wait(animations/Stand/Gestures/Hey_1) ",
			"Finnish" : " ^start(animations/Stand/Gestures/Hey_1) Hei ^wait(animations/Stand/Gestures/Hey_1) ",
			"French" : " ^start(animations/Stand/Gestures/Hey_1) Bonjour ^wait(animations/Stand/Gestures/Hey_1) ",
			"Italian" : " ^start(animations/Stand/Gestures/Hey_1) Ciao ^wait(animations/Stand/Gestures/Hey_1) ",
			"Japanese" : " ^start(animations/Stand/Gestures/Hey_1) こんにちは ^wait(animations/Stand/Gestures/Hey_1) ",
			"Korean" : " ^start(animations/Stand/Gestures/Hey_1) 안녕하세요 ^wait(animations/Stand/Gestures/Hey_1) ",
			"Dutch" : " ^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1) ",
			"Norwegian" : "  ",
			"Polish" : " ^start(animations/Stand/Gestures/Hey_1) Cześć ^wait(animations/Stand/Gestures/Hey_1) ",
			"Brazilian" : " ^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1) ",
			"Portuguese" : " ^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1) ",
			"Russian" : " ^start(animations/Stand/Gestures/Hey_1) Привет ^wait(animations/Stand/Gestures/Hey_1) ",
			"Swedish" : " ^start(animations/Stand/Gestures/Hey_1) Hallå ^wait(animations/Stand/Gestures/Hey_1) ",
			"Turkish" : " ^start(animations/Stand/Gestures/Hey_1) Merhaba ^wait(animations/Stand/Gestures/Hey_1) ",
			"Chinese" : "  "
		}

	def onInput_onStart(self):
		sDefaultLang = self.tts.getLanguage()
		self.onStopped(self.sentences[sDefaultLang])]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <![CDATA[]]>
</arabic>
                                                    <czech>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Ahoj ^wait(animations/Stand/Gestures/Hey_1)]]>
</czech>
                                                    <danish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hej ^wait(animations/Stand/Gestures/Hey_1)]]>
</danish>
                                                    <german>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1)]]>
</german>
                                                    <greek>
                                                        <![CDATA[]]>
</greek>
                                                    <english>
                                                        <![CDATA[english selected]]>
</english>
                                                    <spanish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hola ^wait(animations/Stand/Gestures/Hey_1)]]>
</spanish>
                                                    <finnish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hei ^wait(animations/Stand/Gestures/Hey_1)]]>
</finnish>
                                                    <french>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Bonjour ^wait(animations/Stand/Gestures/Hey_1)]]>
</french>
                                                    <italian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Ciao ^wait(animations/Stand/Gestures/Hey_1)]]>
</italian>
                                                    <japanese>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) こんにちは ^wait(animations/Stand/Gestures/Hey_1)]]>
</japanese>
                                                    <korean>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) 안녕하세요 ^wait(animations/Stand/Gestures/Hey_1)]]>
</korean>
                                                    <dutch>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1)]]>
</dutch>
                                                    <norwegian>
                                                        <![CDATA[]]>
</norwegian>
                                                    <polish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Cześć ^wait(animations/Stand/Gestures/Hey_1)]]>
</polish>
                                                    <brazilian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1)]]>
</brazilian>
                                                    <portuguese>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1)]]>
</portuguese>
                                                    <russian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Привет ^wait(animations/Stand/Gestures/Hey_1)]]>
</russian>
                                                    <swedish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallå ^wait(animations/Stand/Gestures/Hey_1)]]>
</swedish>
                                                    <turkish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Merhaba ^wait(animations/Stand/Gestures/Hey_1)]]>
</turkish>
                                                    <chinese>
                                                        <![CDATA[]]>
</chinese>
                                                    <language>9</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Data is sent on the output when this input is stimulated." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Data sent when asked." id="3" />
                                            </Box>
                                            <Link inputowner="0" indexofinput="4" outputowner="2" indexofoutput="4" />
                                            <Link inputowner="5" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="2" indexofinput="2" outputowner="5" indexofoutput="3" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Blink (1)" id="13" localization="8" tooltip="This box makes the robot blink once." x="1293" y="314">
                            <bitmap>media/images/box/interaction/LED.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.leds = ALProxy("ALLeds")

    def onUnload(self):
        #~ puts code for box cleanup here
        pass

    def onInput_onStart(self):
        rDuration = 0.05
        self.leds.post.fadeRGB( "FaceLed0", 0x000000, rDuration )
        self.leds.post.fadeRGB( "FaceLed1", 0x000000, rDuration )
        self.leds.post.fadeRGB( "FaceLed2", 0xffffff, rDuration )
        self.leds.post.fadeRGB( "FaceLed3", 0x000000, rDuration )
        self.leds.post.fadeRGB( "FaceLed4", 0x000000, rDuration )
        self.leds.post.fadeRGB( "FaceLed5", 0x000000, rDuration )
        self.leds.post.fadeRGB( "FaceLed6", 0xffffff, rDuration )
        self.leds.fadeRGB( "FaceLed7", 0x000000, rDuration )
        time.sleep( 0.1 )
        self.leds.fadeRGB( "FaceLeds", 0xffffff, rDuration )
        self.onDone()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Output name="onDone" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="3" />
                        </Box>
                        <Box name="Hello" id="19" localization="8" tooltip="Simple hello animation.&#x0A;&#x0A;!!Warning!! There is no speech in this box. It is a just an animation box with some&#x0A;leds animation." x="601" y="189">
                            <bitmap>media/images/box/movement/move.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        #~ puts code for box initialization here
        pass

    def onUnload(self):
        #~ puts code for box cleanup here
        pass

    def onInput_onStart(self):
        #~ self.onStopped() #~ activate output of the box
        pass

    def onInput_onStop(self):
        self.onUnload() #~ it is recommanded to call onUnload of this box in a onStop method, as the code written in onUnload is used to stop the box as well
        pass]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
                            <Timeline enable="1" fps="25" start_frame="1" end_frame="-1" size="115">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="FaceLeds" index="1">
                                        <Diagram>
                                            <Box name="Light_AskForAttentionEyes" id="1" localization="8" tooltip="Set an animated gaze which calls for attention (purple eyes).&#x0A;&#x0A;Note: It is a never ending box. You must call onStop to stop it.&#x0A;&#x0A;*** state: 5a_release ***&#x0A;*** ref box in: 5a_release\Leds\Light_AskForAttentionEyes\Light_AskForAttentionEyes.xar ***&#x0A;*** last modification date(svn): Version it! ***" x="281" y="144">
                                                <bitmap>media/images/box/interaction/LED.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[class MyClass(GeneratedClass):
  def __init__(self):
    GeneratedClass.__init__(self, False)

  def onLoad(self):
    self.bIsRunning = False;
    self.leds = ALProxy("ALLeds")

  def onUnload(self):
    self.onInput_onStop(); # will stop current loop execution

  def onInput_onStart(self):
    #self.logger.info( self.getName() + ": start - begin" );

    if( self.bIsRunning ):
      #print( self.getName() + ": already started => nothing" );
      return;

    self.bIsRunning = True;
    self.bMustStop = False;

    rDuration = 0.2;
    self.leds.post.fadeRGB( "FaceLedsTop", 0xff00ff, rDuration );
    self.leds.post.fadeRGB( "FaceLedsInternal", 0xff00ff, rDuration );
    self.leds.post.fadeRGB( "FaceLedsBottom", 0xff00ff, rDuration );
    self.leds.fadeRGB( "FaceLedsExternal", 0xff00ff, rDuration );

    while( not self.bMustStop ):
      rTime = 0.1;
      self.leds.post.fadeRGB( "FaceLedsTop", 0xffffff, rTime );
      self.leds.fadeRGB( "FaceLedsBottom", 0xffffff, rTime );
      if( self.bMustStop ):
        break;
      rTime = 0.3
      self.leds.post.fadeRGB( "FaceLedsTop", 0xff00ff, rTime );
      self.leds.fadeRGB( "FaceLedsBottom", 0xff00ff, rTime );


    # end while
    self.bIsRunning = False;
    self.onStopped();

  def onInput_onStop(self):
    self.bMustStop = True; # will stop current loop execution]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
                                            </Box>
                                            <Link inputowner="1" indexofinput="2" outputowner="0" indexofoutput="1" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                                <ActuatorList model="Nao">
                                    <ActuatorCurve name="value" actuator="HeadYaw" recordable="1" mute="0" unit="-1">
                                        <Key frame="20" value="-7.73688" />
                                        <Key frame="39" value="-20.1296" />
                                        <Key frame="56" value="-23.8211" />
                                        <Key frame="70" value="-23.9968" />
                                        <Key frame="87" value="-29.7977" />
                                        <Key frame="115" value="-21.5359" />
                                    </ActuatorCurve>
                                    <ActuatorCurve name="value" actuator="HeadPitch" recordable="1" mute="0" unit="-1">
                                        <Key frame="20" value="16.9607" />
                                        <Key frame="39" value="-9.75839" />
                                        <Key frame="56" value="-19.5144" />
                                        <Key frame="70" value="-3.43018" />
                                        <Key frame="87" value="-11.0768" />
                                        <Key frame="115" value="-0.617646" />
                                    </ActuatorCurve>
                                    <ActuatorCurve name="value" actuator="LShoulderPitch" recordable="1" mute="0" unit="-1">
                                        <Key frame="18" value="64.0707" />
                                        <Key frame="37" value="53.1721" />
                                        <Key frame="54" value="53.8752" />
                                        <Key frame="68" value="49.3927" />
                                        <Key frame="85" value="51.4143" />
                                        <Key frame="113" value="48.2502" />
                                    </ActuatorCurve>
                                    <ActuatorCurve name="value" actuator="LShoulderRoll" recordable="1" mute="0" unit="-1">
                                        <Key frame="18" value="20.8279" />
                                        <Key frame="37" value="13.0056" />
                                        <Key frame="54" value="11.6872" />
                                        <Key frame="68" value="12.4782" />
                                        <Key frame="85" value="14.2361" />
                                        <Key frame="113" value="13.0056" />
                                    </ActuatorCurve>
                                    <ActuatorCurve name="value" actuator="LElbowYaw" recordable="1" mute="0" unit="-1">
                                        <Key frame="18" value="-46.0577" />
                                        <Key frame="37" value="-39.6416" />
                                        <Key frame="54" value="-38.9384" />
                                        <Key frame="68" value="-34.9833" />
                                        <Key frame="85" value="-43.1572" />
                                        <Key frame="113" value="-38.4111" />
                                    </ActuatorCurve>
                                    <ActuatorCurve name="value" actuator="LElbowRoll" recordable="1" mute="0" unit="-1">
                                        <Key frame="18" value="-79.0123" />
                                        <Key frame="37" value="-73.9145" />
                                        <Key frame="54" value="-67.7621" />
                                        <Key frame="68" value="-71.5415" />
                                        <Key frame="85" value="-75.5845" />
                                        <Key frame="113" value="-67.85" />
                                    </ActuatorCurve>
                                    <ActuatorCurve name="value" actuator="LWristYaw" recordable="1" mute="0" unit="-1">
                                        <Key frame="37" value="8.4352" />
                                        <Key frame="113" value="6.85315" />
                                    </ActuatorCurve>
                                    <ActuatorCurve name="value" actuator="LHand" recordable="1" mute="0" unit="-1">
                                        <Key frame="37" value="0.238207" />
                                        <Key frame="113" value="0.240025" />
                                    </ActuatorCurve>
                                    <ActuatorCurve name="value" actuator="RShoulderPitch" recordable="1" mute="0" unit="-1">
                                        <Key frame="16" value="14.153" />
                                        <Key frame="35" value="-67.1469" />
                                        <Key frame="52" value="-62.4007" />
                                        <Key frame="66" value="-72.2446" />
                                        <Key frame="83" value="-65.8285" />
                                        <Key frame="111" value="58.4504" />
                                    </ActuatorCurve>
                                    <ActuatorCurve name="value" actuator="RShoulderRoll" recordable="1" mute="0" unit="-1">
                                        <Key frame="16" value="-13.8893" />
                                        <Key frame="35" value="-54.6711" />
                                        <Key frame="52" value="-26.3699" />
                                        <Key frame="66" value="-55.0226" />
                                        <Key frame="83" value="-18.8112" />
                                        <Key frame="111" value="-14.3288" />
                                    </ActuatorCurve>
                                    <ActuatorCurve name="value" actuator="RElbowYaw" recordable="1" mute="0" unit="-1">
                                        <Key frame="16" value="-17.9323" />
                                        <Key frame="35" value="32.3418" />
                                        <Key frame="52" value="22.41" />
                                        <Key frame="66" value="19.949" />
                                        <Key frame="83" value="21.8826" />
                                        <Key frame="93" value="56" />
                                        <Key frame="111" value="47.3712" />
                                    </ActuatorCurve>
                                    <ActuatorCurve name="value" actuator="RElbowRoll" recordable="1" mute="0" unit="-1">
                                        <Key frame="16" value="79.3686" />
                                        <Key frame="35" value="13.8893" />
                                        <Key frame="42" value="20" />
                                        <Key frame="52" value="53.5285" />
                                        <Key frame="60" value="39" />
                                        <Key frame="66" value="11" />
                                        <Key frame="76" value="15" />
                                        <Key frame="83" value="40.5205" />
                                        <Key frame="93" value="58.4" />
                                        <Key frame="111" value="72.5131" />
                                    </ActuatorCurve>
                                    <ActuatorCurve name="value" actuator="RWristYaw" recordable="1" mute="0" unit="-1">
                                        <Key frame="35" value="-17.9323" />
                                        <Key frame="83" value="-17.405" />
                                        <Key frame="111" value="10.4567" />
                                    </ActuatorCurve>
                                    <ActuatorCurve name="value" actuator="RHand" recordable="1" mute="0" unit="-1">
                                        <Key frame="35" value="0.853478" />
                                        <Key frame="83" value="0.854933" />
                                        <Key frame="111" value="0.425116" />
                                    </ActuatorCurve>
                                </ActuatorList>
                            </Timeline>
                            <Resource name="Head" type="Lock" timeout="0" />
                            <Resource name="Arms" type="Lock" timeout="0" />
                            <Resource name="Left eye leds" type="Lock" timeout="0" />
                            <Resource name="Right eye leds" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Follow Nao to appointment " id="22" localization="8" tooltip="Nao asks user to follow them to appointment " x="828" y="867">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean." id="6" />
                            <Parameter name="Body language mode" inherits_from_parent="0" content_type="3" value="contextual" default_value="contextual" custom_choice="0" tooltip="Change the body language mode during the speech.&#x0A;disabled: The robot will only play the animations given by the user. ex: ^start(...) or ^tag(...)&#x0A;random: During time the robot has no animation to play, he will launch random neutral animations.&#x0A;contextual: During time the robot has no animation to play, he will try to launch a new one accordingly to the saying text. Every time the robot can&apos;t find a contextual animation he will launch a random neutral animation." id="7">
                                <Choice value="disabled" />
                                <Choice value="random" />
                                <Choice value="contextual" />
                            </Parameter>
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Animated Say Text" id="2" localization="8" tooltip="Say the text received on its input and move during its speech." x="422" y="93">
                                                <bitmap>media/images/box/interaction/say.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.animSpeech = ALProxy('ALAnimatedSpeech')

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.animSpeech.stop(id)
            except:
                pass

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            configuration =\
            {"bodyLanguageMode":self.getParameter("Body language mode")}
            id = self.animSpeech.post.say(str(sentence), configuration)
            self.ids.append(id)
            self.animSpeech.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                                                <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                                                <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                                                <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                                                <Parameter name="Body language mode" inherits_from_parent="1" content_type="3" value="contextual" default_value="contextual" custom_choice="0" tooltip="Change the body language mode during the speech.&#x0A;disabled: The robot will only play the animations given by the user. ex: ^start(...) or ^tag(...)&#x0A;random: During time the robot has no animation to play, he will launch random neutral animations.&#x0A;contextual: During time the robot has no animation to play, he will try to launch a new one accordingly to the saying text. Every time the robot can&apos;t find a contextual animation he will launch a random neutral animation." id="7">
                                                    <Choice value="disabled" />
                                                    <Choice value="random" />
                                                    <Choice value="contextual" />
                                                </Parameter>
                                            </Box>
                                            <Box name="Localized Text" id="5" localization="8" tooltip="Send on the output the text associated with the robot&apos;s current voice language.&#x0A;You can display and edit the text associated with any language by&#x0A;selecting the language in the combobox.&#x0A;&#x0A;!!Warning!! The text sent on the output is NOT the displayed one but the one&#x0A;associated with the robot&apos;s current voice language." plugin="localizationbox_plugin" x="114" y="68">
                                                <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		try: # disable autoBind
			GeneratedClass.__init__(self, False)
		except TypeError: # if NAOqi < 1.14
			GeneratedClass.__init__( self )

		self.tts = ALProxy("ALTextToSpeech")
		self.sentences = {
			"Arabic" : "  ",
			"Czech" : " ^start(animations/Stand/Gestures/Hey_1) Ahoj ^wait(animations/Stand/Gestures/Hey_1) ",
			"Danish" : " ^start(animations/Stand/Gestures/Hey_1) Hej ^wait(animations/Stand/Gestures/Hey_1) ",
			"German" : " ^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1) ",
			"Greek" : "  ",
			"English" : " Please follow me to your appointment ",
			"Spanish" : " ^start(animations/Stand/Gestures/Hey_1) Hola ^wait(animations/Stand/Gestures/Hey_1) ",
			"Finnish" : " ^start(animations/Stand/Gestures/Hey_1) Hei ^wait(animations/Stand/Gestures/Hey_1) ",
			"French" : " ^start(animations/Stand/Gestures/Hey_1) Bonjour ^wait(animations/Stand/Gestures/Hey_1) ",
			"Italian" : " ^start(animations/Stand/Gestures/Hey_1) Ciao ^wait(animations/Stand/Gestures/Hey_1) ",
			"Japanese" : " ^start(animations/Stand/Gestures/Hey_1) こんにちは ^wait(animations/Stand/Gestures/Hey_1) ",
			"Korean" : " ^start(animations/Stand/Gestures/Hey_1) 안녕하세요 ^wait(animations/Stand/Gestures/Hey_1) ",
			"Dutch" : " ^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1) ",
			"Norwegian" : "  ",
			"Polish" : " ^start(animations/Stand/Gestures/Hey_1) Cześć ^wait(animations/Stand/Gestures/Hey_1) ",
			"Brazilian" : " ^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1) ",
			"Portuguese" : " ^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1) ",
			"Russian" : " ^start(animations/Stand/Gestures/Hey_1) Привет ^wait(animations/Stand/Gestures/Hey_1) ",
			"Swedish" : " ^start(animations/Stand/Gestures/Hey_1) Hallå ^wait(animations/Stand/Gestures/Hey_1) ",
			"Turkish" : " ^start(animations/Stand/Gestures/Hey_1) Merhaba ^wait(animations/Stand/Gestures/Hey_1) ",
			"Chinese" : "  "
		}

	def onInput_onStart(self):
		sDefaultLang = self.tts.getLanguage()
		self.onStopped(self.sentences[sDefaultLang])]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <![CDATA[]]>
</arabic>
                                                    <czech>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Ahoj ^wait(animations/Stand/Gestures/Hey_1)]]>
</czech>
                                                    <danish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hej ^wait(animations/Stand/Gestures/Hey_1)]]>
</danish>
                                                    <german>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1)]]>
</german>
                                                    <greek>
                                                        <![CDATA[]]>
</greek>
                                                    <english>
                                                        <![CDATA[Please follow me to your appointment]]>
</english>
                                                    <spanish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hola ^wait(animations/Stand/Gestures/Hey_1)]]>
</spanish>
                                                    <finnish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hei ^wait(animations/Stand/Gestures/Hey_1)]]>
</finnish>
                                                    <french>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Bonjour ^wait(animations/Stand/Gestures/Hey_1)]]>
</french>
                                                    <italian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Ciao ^wait(animations/Stand/Gestures/Hey_1)]]>
</italian>
                                                    <japanese>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) こんにちは ^wait(animations/Stand/Gestures/Hey_1)]]>
</japanese>
                                                    <korean>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) 안녕하세요 ^wait(animations/Stand/Gestures/Hey_1)]]>
</korean>
                                                    <dutch>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1)]]>
</dutch>
                                                    <norwegian>
                                                        <![CDATA[]]>
</norwegian>
                                                    <polish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Cześć ^wait(animations/Stand/Gestures/Hey_1)]]>
</polish>
                                                    <brazilian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1)]]>
</brazilian>
                                                    <portuguese>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1)]]>
</portuguese>
                                                    <russian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Привет ^wait(animations/Stand/Gestures/Hey_1)]]>
</russian>
                                                    <swedish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallå ^wait(animations/Stand/Gestures/Hey_1)]]>
</swedish>
                                                    <turkish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Merhaba ^wait(animations/Stand/Gestures/Hey_1)]]>
</turkish>
                                                    <chinese>
                                                        <![CDATA[]]>
</chinese>
                                                    <language>9</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Data is sent on the output when this input is stimulated." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Data sent when asked." id="3" />
                                            </Box>
                                            <Link inputowner="0" indexofinput="4" outputowner="2" indexofoutput="4" />
                                            <Link inputowner="5" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="2" indexofinput="2" outputowner="5" indexofoutput="3" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Walk to appointment " id="23" localization="8" tooltip="Nao walks to the appointment " x="822" y="980">
                            <bitmap>media/images/box/movement/walk_forward.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):


    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        import threading
        self.motion = ALProxy("ALMotion")
        self.x = 0
        self.y = 0
        self.theta = 0
        self.ptask = qi.PeriodicTask()
        self.lock = threading.RLock()

    def onUnload(self):
        with self.lock:
            self.ptask.stop()
            self.x = 0
            self.y = 0
            self.theta = 0
            self.motion.moveToward(0, 0, 0)
            self.motion.waitUntilMoveIsFinished()

    def onInput_onStop(self):
        with self.lock:
            self.onUnload()
            self.onStopped()

    def onInput_onStart(self):
        with self.lock:
            period = self.getParameter("Period of direction update (s)")
            us_period = int(period*1000000)

            self.ptask.compensateCallbackTime(True)
            self.ptask.setCallback(self.updateMovement)
            self.ptask.setUsPeriod(us_period)
            self.ptask.start(True)

    def moveFailed(self):
        self.onUnload()
        self.onMoveFailed()

    def updateMovement(self):
        import math
        with self.lock:
            enableArms = self.getParameter("Arms movement enabled")
            self.motion.setMoveArmsEnabled(enableArms, enableArms)
            x = self.getParameter("X")
            y = self.getParameter("Y")
            theta = self.getParameter("Theta")
            period = self.getParameter("Period of direction update (s)")
            epsilon = 0.0001
            dx = math.fabs(x - self.x)
            dy = math.fabs(y - self.y)
            dt = math.fabs(theta - self.theta)

            # Update moveToward parameters
            if(dx > epsilon or dy > epsilon or dt > epsilon):
                self.x=x
                self.y=y
                self.theta=theta
                self.motion.moveToward(self.x, self.y, self.theta)

            # Check if the move has been canceled
            if (not self.motion.moveIsActive()):
                self.moveFailed()

            us_period = int(period*1000000)
            self.ptask.setUsPeriod(us_period)]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when the box behavior is stopped." id="4" />
                            <Output name="onMoveFailed" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when the motion move task is canceled." id="5" />
                            <Parameter name="X" inherits_from_parent="0" content_type="2" value="0.2" default_value="0.2" min="-1" max="1" tooltip="The distance in meters for forward/backward motion. Positive value&#x0A;means forward, negative value means backward." id="6" />
                            <Parameter name="Y" inherits_from_parent="0" content_type="2" value="0" default_value="0" min="-1" max="1" tooltip="The distance in meters for lateral motion. Positive value means left, negative&#x0A;value means right." id="7" />
                            <Parameter name="Theta" inherits_from_parent="0" content_type="2" value="-0.719298" default_value="0" min="-1" max="1" tooltip="The orientation in radians for final rotation. Positive value means anticlockwise,&#x0A;negative value means clockwise." id="8" />
                            <Parameter name="Period of direction update (s)" inherits_from_parent="0" content_type="2" value="0.1" default_value="0.1" min="0" max="1" tooltip="" id="9" />
                            <Parameter name="Arms movement enabled" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="Enables natural motion of the arms." id="10" />
                            <Resource name="Legs" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Farewell" id="24" localization="8" tooltip="Nao says farewell and wishes the user well" x="823" y="1101">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean." id="6" />
                            <Parameter name="Body language mode" inherits_from_parent="0" content_type="3" value="contextual" default_value="contextual" custom_choice="0" tooltip="Change the body language mode during the speech.&#x0A;disabled: The robot will only play the animations given by the user. ex: ^start(...) or ^tag(...)&#x0A;random: During time the robot has no animation to play, he will launch random neutral animations.&#x0A;contextual: During time the robot has no animation to play, he will try to launch a new one accordingly to the saying text. Every time the robot can&apos;t find a contextual animation he will launch a random neutral animation." id="7">
                                <Choice value="disabled" />
                                <Choice value="random" />
                                <Choice value="contextual" />
                            </Parameter>
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Animated Say Text" id="2" localization="8" tooltip="Say the text received on its input and move during its speech." x="422" y="93">
                                                <bitmap>media/images/box/interaction/say.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.animSpeech = ALProxy('ALAnimatedSpeech')

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.animSpeech.stop(id)
            except:
                pass

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            configuration =\
            {"bodyLanguageMode":self.getParameter("Body language mode")}
            id = self.animSpeech.post.say(str(sentence), configuration)
            self.ids.append(id)
            self.animSpeech.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                                                <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                                                <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                                                <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                                                <Parameter name="Body language mode" inherits_from_parent="1" content_type="3" value="contextual" default_value="contextual" custom_choice="0" tooltip="Change the body language mode during the speech.&#x0A;disabled: The robot will only play the animations given by the user. ex: ^start(...) or ^tag(...)&#x0A;random: During time the robot has no animation to play, he will launch random neutral animations.&#x0A;contextual: During time the robot has no animation to play, he will try to launch a new one accordingly to the saying text. Every time the robot can&apos;t find a contextual animation he will launch a random neutral animation." id="7">
                                                    <Choice value="disabled" />
                                                    <Choice value="random" />
                                                    <Choice value="contextual" />
                                                </Parameter>
                                            </Box>
                                            <Box name="Localized Text" id="5" localization="8" tooltip="Send on the output the text associated with the robot&apos;s current voice language.&#x0A;You can display and edit the text associated with any language by&#x0A;selecting the language in the combobox.&#x0A;&#x0A;!!Warning!! The text sent on the output is NOT the displayed one but the one&#x0A;associated with the robot&apos;s current voice language." plugin="localizationbox_plugin" x="114" y="68">
                                                <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		try: # disable autoBind
			GeneratedClass.__init__(self, False)
		except TypeError: # if NAOqi < 1.14
			GeneratedClass.__init__( self )

		self.tts = ALProxy("ALTextToSpeech")
		self.sentences = {
			"Arabic" : "  ",
			"Czech" : " ^start(animations/Stand/Gestures/Hey_1) Ahoj ^wait(animations/Stand/Gestures/Hey_1) ",
			"Danish" : " ^start(animations/Stand/Gestures/Hey_1) Hej ^wait(animations/Stand/Gestures/Hey_1) ",
			"German" : " ^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1) ",
			"Greek" : "  ",
			"English" : " Please enjoy your appointment ",
			"Spanish" : " ^start(animations/Stand/Gestures/Hey_1) Hola ^wait(animations/Stand/Gestures/Hey_1) ",
			"Finnish" : " ^start(animations/Stand/Gestures/Hey_1) Hei ^wait(animations/Stand/Gestures/Hey_1) ",
			"French" : " ^start(animations/Stand/Gestures/Hey_1) Bonjour ^wait(animations/Stand/Gestures/Hey_1) ",
			"Italian" : " ^start(animations/Stand/Gestures/Hey_1) Ciao ^wait(animations/Stand/Gestures/Hey_1) ",
			"Japanese" : " ^start(animations/Stand/Gestures/Hey_1) こんにちは ^wait(animations/Stand/Gestures/Hey_1) ",
			"Korean" : " ^start(animations/Stand/Gestures/Hey_1) 안녕하세요 ^wait(animations/Stand/Gestures/Hey_1) ",
			"Dutch" : " ^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1) ",
			"Norwegian" : "  ",
			"Polish" : " ^start(animations/Stand/Gestures/Hey_1) Cześć ^wait(animations/Stand/Gestures/Hey_1) ",
			"Brazilian" : " ^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1) ",
			"Portuguese" : " ^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1) ",
			"Russian" : " ^start(animations/Stand/Gestures/Hey_1) Привет ^wait(animations/Stand/Gestures/Hey_1) ",
			"Swedish" : " ^start(animations/Stand/Gestures/Hey_1) Hallå ^wait(animations/Stand/Gestures/Hey_1) ",
			"Turkish" : " ^start(animations/Stand/Gestures/Hey_1) Merhaba ^wait(animations/Stand/Gestures/Hey_1) ",
			"Chinese" : "  "
		}

	def onInput_onStart(self):
		sDefaultLang = self.tts.getLanguage()
		self.onStopped(self.sentences[sDefaultLang])]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <![CDATA[]]>
</arabic>
                                                    <czech>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Ahoj ^wait(animations/Stand/Gestures/Hey_1)]]>
</czech>
                                                    <danish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hej ^wait(animations/Stand/Gestures/Hey_1)]]>
</danish>
                                                    <german>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1)]]>
</german>
                                                    <greek>
                                                        <![CDATA[]]>
</greek>
                                                    <english>
                                                        <![CDATA[Please enjoy your appointment]]>
</english>
                                                    <spanish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hola ^wait(animations/Stand/Gestures/Hey_1)]]>
</spanish>
                                                    <finnish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hei ^wait(animations/Stand/Gestures/Hey_1)]]>
</finnish>
                                                    <french>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Bonjour ^wait(animations/Stand/Gestures/Hey_1)]]>
</french>
                                                    <italian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Ciao ^wait(animations/Stand/Gestures/Hey_1)]]>
</italian>
                                                    <japanese>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) こんにちは ^wait(animations/Stand/Gestures/Hey_1)]]>
</japanese>
                                                    <korean>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) 안녕하세요 ^wait(animations/Stand/Gestures/Hey_1)]]>
</korean>
                                                    <dutch>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1)]]>
</dutch>
                                                    <norwegian>
                                                        <![CDATA[]]>
</norwegian>
                                                    <polish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Cześć ^wait(animations/Stand/Gestures/Hey_1)]]>
</polish>
                                                    <brazilian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1)]]>
</brazilian>
                                                    <portuguese>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1)]]>
</portuguese>
                                                    <russian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Привет ^wait(animations/Stand/Gestures/Hey_1)]]>
</russian>
                                                    <swedish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallå ^wait(animations/Stand/Gestures/Hey_1)]]>
</swedish>
                                                    <turkish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Merhaba ^wait(animations/Stand/Gestures/Hey_1)]]>
</turkish>
                                                    <chinese>
                                                        <![CDATA[]]>
</chinese>
                                                    <language>10</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Data is sent on the output when this input is stimulated." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Data sent when asked." id="3" />
                                            </Box>
                                            <Link inputowner="0" indexofinput="4" outputowner="2" indexofoutput="4" />
                                            <Link inputowner="5" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="2" indexofinput="2" outputowner="5" indexofoutput="3" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Set Language" id="25" localization="8" tooltip="Select the language you would like the robot to speak and understand. Any following call to&#x0A;ALSpeechRecognition (Speech Reco. box for instance) or ALTextToSpeech (Say box&#x0A;for instance) will use this language." x="155" y="385">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        try:
            self.tts = ALProxy("ALTextToSpeech")
        except:
            self.logger.warn("ALTextToSpeech is not available, language setting cannot be applied to speech")
            self.tts = None

        try:
            self.asr = ALProxy("ALSpeechRecognition")
        except:
            self.logger.warn("ALSpeechRecognition is not available, language setting cannot be applied to recognition")
            self.asr = None

        try:
            self.dialog = ALProxy("ALDialog")
        except:
            self.logger.warn("ALDialog is not available, language setting cannot be applied to dialog")
            self.dialog = None

    def onInput_onSet(self):
        lang = self.getParameter("Language")
        try:
            if self.asr:
                self.asr.setLanguage( self.getParameter("Language") )
            if self.tts:
                self.tts.setLanguage( self.getParameter("Language") )
            if self.dialog:
                self.dialog.setLanguage( self.getParameter("Language") )
            if self.tts is None and self.asr is None and self.dialog is None:
                raise RuntimeError("Cannot set language: neither ALTextToSpeech nor ALSpeechRecognition nor ALDialog is available.")
            self.onReady()
        except:
            error = "Language " + lang + " cannot be set."
            self.logger.warn(error)
            self.onError(error)]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onSet" type="1" type_size="1" nature="1" inner="0" tooltip="The data is set when a signal is received on this input." id="2" />
                            <Output name="onReady" type="1" type_size="1" nature="2" inner="0" tooltip="Signal sent when the data has been set." id="3" />
                            <Output name="onError" type="3" type_size="1" nature="2" inner="0" tooltip="Error output:&#x0A;- triggered if the language asked cannot be set" id="4" />
                            <Parameter name="Language" inherits_from_parent="0" content_type="3" value="English" default_value="English" custom_choice="1" tooltip="Set the language the robot speaks and understands." id="5">
                                <Choice value="Arabic" />
                                <Choice value="Brazilian" />
                                <Choice value="Chinese" />
                                <Choice value="Czech" />
                                <Choice value="Danish" />
                                <Choice value="Dutch" />
                                <Choice value="English" />
                                <Choice value="Finnish" />
                                <Choice value="French" />
                                <Choice value="German" />
                                <Choice value="Greek" />
                                <Choice value="Italian" />
                                <Choice value="Japanese" />
                                <Choice value="Korean" />
                                <Choice value="Norwegian" />
                                <Choice value="Polish" />
                                <Choice value="Portuguese" />
                                <Choice value="Russian" />
                                <Choice value="Spanish" />
                                <Choice value="Swedish" />
                                <Choice value="Turkish" />
                            </Parameter>
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Ask user to wait in the waiting room" id="26" localization="8" tooltip="Ask user to take a seat in the waiting room." x="1065" y="874">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean." id="6" />
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Say Text" id="2" localization="8" tooltip="Say the text received on its input." x="422" y="65">
                                                <bitmap>media/images/box/interaction/say.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.tts = ALProxy('ALTextToSpeech')
        self.ttsStop = ALProxy('ALTextToSpeech', True) #Create another proxy as wait is blocking if audioout is remote

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            id = self.tts.post.say(str(sentence))
            self.ids.append(id)
            self.tts.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                                                <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                                                <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                                                <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                                            </Box>
                                            <Box name="Localized Text" id="5" localization="8" tooltip="Send on the output the text associated with the robot&apos;s current voice language.&#x0A;You can display and edit the text associated with any language by&#x0A;selecting the language in the combobox.&#x0A;&#x0A;!!Warning!! The text sent on the output is NOT the displayed one but the one&#x0A;associated with the robot&apos;s current voice language." plugin="localizationbox_plugin" x="114" y="68">
                                                <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		try: # disable autoBind
			GeneratedClass.__init__(self, False)
		except TypeError: # if NAOqi < 1.14
			GeneratedClass.__init__( self )

		self.tts = ALProxy("ALTextToSpeech")
		self.sentences = {
			"Arabic" : "  ",
			"Czech" : " Ahoj ",
			"Danish" : " Hej ",
			"German" : " Hallo ",
			"Greek" : "  ",
			"English" : " Please take a seat in the waiting room ",
			"Spanish" : " Hola ",
			"Finnish" : " Hei ",
			"French" : " Bonjour ",
			"Italian" : " Ciao ",
			"Japanese" : " こんにちは ",
			"Korean" : " 안녕하세요 ",
			"Dutch" : " Hallo ",
			"Norwegian" : "  ",
			"Polish" : " Cześć ",
			"Brazilian" : " Olá ",
			"Portuguese" : " Olá ",
			"Russian" : " Привет ",
			"Swedish" : " Hallå ",
			"Turkish" : " Merhaba ",
			"Chinese" : "  "
		}

	def onInput_onStart(self):
		sDefaultLang = self.tts.getLanguage()
		self.onStopped(self.sentences[sDefaultLang])]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <![CDATA[]]>
</arabic>
                                                    <czech>
                                                        <![CDATA[Ahoj]]>
</czech>
                                                    <danish>
                                                        <![CDATA[Hej]]>
</danish>
                                                    <german>
                                                        <![CDATA[Hallo]]>
</german>
                                                    <greek>
                                                        <![CDATA[]]>
</greek>
                                                    <english>
                                                        <![CDATA[Please take a seat in the waiting room]]>
</english>
                                                    <spanish>
                                                        <![CDATA[Hola]]>
</spanish>
                                                    <finnish>
                                                        <![CDATA[Hei]]>
</finnish>
                                                    <french>
                                                        <![CDATA[Bonjour]]>
</french>
                                                    <italian>
                                                        <![CDATA[Ciao]]>
</italian>
                                                    <japanese>
                                                        <![CDATA[こんにちは]]>
</japanese>
                                                    <korean>
                                                        <![CDATA[안녕하세요]]>
</korean>
                                                    <dutch>
                                                        <![CDATA[Hallo]]>
</dutch>
                                                    <norwegian>
                                                        <![CDATA[]]>
</norwegian>
                                                    <polish>
                                                        <![CDATA[Cześć]]>
</polish>
                                                    <brazilian>
                                                        <![CDATA[Olá]]>
</brazilian>
                                                    <portuguese>
                                                        <![CDATA[Olá]]>
</portuguese>
                                                    <russian>
                                                        <![CDATA[Привет]]>
</russian>
                                                    <swedish>
                                                        <![CDATA[Hallå]]>
</swedish>
                                                    <turkish>
                                                        <![CDATA[Merhaba]]>
</turkish>
                                                    <chinese>
                                                        <![CDATA[]]>
</chinese>
                                                    <language>9</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Data is sent on the output when this input is stimulated." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Data sent when asked." id="3" />
                                            </Box>
                                            <Link inputowner="0" indexofinput="4" outputowner="2" indexofoutput="4" />
                                            <Link inputowner="5" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="2" indexofinput="2" outputowner="5" indexofoutput="3" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="How to make appointment online" id="31" localization="8" tooltip="Nao gives user information on how to make appointment online " x="1366" y="815">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean." id="6" />
                            <Parameter name="Body language mode" inherits_from_parent="0" content_type="3" value="contextual" default_value="contextual" custom_choice="0" tooltip="Change the body language mode during the speech.&#x0A;disabled: The robot will only play the animations given by the user. ex: ^start(...) or ^tag(...)&#x0A;random: During time the robot has no animation to play, he will launch random neutral animations.&#x0A;contextual: During time the robot has no animation to play, he will try to launch a new one accordingly to the saying text. Every time the robot can&apos;t find a contextual animation he will launch a random neutral animation." id="7">
                                <Choice value="disabled" />
                                <Choice value="random" />
                                <Choice value="contextual" />
                            </Parameter>
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Animated Say Text" id="2" localization="8" tooltip="Say the text received on its input and move during its speech." x="422" y="65">
                                                <bitmap>media/images/box/interaction/say.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.animSpeech = ALProxy('ALAnimatedSpeech')

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.animSpeech.stop(id)
            except:
                pass

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            configuration =\
            {"bodyLanguageMode":self.getParameter("Body language mode")}
            id = self.animSpeech.post.say(str(sentence), configuration)
            self.ids.append(id)
            self.animSpeech.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                                                <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                                                <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                                                <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                                                <Parameter name="Body language mode" inherits_from_parent="1" content_type="3" value="contextual" default_value="contextual" custom_choice="0" tooltip="Change the body language mode during the speech.&#x0A;disabled: The robot will only play the animations given by the user. ex: ^start(...) or ^tag(...)&#x0A;random: During time the robot has no animation to play, he will launch random neutral animations.&#x0A;contextual: During time the robot has no animation to play, he will try to launch a new one accordingly to the saying text. Every time the robot can&apos;t find a contextual animation he will launch a random neutral animation." id="7">
                                                    <Choice value="disabled" />
                                                    <Choice value="random" />
                                                    <Choice value="contextual" />
                                                </Parameter>
                                            </Box>
                                            <Box name="Localized Text" id="5" localization="8" tooltip="Send on the output the text associated with the robot&apos;s current voice language.&#x0A;You can display and edit the text associated with any language by&#x0A;selecting the language in the combobox.&#x0A;&#x0A;!!Warning!! The text sent on the output is NOT the displayed one but the one&#x0A;associated with the robot&apos;s current voice language." plugin="localizationbox_plugin" x="114" y="68">
                                                <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		try: # disable autoBind
			GeneratedClass.__init__(self, False)
		except TypeError: # if NAOqi < 1.14
			GeneratedClass.__init__( self )

		self.tts = ALProxy("ALTextToSpeech")
		self.sentences = {
			"Arabic" : "  ",
			"Czech" : " ^start(animations/Stand/Gestures/Hey_1) Ahoj ^wait(animations/Stand/Gestures/Hey_1) ",
			"Danish" : " ^start(animations/Stand/Gestures/Hey_1) Hej ^wait(animations/Stand/Gestures/Hey_1) ",
			"German" : " ^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1) ",
			"Greek" : "  ",
			"English" : " Please visit our website for more information on booking an appointment ",
			"Spanish" : " ^start(animations/Stand/Gestures/Hey_1) Hola ^wait(animations/Stand/Gestures/Hey_1) ",
			"Finnish" : " ^start(animations/Stand/Gestures/Hey_1) Hei ^wait(animations/Stand/Gestures/Hey_1) ",
			"French" : " ^start(animations/Stand/Gestures/Hey_1) Bonjour ^wait(animations/Stand/Gestures/Hey_1) ",
			"Italian" : " ^start(animations/Stand/Gestures/Hey_1) Ciao ^wait(animations/Stand/Gestures/Hey_1) ",
			"Japanese" : " ^start(animations/Stand/Gestures/Hey_1) こんにちは ^wait(animations/Stand/Gestures/Hey_1) ",
			"Korean" : " ^start(animations/Stand/Gestures/Hey_1) 안녕하세요 ^wait(animations/Stand/Gestures/Hey_1) ",
			"Dutch" : " ^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1) ",
			"Norwegian" : "  ",
			"Polish" : " ^start(animations/Stand/Gestures/Hey_1) Cześć ^wait(animations/Stand/Gestures/Hey_1) ",
			"Brazilian" : " ^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1) ",
			"Portuguese" : " ^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1) ",
			"Russian" : " ^start(animations/Stand/Gestures/Hey_1) Привет ^wait(animations/Stand/Gestures/Hey_1) ",
			"Swedish" : " ^start(animations/Stand/Gestures/Hey_1) Hallå ^wait(animations/Stand/Gestures/Hey_1) ",
			"Turkish" : " ^start(animations/Stand/Gestures/Hey_1) Merhaba ^wait(animations/Stand/Gestures/Hey_1) ",
			"Chinese" : "  "
		}

	def onInput_onStart(self):
		sDefaultLang = self.tts.getLanguage()
		self.onStopped(self.sentences[sDefaultLang])]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <![CDATA[]]>
</arabic>
                                                    <czech>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Ahoj ^wait(animations/Stand/Gestures/Hey_1)]]>
</czech>
                                                    <danish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hej ^wait(animations/Stand/Gestures/Hey_1)]]>
</danish>
                                                    <german>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1)]]>
</german>
                                                    <greek>
                                                        <![CDATA[]]>
</greek>
                                                    <english>
                                                        <![CDATA[Please visit our website for more information on booking an appointment]]>
</english>
                                                    <spanish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hola ^wait(animations/Stand/Gestures/Hey_1)]]>
</spanish>
                                                    <finnish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hei ^wait(animations/Stand/Gestures/Hey_1)]]>
</finnish>
                                                    <french>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Bonjour ^wait(animations/Stand/Gestures/Hey_1)]]>
</french>
                                                    <italian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Ciao ^wait(animations/Stand/Gestures/Hey_1)]]>
</italian>
                                                    <japanese>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) こんにちは ^wait(animations/Stand/Gestures/Hey_1)]]>
</japanese>
                                                    <korean>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) 안녕하세요 ^wait(animations/Stand/Gestures/Hey_1)]]>
</korean>
                                                    <dutch>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1)]]>
</dutch>
                                                    <norwegian>
                                                        <![CDATA[]]>
</norwegian>
                                                    <polish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Cześć ^wait(animations/Stand/Gestures/Hey_1)]]>
</polish>
                                                    <brazilian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1)]]>
</brazilian>
                                                    <portuguese>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1)]]>
</portuguese>
                                                    <russian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Привет ^wait(animations/Stand/Gestures/Hey_1)]]>
</russian>
                                                    <swedish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallå ^wait(animations/Stand/Gestures/Hey_1)]]>
</swedish>
                                                    <turkish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Merhaba ^wait(animations/Stand/Gestures/Hey_1)]]>
</turkish>
                                                    <chinese>
                                                        <![CDATA[]]>
</chinese>
                                                    <language>9</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Data is sent on the output when this input is stimulated." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Data sent when asked." id="3" />
                                            </Box>
                                            <Link inputowner="0" indexofinput="4" outputowner="2" indexofoutput="4" />
                                            <Link inputowner="5" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="2" indexofinput="2" outputowner="5" indexofoutput="3" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Appointment date" id="32" localization="8" tooltip="Nao asks user their prefered appointment time" x="1547" y="462">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean." id="6" />
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Say Text" id="2" localization="8" tooltip="Say the text received on its input." x="422" y="65">
                                                <bitmap>media/images/box/interaction/say.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.tts = ALProxy('ALTextToSpeech')
        self.ttsStop = ALProxy('ALTextToSpeech', True) #Create another proxy as wait is blocking if audioout is remote

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            id = self.tts.post.say(str(sentence))
            self.ids.append(id)
            self.tts.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                                                <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                                                <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                                                <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                                            </Box>
                                            <Box name="Localized Text" id="5" localization="8" tooltip="Send on the output the text associated with the robot&apos;s current voice language.&#x0A;You can display and edit the text associated with any language by&#x0A;selecting the language in the combobox.&#x0A;&#x0A;!!Warning!! The text sent on the output is NOT the displayed one but the one&#x0A;associated with the robot&apos;s current voice language." plugin="localizationbox_plugin" x="114" y="68">
                                                <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		try: # disable autoBind
			GeneratedClass.__init__(self, False)
		except TypeError: # if NAOqi < 1.14
			GeneratedClass.__init__( self )

		self.tts = ALProxy("ALTextToSpeech")
		self.sentences = {
			"Arabic" : "  ",
			"Czech" : " Ahoj ",
			"Danish" : " Hej ",
			"German" : " Hallo ",
			"Greek" : "  ",
			"English" : " Please let me know the time and date you would like your appointment. ",
			"Spanish" : " Hola ",
			"Finnish" : " Hei ",
			"French" : " Bonjour ",
			"Italian" : " Ciao ",
			"Japanese" : " こんにちは ",
			"Korean" : " 안녕하세요 ",
			"Dutch" : " Hallo ",
			"Norwegian" : "  ",
			"Polish" : " Cześć ",
			"Brazilian" : " Olá ",
			"Portuguese" : " Olá ",
			"Russian" : " Привет ",
			"Swedish" : " Hallå ",
			"Turkish" : " Merhaba ",
			"Chinese" : "  "
		}

	def onInput_onStart(self):
		sDefaultLang = self.tts.getLanguage()
		self.onStopped(self.sentences[sDefaultLang])]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <![CDATA[]]>
</arabic>
                                                    <czech>
                                                        <![CDATA[Ahoj]]>
</czech>
                                                    <danish>
                                                        <![CDATA[Hej]]>
</danish>
                                                    <german>
                                                        <![CDATA[Hallo]]>
</german>
                                                    <greek>
                                                        <![CDATA[]]>
</greek>
                                                    <english>
                                                        <![CDATA[Please let me know the time and date you would like your appointment.]]>
</english>
                                                    <spanish>
                                                        <![CDATA[Hola]]>
</spanish>
                                                    <finnish>
                                                        <![CDATA[Hei]]>
</finnish>
                                                    <french>
                                                        <![CDATA[Bonjour]]>
</french>
                                                    <italian>
                                                        <![CDATA[Ciao]]>
</italian>
                                                    <japanese>
                                                        <![CDATA[こんにちは]]>
</japanese>
                                                    <korean>
                                                        <![CDATA[안녕하세요]]>
</korean>
                                                    <dutch>
                                                        <![CDATA[Hallo]]>
</dutch>
                                                    <norwegian>
                                                        <![CDATA[]]>
</norwegian>
                                                    <polish>
                                                        <![CDATA[Cześć]]>
</polish>
                                                    <brazilian>
                                                        <![CDATA[Olá]]>
</brazilian>
                                                    <portuguese>
                                                        <![CDATA[Olá]]>
</portuguese>
                                                    <russian>
                                                        <![CDATA[Привет]]>
</russian>
                                                    <swedish>
                                                        <![CDATA[Hallå]]>
</swedish>
                                                    <turkish>
                                                        <![CDATA[Merhaba]]>
</turkish>
                                                    <chinese>
                                                        <![CDATA[]]>
</chinese>
                                                    <language>5</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Data is sent on the output when this input is stimulated." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Data sent when asked." id="3" />
                                            </Box>
                                            <Link inputowner="0" indexofinput="4" outputowner="2" indexofoutput="4" />
                                            <Link inputowner="5" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="2" indexofinput="2" outputowner="5" indexofoutput="3" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Email address" id="33" localization="8" tooltip="Nao asks user their email address " x="1769" y="646">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean." id="6" />
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Say Text" id="2" localization="8" tooltip="Say the text received on its input." x="422" y="65">
                                                <bitmap>media/images/box/interaction/say.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.tts = ALProxy('ALTextToSpeech')
        self.ttsStop = ALProxy('ALTextToSpeech', True) #Create another proxy as wait is blocking if audioout is remote

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            id = self.tts.post.say(str(sentence))
            self.ids.append(id)
            self.tts.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                                                <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                                                <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                                                <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                                            </Box>
                                            <Box name="Localized Text" id="5" localization="8" tooltip="Send on the output the text associated with the robot&apos;s current voice language.&#x0A;You can display and edit the text associated with any language by&#x0A;selecting the language in the combobox.&#x0A;&#x0A;!!Warning!! The text sent on the output is NOT the displayed one but the one&#x0A;associated with the robot&apos;s current voice language." plugin="localizationbox_plugin" x="114" y="68">
                                                <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		try: # disable autoBind
			GeneratedClass.__init__(self, False)
		except TypeError: # if NAOqi < 1.14
			GeneratedClass.__init__( self )

		self.tts = ALProxy("ALTextToSpeech")
		self.sentences = {
			"Arabic" : "  ",
			"Czech" : " Ahoj ",
			"Danish" : " Hej ",
			"German" : " Hallo ",
			"Greek" : "  ",
			"English" : " What is your email address  ",
			"Spanish" : " Hola ",
			"Finnish" : " Hei ",
			"French" : " Bonjour ",
			"Italian" : " Ciao ",
			"Japanese" : " こんにちは ",
			"Korean" : " 안녕하세요 ",
			"Dutch" : " Hallo ",
			"Norwegian" : "  ",
			"Polish" : " Cześć ",
			"Brazilian" : " Olá ",
			"Portuguese" : " Olá ",
			"Russian" : " Привет ",
			"Swedish" : " Hallå ",
			"Turkish" : " Merhaba ",
			"Chinese" : "  "
		}

	def onInput_onStart(self):
		sDefaultLang = self.tts.getLanguage()
		self.onStopped(self.sentences[sDefaultLang])]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <![CDATA[]]>
</arabic>
                                                    <czech>
                                                        <![CDATA[Ahoj]]>
</czech>
                                                    <danish>
                                                        <![CDATA[Hej]]>
</danish>
                                                    <german>
                                                        <![CDATA[Hallo]]>
</german>
                                                    <greek>
                                                        <![CDATA[]]>
</greek>
                                                    <english>
                                                        <![CDATA[What is your email address ]]>
</english>
                                                    <spanish>
                                                        <![CDATA[Hola]]>
</spanish>
                                                    <finnish>
                                                        <![CDATA[Hei]]>
</finnish>
                                                    <french>
                                                        <![CDATA[Bonjour]]>
</french>
                                                    <italian>
                                                        <![CDATA[Ciao]]>
</italian>
                                                    <japanese>
                                                        <![CDATA[こんにちは]]>
</japanese>
                                                    <korean>
                                                        <![CDATA[안녕하세요]]>
</korean>
                                                    <dutch>
                                                        <![CDATA[Hallo]]>
</dutch>
                                                    <norwegian>
                                                        <![CDATA[]]>
</norwegian>
                                                    <polish>
                                                        <![CDATA[Cześć]]>
</polish>
                                                    <brazilian>
                                                        <![CDATA[Olá]]>
</brazilian>
                                                    <portuguese>
                                                        <![CDATA[Olá]]>
</portuguese>
                                                    <russian>
                                                        <![CDATA[Привет]]>
</russian>
                                                    <swedish>
                                                        <![CDATA[Hallå]]>
</swedish>
                                                    <turkish>
                                                        <![CDATA[Merhaba]]>
</turkish>
                                                    <chinese>
                                                        <![CDATA[]]>
</chinese>
                                                    <language>9</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Data is sent on the output when this input is stimulated." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Data sent when asked." id="3" />
                                            </Box>
                                            <Link inputowner="0" indexofinput="4" outputowner="2" indexofoutput="4" />
                                            <Link inputowner="5" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="2" indexofinput="2" outputowner="5" indexofoutput="3" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Send E-mail" id="34" localization="8" tooltip="Send an e-mail. Set all parameters of this e-mail before sending it.&#x0A;&#x0A;!!Warning!! The Password has to be hardcoded inside the behavior, and will not&#x0A;be encrypted or hidden. You should create an e-mail account for your robot, that&#x0A;uses a password that you are comfortable to leave un-encrypted." x="1932" y="656">
                            <bitmap>media/images/box/internet/email.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import sys, os
import smtplib, email

def mail(email_user, to, subject, text, attach, email_pwd, smtp, port):
  msg = email.MIMEMultipart.MIMEMultipart()
  msg['From'] = email_user
  msg['To'] = to
  msg['Subject'] = subject

  msg.attach(email.MIMEText.MIMEText(text))

  if attach:
     part = email.MIMEBase.MIMEBase('application', 'octet-stream')
     part.set_payload(open(attach, 'rb').read())
     email.Encoders.encode_base64(part)
     part.add_header('Content-Disposition',
             'attachment; filename="%s"' % os.path.basename(attach))
     msg.attach(part)

  if( port != "" ):
      mailServer = smtplib.SMTP(smtp, port)
  else:
      mailServer = smtplib.SMTP(smtp)
  mailServer.ehlo()
  mailServer.starttls()
  mailServer.ehlo()
  mailServer.login(email_user, email_pwd)
  mailServer.sendmail(email_user, to, msg.as_string())

  mailServer.close()

class MyClass(GeneratedClass):
  def __init__(self):
    GeneratedClass.__init__(self, False)

  def onLoad(self):
    pass

  def onUnload(self):
    #puts code for box cleanup here
    pass

  def onInput_onSend(self):
    sEmailUser = self.getParameter("From")
    aTo = self.getParameter("To").split(";")
    sSubject = self.getParameter("Subject")
    sText = self.getParameter("Contents")
    sAttachedFilePath = self.getParameter("Attachment")
    sPwd = self.getParameter("Password")
    sSmtp = self.getParameter("SMTP address")
    sPort = int( self.getParameter("Port number") )
    try:
        sPort = int( sPort )
        bValidPort = ( sPort >= 0 and sPort <= 65535 )
    except:
        bValidPort = False
    if( not bValidPort ):
        raise Exception( str(sPort) + " is not a valid port number to use to send e-mail. It must be an integer between 0 and 65535. Please check that the port parameter of the box is correct." )
    for address in aTo:
      try:
        mail(
          sEmailUser,
          address,
          sSubject,
          sText,
          sAttachedFilePath,
          sPwd,
          sSmtp,
          sPort)
      except smtplib.SMTPAuthenticationError as e:
        raise(Exception("Authentication error, server answered : [%s] %s" % (e.smtp_code, e.smtp_error)))


    self.onSent() # activate output of the box]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onSend" type="1" type_size="1" nature="1" inner="0" tooltip="Send the e-mail." id="2" />
                            <Output name="onSent" type="1" type_size="1" nature="2" inner="0" tooltip="E-mail sent." id="3" />
                            <Output name="onError" type="3" type_size="1" nature="2" inner="0" tooltip="" id="4" />
                            <Parameter name="From" inherits_from_parent="0" content_type="3" value="myemail@email.com" default_value="myemail@email.com" custom_choice="0" tooltip="E-mail address of the sender." id="5" />
                            <Parameter name="Password" inherits_from_parent="0" content_type="3" value="" default_value="" custom_choice="0" password="1" tooltip="Password of your e-mail account." id="6" />
                            <Parameter name="To" inherits_from_parent="0" content_type="3" value="to@email.com" default_value="to@email.com" custom_choice="0" tooltip="Receiver(s) of the e-mail. Separate e-mail addresses by &apos;;&apos;." id="7" />
                            <Parameter name="Subject" inherits_from_parent="0" content_type="3" value="" default_value="" custom_choice="0" tooltip="Subject of the e-mail." id="8" />
                            <Parameter name="Contents" inherits_from_parent="0" content_type="3" value="" default_value="" custom_choice="0" tooltip="Contents of the e-mail." id="9" />
                            <Parameter name="Attachment" inherits_from_parent="0" content_type="3" value="" default_value="" custom_choice="0" tooltip="Attachment path." id="10" />
                            <Parameter name="SMTP address" inherits_from_parent="0" content_type="3" value="smtp.email.com" default_value="smtp.email.com" custom_choice="0" tooltip="SMTP server this box is supposed to use." id="11" />
                            <Parameter name="Port number" inherits_from_parent="0" content_type="3" value="587" default_value="587" custom_choice="1" tooltip="Port of the server to use.&#x0A;&#x0A;Note: For example, for a gmail address to use TLS/STARTTLS you need to set the&#x0A;port to 587, and to use SSL you need to set it to 465." id="12">
                                <Choice value="587" />
                                <Choice value="465" />
                            </Parameter>
                        </Box>
                        <Box name="Email conformation " id="35" localization="8" tooltip="Nao confirms that the email has sent " x="2134" y="665">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean." id="6" />
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Say Text" id="2" localization="8" tooltip="Say the text received on its input." x="422" y="65">
                                                <bitmap>media/images/box/interaction/say.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.tts = ALProxy('ALTextToSpeech')
        self.ttsStop = ALProxy('ALTextToSpeech', True) #Create another proxy as wait is blocking if audioout is remote

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            id = self.tts.post.say(str(sentence))
            self.ids.append(id)
            self.tts.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                                                <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                                                <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                                                <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                                            </Box>
                                            <Box name="Localized Text" id="5" localization="8" tooltip="Send on the output the text associated with the robot&apos;s current voice language.&#x0A;You can display and edit the text associated with any language by&#x0A;selecting the language in the combobox.&#x0A;&#x0A;!!Warning!! The text sent on the output is NOT the displayed one but the one&#x0A;associated with the robot&apos;s current voice language." plugin="localizationbox_plugin" x="114" y="68">
                                                <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		try: # disable autoBind
			GeneratedClass.__init__(self, False)
		except TypeError: # if NAOqi < 1.14
			GeneratedClass.__init__( self )

		self.tts = ALProxy("ALTextToSpeech")
		self.sentences = {
			"Arabic" : "  ",
			"Czech" : " Ahoj ",
			"Danish" : " Hej ",
			"German" : " Hallo ",
			"Greek" : "  ",
			"English" : " Email sent  ",
			"Spanish" : " Hola ",
			"Finnish" : " Hei ",
			"French" : " Bonjour ",
			"Italian" : " Ciao ",
			"Japanese" : " こんにちは ",
			"Korean" : " 안녕하세요 ",
			"Dutch" : " Hallo ",
			"Norwegian" : "  ",
			"Polish" : " Cześć ",
			"Brazilian" : " Olá ",
			"Portuguese" : " Olá ",
			"Russian" : " Привет ",
			"Swedish" : " Hallå ",
			"Turkish" : " Merhaba ",
			"Chinese" : "  "
		}

	def onInput_onStart(self):
		sDefaultLang = self.tts.getLanguage()
		self.onStopped(self.sentences[sDefaultLang])]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <![CDATA[]]>
</arabic>
                                                    <czech>
                                                        <![CDATA[Ahoj]]>
</czech>
                                                    <danish>
                                                        <![CDATA[Hej]]>
</danish>
                                                    <german>
                                                        <![CDATA[Hallo]]>
</german>
                                                    <greek>
                                                        <![CDATA[]]>
</greek>
                                                    <english>
                                                        <![CDATA[Email sent ]]>
</english>
                                                    <spanish>
                                                        <![CDATA[Hola]]>
</spanish>
                                                    <finnish>
                                                        <![CDATA[Hei]]>
</finnish>
                                                    <french>
                                                        <![CDATA[Bonjour]]>
</french>
                                                    <italian>
                                                        <![CDATA[Ciao]]>
</italian>
                                                    <japanese>
                                                        <![CDATA[こんにちは]]>
</japanese>
                                                    <korean>
                                                        <![CDATA[안녕하세요]]>
</korean>
                                                    <dutch>
                                                        <![CDATA[Hallo]]>
</dutch>
                                                    <norwegian>
                                                        <![CDATA[]]>
</norwegian>
                                                    <polish>
                                                        <![CDATA[Cześć]]>
</polish>
                                                    <brazilian>
                                                        <![CDATA[Olá]]>
</brazilian>
                                                    <portuguese>
                                                        <![CDATA[Olá]]>
</portuguese>
                                                    <russian>
                                                        <![CDATA[Привет]]>
</russian>
                                                    <swedish>
                                                        <![CDATA[Hallå]]>
</swedish>
                                                    <turkish>
                                                        <![CDATA[Merhaba]]>
</turkish>
                                                    <chinese>
                                                        <![CDATA[]]>
</chinese>
                                                    <language>9</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Data is sent on the output when this input is stimulated." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Data sent when asked." id="3" />
                                            </Box>
                                            <Link inputowner="0" indexofinput="4" outputowner="2" indexofoutput="4" />
                                            <Link inputowner="5" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="2" indexofinput="2" outputowner="5" indexofoutput="3" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Blink (3)" id="36" localization="8" tooltip="This box makes the robot blink once." x="1905" y="428">
                            <bitmap>media/images/box/interaction/LED.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.leds = ALProxy("ALLeds")

    def onUnload(self):
        #~ puts code for box cleanup here
        pass

    def onInput_onStart(self):
        rDuration = 0.05
        self.leds.post.fadeRGB( "FaceLed0", 0x000000, rDuration )
        self.leds.post.fadeRGB( "FaceLed1", 0x000000, rDuration )
        self.leds.post.fadeRGB( "FaceLed2", 0xffffff, rDuration )
        self.leds.post.fadeRGB( "FaceLed3", 0x000000, rDuration )
        self.leds.post.fadeRGB( "FaceLed4", 0x000000, rDuration )
        self.leds.post.fadeRGB( "FaceLed5", 0x000000, rDuration )
        self.leds.post.fadeRGB( "FaceLed6", 0xffffff, rDuration )
        self.leds.fadeRGB( "FaceLed7", 0x000000, rDuration )
        time.sleep( 0.1 )
        self.leds.fadeRGB( "FaceLeds", 0xffffff, rDuration )
        self.onDone()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Output name="onDone" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="3" />
                        </Box>
                        <Box name="Tactile R.Hand" id="8" localization="8" tooltip="Detect touch on right hand tactile sensor." x="820" y="181">
                            <bitmap>media/images/box/movement/move_arm.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload() #~ it is usually a good idea to call onUnload of this box in a onStop method, as the code written in onUnload is used to finish the working of the box as well
            self.onStopped() #~ activate output of the box
        pass]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Input name="HRLeftTouched" type="0" type_size="1" nature="4" stm_value_name="HandRightLeftTouched" inner="1" tooltip="Connected to ALMemory. Will be stimulated every time the value subscribed to changes, respecting the refresh period." id="4" />
                            <Input name="HRBackTouched" type="0" type_size="1" nature="4" stm_value_name="HandRightBackTouched" inner="1" tooltip="Connected to ALMemory. Will be stimulated every time the value subscribed to changes, respecting the refresh period." id="5" />
                            <Input name="HRRightTouched" type="0" type_size="1" nature="4" stm_value_name="HandRightRightTouched" inner="1" tooltip="Connected to ALMemory. Will be stimulated every time the value subscribed to changes, respecting the refresh period." id="6" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is stopped." id="7" />
                            <Output name="backTouched" type="1" type_size="1" nature="2" inner="0" tooltip="The back of the right hand was touched." id="8" />
                            <Output name="leftTouched" type="1" type_size="1" nature="2" inner="0" tooltip="The left of the right hand was touched." id="9" />
                            <Output name="rightTouched" type="1" type_size="1" nature="2" inner="0" tooltip="The right of the right hand was touched." id="10" />
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="if &gt; 0" id="1" localization="8" tooltip="Transmit only if value is &gt; 0." x="157" y="130">
                                                <bitmap>media/images/box/box-diagram.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        #~ puts code for box initialization here
        pass

    def onUnload(self):
        #~ puts code for box cleanup here
        pass

    def onInput_onStart(self, p):
        if(p > 0):
            self.onStopped() #~ activate output of the box
        pass

    def onInput_onStop(self):
        self.onUnload() #~ it is usually a good idea to call onUnload of this box in a onStop method, as the code written in onUnload is used to finish the working of the box as well
        pass]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="0" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
                                            </Box>
                                            <Box name="if &gt; 0" id="2" localization="8" tooltip="Transmit only if value is &gt; 0." x="157" y="28">
                                                <bitmap>media/images/box/box-diagram.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        #~ puts code for box initialization here
        pass

    def onUnload(self):
        #~ puts code for box cleanup here
        pass

    def onInput_onStart(self, p):
        if(p > 0):
            self.onStopped() #~ activate output of the box
        pass

    def onInput_onStop(self):
        self.onUnload() #~ it is usually a good idea to call onUnload of this box in a onStop method, as the code written in onUnload is used to finish the working of the box as well
        pass]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="0" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
                                            </Box>
                                            <Box name="if &gt; 0" id="3" localization="8" tooltip="Transmit only if value is &gt; 0." x="157" y="232">
                                                <bitmap>media/images/box/box-diagram.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        #~ puts code for box initialization here
        pass

    def onUnload(self):
        #~ puts code for box cleanup here
        pass

    def onInput_onStart(self, p):
        if(p > 0):
            self.onStopped() #~ activate output of the box
        pass

    def onInput_onStop(self):
        self.onUnload() #~ it is usually a good idea to call onUnload of this box in a onStop method, as the code written in onUnload is used to finish the working of the box as well
        pass]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="0" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
                                            </Box>
                                            <Link inputowner="1" indexofinput="2" outputowner="0" indexofoutput="5" />
                                            <Link inputowner="0" indexofinput="8" outputowner="1" indexofoutput="4" />
                                            <Link inputowner="2" indexofinput="2" outputowner="0" indexofoutput="4" />
                                            <Link inputowner="0" indexofinput="9" outputowner="2" indexofoutput="4" />
                                            <Link inputowner="3" indexofinput="2" outputowner="0" indexofoutput="6" />
                                            <Link inputowner="0" indexofinput="10" outputowner="3" indexofoutput="4" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Right arm-sequence" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Sit Down" id="37" localization="8" tooltip="the robot tries to sit down from any position for a number of tries.&#x0A;&#x0A;Note: The number of tries can be set in parameters." x="1076" y="1102">
                            <bitmap>media/images/box/movement/sit_ground.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Output name="success" type="1" type_size="1" nature="1" inner="0" tooltip="Stimulated when the robot succeed in sitting down." id="4" />
                            <Output name="failure" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when the robot failed to sit down after n tries.&#x0A;&#x0A;Note: The number of tries can be set in parameters." id="5" />
                            <Timeline enable="0">
                                <BehaviorLayer name="SitDownBehavior">
                                    <BehaviorKeyframe name="DetectRobotPose" index="1">
                                        <Diagram>
                                            <Box name="Goto Posture" id="7" localization="8" tooltip="The robot goes from its current postition to the asked posture." x="371" y="101">
                                                <bitmap>media/images/box/box-diagram.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.postureProxy = ALProxy("ALRobotPosture")
        pass

    def onUnload(self):
        self.postureProxy.stopMove()

    def onInput_onStart(self):
        result = self.postureProxy.goToPosture(self.getParameter("Name"), self.getParameter("Speed (%)")/100.)
        if(result):
            self.success()
        else:
            self.failure()
        pass

    def onInput_onStop(self):
        self.onUnload() #~ it is recommanded to call onUnload of this box in a onStop method, as the code written in onUnload is used to stop the box as well
        pass]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                                                <Output name="success" type="1" type_size="1" nature="1" inner="0" tooltip="Stimulated if the posture has been reached." id="4" />
                                                <Output name="failure" type="1" type_size="1" nature="1" inner="0" tooltip="Stimulated if the posture could not be reached." id="5" />
                                                <Parameter name="Name" inherits_from_parent="0" content_type="3" value="Sit" default_value="Sit" custom_choice="1" tooltip="Name of the posture to go to." id="6">
                                                    <Choice value="Crouch" />
                                                    <Choice value="LyingBack" />
                                                    <Choice value="LyingBelly" />
                                                    <Choice value="Sit" />
                                                    <Choice value="SitRelax" />
                                                    <Choice value="StandInit" />
                                                    <Choice value="Stand" />
                                                    <Choice value="StandZero" />
                                                </Parameter>
                                                <Parameter name="Speed (%)" inherits_from_parent="0" content_type="1" value="80" default_value="100" min="0" max="100" tooltip="Speed to go to the posture." id="7" />
                                                <Resource name="All motors" type="Lock" timeout="0" />
                                                <Resource name="Stiffness" type="Lock" timeout="0" />
                                            </Box>
                                            <Link inputowner="7" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="0" indexofinput="4" outputowner="7" indexofoutput="4" />
                                            <Link inputowner="0" indexofinput="5" outputowner="7" indexofoutput="5" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="All motors" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Tactile L.Hand" id="57" localization="8" tooltip="Detect touch on left hand tactile sensor." x="216" y="572">
                            <bitmap>media/images/box/movement/move_leftarm.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload() #~ it is usually a good idea to call onUnload of this box in a onStop method, as the code written in onUnload is used to finish the working of the box as well
            self.onStopped() #~ activate output of the box
        pass]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Input name="HLLeftTouched" type="0" type_size="1" nature="4" stm_value_name="HandLeftLeftTouched" inner="1" tooltip="Connected to ALMemory. Will be stimulated every time the value subscribed to changes, respecting the refresh period." id="4" />
                            <Input name="HLBackTouched" type="0" type_size="1" nature="4" stm_value_name="HandLeftBackTouched" inner="1" tooltip="Connected to ALMemory. Will be stimulated every time the value subscribed to changes, respecting the refresh period." id="5" />
                            <Input name="HLRightTouched" type="0" type_size="1" nature="4" stm_value_name="HandLeftRightTouched" inner="1" tooltip="Connected to ALMemory. Will be stimulated every time the value subscribed to changes, respecting the refresh period." id="6" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is stopped." id="7" />
                            <Output name="backTouched" type="1" type_size="1" nature="2" inner="0" tooltip="The back of the left hand was touched." id="8" />
                            <Output name="leftTouched" type="1" type_size="1" nature="2" inner="0" tooltip="The left of the left hand was touched." id="9" />
                            <Output name="rightTouched" type="1" type_size="1" nature="2" inner="0" tooltip="The right of the left hand was touched." id="10" />
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="if &gt; 0" id="1" localization="8" tooltip="Transmit only if value is &gt; 0." x="171" y="142">
                                                <bitmap>media/images/box/box-diagram.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        #~ puts code for box initialization here
        pass

    def onUnload(self):
        #~ puts code for box cleanup here
        pass

    def onInput_onStart(self, p):
        if(p > 0):
            self.onStopped() #~ activate output of the box
        pass

    def onInput_onStop(self):
        self.onUnload() #~ it is usually a good idea to call onUnload of this box in a onStop method, as the code written in onUnload is used to finish the working of the box as well
        pass]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="0" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
                                            </Box>
                                            <Box name="if &gt; 0" id="2" localization="8" tooltip="Transmit only if value is &gt; 0." x="171" y="39">
                                                <bitmap>media/images/box/box-diagram.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        #~ puts code for box initialization here
        pass

    def onUnload(self):
        #~ puts code for box cleanup here
        pass

    def onInput_onStart(self, p):
        if(p > 0):
            self.onStopped() #~ activate output of the box
        pass

    def onInput_onStop(self):
        self.onUnload() #~ it is usually a good idea to call onUnload of this box in a onStop method, as the code written in onUnload is used to finish the working of the box as well
        pass]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="0" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
                                            </Box>
                                            <Box name="if &gt; 0" id="3" localization="8" tooltip="Transmit only if value is &gt; 0." x="171" y="246">
                                                <bitmap>media/images/box/box-diagram.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        #~ puts code for box initialization here
        pass

    def onUnload(self):
        #~ puts code for box cleanup here
        pass

    def onInput_onStart(self, p):
        if(p > 0):
            self.onStopped() #~ activate output of the box
        pass

    def onInput_onStop(self):
        self.onUnload() #~ it is usually a good idea to call onUnload of this box in a onStop method, as the code written in onUnload is used to finish the working of the box as well
        pass]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="0" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
                                            </Box>
                                            <Link inputowner="1" indexofinput="2" outputowner="0" indexofoutput="5" />
                                            <Link inputowner="0" indexofinput="8" outputowner="1" indexofoutput="4" />
                                            <Link inputowner="2" indexofinput="2" outputowner="0" indexofoutput="4" />
                                            <Link inputowner="0" indexofinput="9" outputowner="2" indexofoutput="4" />
                                            <Link inputowner="3" indexofinput="2" outputowner="0" indexofoutput="6" />
                                            <Link inputowner="0" indexofinput="10" outputowner="3" indexofoutput="4" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Left arm-sequence" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Choice (light)" id="30" localization="8" tooltip="Launch speech recognition, and wait for one of a defined number of expected answers (written in the table of the box). the robot will prompt the speaker if he cannot understand and give suggestions as to available answers and other ways of selecting your choice. e.g. The tactile sensor on his head.&#x0A;&#x0A;Note that you must open this box to enter the question text and the available answers.&#x0A;&#x0A;This is a lighter version of Choice box from standard library which has no animation embedded.&#x0A;&#x0A;V1.1.0&#x0A;" x="1379" y="677">
                            <bitmap>media/images/box/interaction/choice.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                            <Output name="answer" type="3" type_size="1" nature="1" inner="0" tooltip="Answer recognized." id="5" />
                            <Output name="yes" type="1" type_size="1" nature="1" inner="0" tooltip="" id="6" />
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Choice" id="1" localization="8" tooltip="Launch the speech recognition waiting for a defined number of predicted answers (written in the table on the box). Available help&#x0A;from the robot which gives some possible answers and attracts attention on the other modalities to answer (head tactile sensor).&#x0A;&#x0A;You can edit a choice by left double-clicking on the line. You can add a choice by right clicking on a line and selecting &apos;Insert a&#x0A;row&apos;. You can delete a choice by right clicking on a line and selecting &apos;Remove a row&apos;. You can also write several alternative&#x0A;answers for the same choice by writing them on the line separated by the character &apos;/&apos;.&#x0A;Ex: apple pie / pie / apple&#x0A;Then if any of these answers (&apos;apple pie&apos;, &apos;pie&apos; or &apos;apple&apos;) are said, the corresponding output will be activated. Indeed, each output&#x0A;which name begins with &apos;output_&apos; correspond to the choice in the list placed just in front of the output.&#x0A;&#x0A;Moreover, you have advanced options appearing when you click on the blue cross. Then you can make the robot calculate the threshold&#x0A;average of choices with the 1/2/3 button. Actually, it will calculate recognition threshold of each alternative answer and put them from&#x0A;highest to smallest threshold. The threshold displayed in front of each choice then is the highest&apos;s." plugin="ui_choice_plugin" x="312" y="51">
                                                <bitmap>media/images/box/interaction/choice.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
# -*- coding: utf-8 -*-
# script of the Choice box v8.8
# @author Desktop Application team
# (c) 2011 Aldebaran Robotics

import os
import time
import random
import thread
import mutex
import xml.dom.minidom

class MyClass(GeneratedClass):
    def __init__(self):
        try: # disable autoBind
          GeneratedClass.__init__(self, False)
        except TypeError: # if NAOqi < 1.14
          GeneratedClass.__init__( self )

        # PROXIES INITIALIZATION
        self.tts = ALProxy("ALTextToSpeech")
        self.ttsStop = ALProxy("ALTextToSpeech", True) #Create another proxy as wait is blocking if audioout is remote
        self.memory = ALProxy("ALMemory")
        try:
            self.asr = ALProxy("ALSpeechRecognition")
            self.ad = ALProxy("ALAudioDevice")
            self.player = ALProxy("ALAudioPlayer")
            self.dcm = ALProxy( "DCM" )
        except:
            self.logger.warning("cannot find ALSpeechRecognition, choice box will run in simulation mode")
            self.asr = None
            self.ad = None
            self.player = None
            self.dcm = None

        self.leds = ALProxy( "ALLeds" )
        # VARIABLES INITIALIZATION
        self.aIdsTTS = []
        self.bSentencesInitialized = False
        self.bMustStop = False
        self.bIsRunning = False
        self.bGoOut = False
        self.nCountNoReply = 0
        self.nCountFailure = 0
        self.aFrameNumbers = {"end" : 1,
                              "headDown" : 10,
                              "bodyTalk" : 20,
                              "reco" : 30,
                              "headCheck" : 40,
                              "helpTactileSensor" : 50,
                              "notUnderstood" : 70}
        self.nFrameNumber = self.aFrameNumbers["end"]
        self.bInConfirmation = False
        self.bVocabularyLoaded = False
        self.bRecoIsHearingOrAnalysing = False
        self.bRecoIsWaitingForVoice = False
        self.bHasAlreadyHearingEyes = False
        self.bInTactileSensorMenu = False
        self.bExternChoices = False
        self.bBrainAnimPaused = False
        self.rTimeLastChoiceSaid = -1.
        self.bIsSayingChoice = False
        self.nIndexChoice = 0
        self.sRecoInterruption = "" # = "wordRecognised" or "timeout" or "onStop" or "onTactileSensor"
        self.sPreviousAnswer = ""
        self.rTimeWhenActionMadeInTactileMenu = -1.
        # variables used for the tactile sensor
        self.nFront = 0
        self.nMiddle = 0
        self.nRear = 0
        self.bSeqStarted = False
        self.bIsStoringParam = False
        self.bPressed = False
        self.mutexProcessCurrentState = mutex.mutex()
        self.mutexTactilTouched = mutex.mutex()
        self.mutexCheckIfSeqsCorrespondingLeft = mutex.mutex()
        self.bSeqStarted = False
        # assuming that every sequence is after [0, 0, 0]
        # and then start with one tactil sensor activated
        # timeout must be either a number (int or float) not equal to 0 or an array of two numbers not equal to 0, a negative one and a positive one
        # a negative timeout means a minimum time that has to ellapse before the next step
        # a positive timeout means a maximum time before the next step must show up
        self.aSeqs = [{"name" : "Tap", "statesAndTimeout" : [ "1+", 0.35, "2+", 0.45, "0" ]},
                      {"name" : "TapFront", "statesAndTimeout" : [ "F", 1, "0" ]},
                      {"name" : "LongFront", "statesAndTimeout" : [ "F", -1, "F" ]},
                      {"name" : "TapMiddle", "statesAndTimeout" : [ "M", 1, "0" ]},
                      {"name" : "LongMiddle", "statesAndTimeout" : [ "M", -1, "M" ]},
                      {"name" : "TapRear", "statesAndTimeout" : [ "R", 1, "0" ]},
                      {"name" : "LongRear", "statesAndTimeout" : [ "R", -1, "R" ]},
                      {"name" : "CalmDown", "statesAndTimeout" : [ "1+", 0.5, "2+", -1, "2+" ]}]
        # sequences initialization
        aSeqsTemp = []
        for seq in self.aSeqs:
            try: # ensure that the sequence has at least a name and states and timeout defined
                seq["name"]
                seq["statesAndTimeout"]
                aSeqsTemp.append(seq)
            except:
                pass
        self.aSeqs = aSeqsTemp
        for seq in self.aSeqs:
            states = range( len( seq["statesAndTimeout"][0:len(seq["statesAndTimeout"]):2] ) )
            i = 0
            for state in seq["statesAndTimeout"][0:len(seq["statesAndTimeout"]):2]:
                states[i] = self.convertToArrayOfPossibleStates(state)
                i += 1
            seq["statesAndTimeout"][0:len(seq["statesAndTimeout"]):2] = states
        self.aDetectedSeqs = []
        self.aDetectedSeqs.extend(self.aSeqs)
        # end - variables used for the tactile sensor
        self.aChoices = []
        self.aChoiceIndexes = []
        # parameters which can be changed from the parameters edition window
        self.sQuestion = ""
        self.nTimeoutReco = 6
        self.nTimeoutRecoConfirmation = 6
        self.nTimeoutTactile = 10
        self.nMaxCountNoReply = 3
        self.nMaxCountFailure = 5
        self.arUnderstoodThreshold = [0.0, 1.0] # range of self.rUnderstoodThreshold
        self.arConfirmationThreshold = [0.0, 1.0] # range of self.rConfirmationThreshold (must be higher than self.arUnderstoodThreshold)
        self.rUnderstoodThreshold = 0.2
        self.rConfirmationThreshold = 0.4
        self.bActivateEyesLight = True
        self.bActivateEarsLight = True
        self.bActivateBrainLight = True
        self.bActivateHelpWhenFailure = True
        self.bRepeatValidatedChoice = True
        self.bActivateDefaultChoiceHelp = True
        self.bActivateDefaultChoiceRepeat = True
        self.bActivateDefaultChoiceExit = True
        self.BIND_PYTHON(self.getName(), "onTactilTouched")
        self.BIND_PYTHON(self.getName(), "onWordRecognized")
        self.BIND_PYTHON(self.getName(), "onSpeechDetected")


# FUNCTIONS ===============================================================================================

    def onLoad(self):
        # initialize sentences for each language
        if( not self.bSentencesInitialized ):
            self.initializeSentences()
            self.bSentencesInitialized = True

# XML PARSER FOR SENTENCES INITIALIZATION
    def initializeSentences(self):
        "Initialize necessary sentences in each language."
        framemanager = ALProxy("ALFrameManager")
        filename = framemanager.getBehaviorPath(self.behaviorId) + self.tryGetParameter( "Sentences file", "/Aldebaran/choice_sentences.xml" )
        if not self.fileExists(filename):
            raise RuntimeError("File " + filename + " could not be found. Please update your Choice box with a newer one from Choregraphe")
        try:
            doc = self.getFileContents( filename )
            dom = xml.dom.minidom.parseString( doc )
        except Exception as e:
            raise Exception( "The " + filename + " file is not in the right format. Check the special characters and that the syntax is correct.\n" + str(e) )
        try:
            tag = "sentences"
            mainBlock = dom.getElementsByTagName( tag )[0]
            tag = "translation"
            aTranslations = mainBlock.getElementsByTagName( tag )
            self.aAllWords = {}
            self.aAllSentences = {}
            for sTranslation in aTranslations:
                sLanguage = sTranslation.getAttribute("language")
                tag = "speechReco"
                blockSpeechReco = sTranslation.getElementsByTagName( tag )[0]
                # variable used for the speech recognition
                self.aAllWords[sLanguage] = {}
                aKinds = ["negative",
                          "positive",
                          "help",
                          "exit",
                          "repeat"]
                for sKind in aKinds:
                    tag = sKind
                    blockWordsForThisKind = blockSpeechReco.getElementsByTagName( sKind )[0]
                    self.aAllWords[sLanguage][sKind] = blockWordsForThisKind.getAttribute( "text" ).encode("utf-8").split("/")
                # end - variable used for the speech recognition
                tag = "tts"
                blockTTS = sTranslation.getElementsByTagName( tag )[0]
                # variable used for the Text-To-Speech
                self.aAllSentences[sLanguage] = {}
                aKinds = ["confirmation",
                          "enumMarks",
                          "helpEnumChoices",
                          "helpEnumDefault",
                          "helpTactile",
                          "notUnderstood",
                          "noQuestion",
                          "notUnderstoodAnims"]
                for sKind in aKinds:
                    tag = sKind
                    blockSentencesForThisKind = blockTTS.getElementsByTagName( sKind )[0]
                    self.aAllSentences[sLanguage][sKind] = blockSentencesForThisKind.getAttribute( "text" ).encode("utf-8").split("/")
                # end - variable used for the Text-To-Speech
        except Exception as e:
            raise Exception( "The " + filename + " file is not in the right format. Check that the '" + tag + "' tag is defined and with the right format.\n" + str(e) )

        # choices
        # !!! don't remove any comments from this variable !!!
        # (they are here to make the plugin work)
        self.aListAllChoices = {"Arabic": ["نعم", "لا", "", ""], "Brazilian": ["sim", "não", "", ""], "Chinese": ["是", "不是", "", ""], "Czech": ["ano", "ne", "", ""], "Danish": ["ja", "nej", "", ""], "Dutch": ["ja", "nee", "", ""], "English": ["", "No", "Yes", ""], "Finnish": ["kyllä", "ei", "", ""], "French": ["oui", "non", "", ""], "German": ["ja", "nein", "", ""], "Greek": ["ναί", "κανένα", "", ""], "Italian": ["sì", "no", "", ""], "Japanese": ["はい", "いいえ", "", ""], "Korean": ["예", "아니", "", ""], "Norwegian": ["ja", "Nei", "", ""], "Polish": ["tak", "nie", "", ""], "Portuguese": ["sim", "não", "", ""], "Russian": ["да", "нет", "", ""], "Spanish": ["si", "no", "", ""], "Swedish": ["ja", "ingen", "", ""], "Turkish": ["evet", "hayır", "", ""]
                               }
        # end - choices

# INPUTS ACTIVATION PROCESSING ------------------------------------------------------------------------------
    def onInput_onStart(self, question=None):
        "Initialize variables and start box behaviour."
        self.logger.debug( "Input onStart stimulated." )
        if( self.bIsRunning): # to avoid starting the process twice
            return
        self.bIsRunning = True
        if(self.asr != None):
            self.asr.setVisualExpression( False )
        language = self.tts.getLanguage()
        if(self.asr != None):
            self.asr.setLanguage( language )
        try:
            self.aAllWords[language]
            self.aAllSentences[language]
        except:
            raise Exception( "The current language is not supported by this Choice box. It is probably deprecated. Try to use the one supplied in Choregraphe library instead." )
        self.asNegativeWords = self.aAllWords[language]["negative"]
        self.asPositiveWords = self.aAllWords[language]["positive"]
        self.asHelpWords = self.aAllWords[language]["help"]
        self.asExitWords = self.aAllWords[language]["exit"]
        self.asRepeatWords = self.aAllWords[language]["repeat"]
        self.bGoOut = False
        self.bVocabularyLoaded = False
        self.bRecoIsHearingOrAnalysing = False
        self.bRecoIsWaitingForVoice = False
        self.bHasAlreadyHearingEyes = False
        self.sRecoInterruption = ""
        self.sPreviousAnswer = ""
        self.bMustStop = False
        self.nCountNoReply = 0
        self.nCountFailure = 0
        self.nFrameNumber = self.aFrameNumbers["end"]
        self.beginTime = time.time()
        self.bInConfirmation = False
        self.bInTactileSensorMenu = False
        self.bBrainAnimPaused = False
        self.bPressed = False
        self.rTimeWhenActionMadeInTactileMenu = -1.
        self.nFront = 0
        self.nMiddle = 0
        self.nRear = 0
        self.bSeqStarted = False
        self.bIsStoringParam = False
        self.rUnderstoodThreshold = self.tryGetParameter( "Minimum threshold to understand", 0.2 )
        self.rConfirmationThreshold = self.tryGetParameter( "Minimum threshold to be sure", 0.4 )
        self.nTimeoutReco = self.tryGetParameter( "Speech recognition timeout", 6 )
        self.nTimeoutRecoConfirmation = self.tryGetParameter( "Speech recognition timeout when confirmation", 6 )
        self.nTimeoutTactile = self.tryGetParameter( "Tactile sensor menu timeout", 10 )
        self.nMaxCountNoReply = self.tryGetParameter( "Maximum number of repetition when no reply", 3 )
        self.nMaxCountFailure = self.tryGetParameter( "Maximum number of repetition when failure", 5 )
        self.bActivateEyesLight = self.tryGetParameter( "Activate eyes light", True )
        self.bActivateEarsLight = self.tryGetParameter( "Activate ears light", True )
        self.bActivateBrainLight = self.tryGetParameter( "Activate brain light", True )
        self.bActivateHelpWhenFailure = self.tryGetParameter( "Activate help when failure", True )
        self.bRepeatValidatedChoice = self.tryGetParameter( "Repeat validated choice", True )
        self.bActivateDefaultChoiceHelp = self.tryGetParameter( "Activate help command", True )
        self.bActivateDefaultChoiceRepeat = self.tryGetParameter( "Activate repeat command", True )
        self.bActivateDefaultChoiceExit = self.tryGetParameter( "Activate exit command", True )
        self.aDefaultChoices = []
        if (self.bActivateDefaultChoiceHelp):
            self.aDefaultChoices.append( self.asHelpWords )
        if (self.bActivateDefaultChoiceRepeat):
            self.aDefaultChoices.append( self.asRepeatWords )
        if (self.bActivateDefaultChoiceExit):
            self.aDefaultChoices.append( self.asExitWords )
        if( question == None ):
            question = ""
        self.initQuestionAndChoices( question )
        if( len( self.aChoices ) > len( self.aDefaultChoices ) ): # if there is at least one choice (not a default one)
            self.nIndexChoice = len( self.aDefaultChoices )
        else: # if there are only default words
            self.nIndexChoice = 0
        self.bGoOut = False
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFFFFFF, 0.1 )
        # initialize tactile sensor handler
        self.initSeqDetected()
        # subscribe to tactile sensors extractors (launch tactile sensor handler)
        self.memory.subscribeToEvent( "FrontTactilTouched", self.getName(), "onTactilTouched" )
        self.memory.subscribeToEvent( "MiddleTactilTouched", self.getName(), "onTactilTouched" )
        self.memory.subscribeToEvent( "RearTactilTouched", self.getName(), "onTactilTouched" )
        thread.start_new_thread( self.loopLedsBrainTwinkle, () )
        while( not self.bGoOut ):
            self.questionRecognitionReaction()
        if( self.bInTactileSensorMenu ):
            self.nCountNoReply = 0
            if( self.nFrameNumber != self.aFrameNumbers["headDown"] ):
                self.nFrameNumber = self.aFrameNumbers["headDown"]
                try:
                    self.getTimeline().goTo(self.nFrameNumber)
                except: # if NAOqi < 1.14
                    try:
                        self.gotoAndStop(self.nFrameNumber)
                    except:
                        pass
            self.loopLedsBrainTurn()
        else:
            self.bIsRunning = False

    def onInput_choicesList(self, p):
        "Set choices list."
        self.logger.debug( "Input choicesList stimulated." )
        if( not self.bIsRunning ):
            self.bExternChoices = True
            language = "English"
            if(self.asr != None):
                language =  self.asr.getLanguage()
            self.asNegativeWords = self.aAllWords[language]["negative"]
            self.asPositiveWords = self.aAllWords[language]["positive"]
            self.asHelpWords = self.aAllWords[language]["help"]
            self.asExitWords = self.aAllWords[language]["exit"]
            self.asRepeatWords = self.aAllWords[language]["repeat"]
            self.bActivateDefaultChoiceHelp = self.tryGetParameter( "Activate help command", True )
            self.bActivateDefaultChoiceRepeat = self.tryGetParameter( "Activate repeat command", True )
            self.bActivateDefaultChoiceExit = self.tryGetParameter( "Activate exit command", True )
            self.aDefaultChoices = []
            if (self.bActivateDefaultChoiceHelp):
                self.aDefaultChoices.append( self.asHelpWords )
            if (self.bActivateDefaultChoiceRepeat):
                self.aDefaultChoices.append( self.asRepeatWords )
            if (self.bActivateDefaultChoiceExit):
                self.aDefaultChoices.append( self.asExitWords )
            self.aChoices = []
            self.aChoiceIndexes = []
            self.aChoices.extend( self.aDefaultChoices )
            index = 0
            for choice in p:
                if( self.isString(choice) ):
                    choice = choice.strip(" \t,;.\n") # remove space or tabs at beginning or end of a choice
                    if( choice != "" ):
                        choice = [ choice ]
                    else:
                        choice = []
                elif( self.isArray(choice) ):
                    if( choice != [] ):
                        for i in range( len( choice ) ):
                            if( self.isString(choice[i]) ):
                                choice[i] = choice[i].strip(" \t,;.\n") # remove space or tabs at beginning or end of a choice
                                if( len( choice[i] ) < 1 ):
                                    del choice[i]
                                    i -= 1 # to parse the good one next loop
                            else:
                                raise Exception( "Error in choices input syntax:\nIt must be an array of choices and each choice can be either a string or an array of strings (several possibilities for one choice)\nEx: ['choice1',['choice2a','choice2b']]\nbut: " + str(p) + " found" )
                else:
                    raise Exception( "Error in choices input syntax:\nIt must be an array of choices and each choice can be either a string or an array of strings (several possibilities for one choice)\nEx: ['choice1',['choice2a','choice2b']]\nbut: " + str(p) + " found" )
                if( len( choice ) > 0 ):
                    for sWord in choice:
                        for aDefaultChoice in self.aDefaultChoices:
                            if( sWord in aDefaultChoice ):
                                raise Exception( "Error in input choices list: You chose a word which is already used for default choices:\n" + str(sWord) + " is used for the default choice: " + str(aDefaultChoice[0]) )
                    self.aChoices.append( choice )
                    self.aChoiceIndexes.append( index )
                index += 1

    def onInput_onStop(self):
        "Stop box behaviour."
        self.logger.debug( "Input onStop stimulated." )
        if( self.bIsRunning ):
            self.goOut( self.asExitWords[0], "onStop" )
            self.sRecoInterruption = "onStop"
        else:
            self.onUnload()

# GENERAL FUNCTIONS ------------------------------------------------------------------------------------------

    def isString(self, strVariable):
        try:
            if( type( strVariable ) == type( "some string" ) ):
                return True
        except:
            pass
        return False

    def isArray(self, aVariable):
        try:
            if( type( aVariable ) == type( ["some array"] ) ):
                return True
        except:
            pass
        return False

    def fileExists(self, strPathFilename ):
        try:
            file = open( strPathFilename, 'r' )
            if( file ):
                file.close()
                return True
        except (IOError, os.error), err:
            pass
        return False

    def getFileContents(self, sFilename ):
        "read a file and return it's contents, or '' if not found, empty, ..."
        try:
            fileContent = open( sFilename )
            aBuf = fileContent.read()
            fileContent.close()
        except:
            try:
                fileContent.close()
            except:
                pass
            return ""
        return aBuf

    def getBrainLedName(self, nNumLed):
        "Get the name of the DCM led device from its number"
        "0 => front left; 1 => next in clock wise; until 11"
        numLed = nNumLed%12
        if( numLed <= 1 ):
            return "Head/Led/Front/Right/%d/Actuator/Value" % (1-numLed)
        elif( numLed >= 10 ):
            return "Head/Led/Front/Left/%d/Actuator/Value" % (numLed-10)
        elif( numLed <= 2 ):
            return "Head/Led/Middle/Right/%d/Actuator/Value" % (2-numLed)
        elif( numLed >= 9 ):
            return "Head/Led/Middle/Left/%d/Actuator/Value" % (numLed-9)
        elif( numLed <= 5 ):
            return "Head/Led/Rear/Right/%d/Actuator/Value" % (numLed-3)
        else:
            return "Head/Led/Rear/Left/%d/Actuator/Value" % (8-numLed)

    def skipTTS(self):
        for idtts in self.aIdsTTS:
            try:
                self.ttsStop.stop(idtts)
            except:
                self.logger.debug( "Warning: The Text-To-Speech could not have been stopped." )

    def tryGetParameter(self, sParameterName, defaultValue):
        try:
            return self.getParameter( sParameterName )
        except:
            return defaultValue

# QUESTION AND CHOICES INITIALIZATION ----------------------------------------------------------------------

    def initQuestionAndChoices(self, p):
        "Initialize the question and the choices."
        # question processing
        if( self.isString(p) ):
            self.sQuestion = p
        else:
            raise Exception( "Error in question input syntax:\nQuestion text\nexpected for example, but:\n" + str(p[0]) + "\nfound" )
        # choices processing
        if( not self.bExternChoices ):
            self.aChoices = []
            self.aChoiceIndexes = []
            self.aChoices.extend( self.aDefaultChoices )
            index = 0
            listChoices = self.aListAllChoices[self.tts.getLanguage()]
            for choice in listChoices:
                aChoice = choice.split( "/" )
                if( aChoice != [] ):
                    for i in range( len( aChoice ) ):
                        aChoice[i] = aChoice[i].strip(" \t,;.\n") # remove space or tabs at beginning or end of a choice
                        if( len( aChoice[i] ) < 1 ):
                            del aChoice[i]
                            i -= 1 # to parse the good one next loop
                if( len( aChoice ) > 0 ):
                    # check if there is a word which is already used for the default choices
                    for sWord in aChoice:
                        for aDefaultChoice in self.aDefaultChoices:
                            if( sWord in aDefaultChoice ):
                                raise Exception( "Error in choices list: You chose a word which is already used for default choices:\n" + str(sWord) + " is used for the default choice: " + str(aDefaultChoice[0]) )
                    # append the choice to the list if everything worked well
                    self.aChoices.append( aChoice )
                    self.aChoiceIndexes.append( index )
                index += 1
        # check that there is at least one choice (a default one or not)
        if( len( self.aChoices ) < 1 ):
            raise Exception( "Error in choices list: It is empty. There is no default choice nor choice entered." )

# QUESTION-RECOGNITION-REACTION -----------------------------------------------------------------------------

    def questionRecognitionReaction(self):
        "Ask question, launch speech recognition and process answer."
        self.ttsQuestionAndRecoInit()
        if( not self.bMustStop ):
            # stop movement animation
            if( self.nFrameNumber != self.aFrameNumbers["reco"] ):
                self.nFrameNumber = self.aFrameNumbers["reco"]
                try:
                    self.getTimeline().goTo(self.nFrameNumber)
                except: # if NAOqi < 1.14
                    try:
                        self.gotoAndStop(self.nFrameNumber)
                    except:
                        pass
            # start speech recognition
            self.logger.debug( "Speech recognition started." )
            self.memory.subscribeToEvent( "WordRecognized", self.getName(), "onWordRecognized" )
            self.bRecoIsWaitingForVoice = True
            self.memory.subscribeToEvent( "SpeechDetected", self.getName(), "onSpeechDetected" )
        # leds during the recognition
        self.loopLedsReco()
        # process the reco loop break
        self.processRecoInterruption()

    def ttsQuestionAndRecoInit(self):
        "Ask question and initialize the speech recognition during the question to gain time in the interaction."
        if( not self.bInConfirmation ):
            # launch TTS
            idTTS = -1
            if( self.sQuestion != ""):
                idTTS = self.tts.post.say( self.sQuestion )
                self.aIdsTTS.append( idTTS )
                self.logger.debug( "Robot says: " + str(self.sQuestion) )
                # launch TTS movement animation
                if( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ):
                    self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
            # prepare speech recognition
            if(self.asr != None):
                self.asr.setLanguage( self.tts.getLanguage() )
            if( not self.bVocabularyLoaded ):
                aWordsRecognised = []
                for i in range( len( self.aChoices ) ):
                    if( self.aChoices[i] != [] ):
                        aWordsRecognised.extend( self.aChoices[i] )
                sWordsRecognised = "You can say: "
                if( len( aWordsRecognised ) > 1 ):
                    for i in range( len( aWordsRecognised ) - 1 ):
                        sWordsRecognised += "'" + aWordsRecognised[i] + "', "
                if( len( aWordsRecognised ) > 0 ):
                    sWordsRecognised += "'" + aWordsRecognised[len( aWordsRecognised ) - 1] + "'"
                sWordsRecognised += "."
                self.logger.debug( sWordsRecognised )
                if(self.asr != None):
                    self.asr.setVocabulary( aWordsRecognised, False )
                self.bVocabularyLoaded = True
        else:
            # launch TTS
            sentence = self.aAllSentences[self.tts.getLanguage()]["confirmation"][0]
            idTTS = -1
            sentenceToSay = sentence % self.sPreviousAnswer
            if( sentenceToSay != ""):
                idTTS = self.tts.post.say( sentenceToSay )
                self.aIdsTTS.append( idTTS )
                self.logger.debug( "Robot says: " + str(sentenceToSay) )
                # launch TTS movement animation
                if( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ):
                    self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
            # prepare speech recognition
            aWordsRecognised = []
            aWordsRecognised.extend( self.asNegativeWords )
            aWordsRecognised.extend( self.asPositiveWords )
            sWordsRecognised = "You can say: "
            if( len( aWordsRecognised ) > 1 ):
                for i in range( len( aWordsRecognised ) - 1 ):
                    sWordsRecognised += "'" + aWordsRecognised[i] + "', "
            if( len( aWordsRecognised ) > 0 ):
                sWordsRecognised += "'" + aWordsRecognised[len( aWordsRecognised ) - 1] + "'"
            sWordsRecognised += "."
            self.logger.debug( sWordsRecognised )
            if(self.asr != None):
                self.asr.setVocabulary( aWordsRecognised, False )
            self.bVocabularyLoaded = False
        # wait for the end of the TTS
        if( idTTS != -1 ):
            try:
                self.tts.wait( idTTS, 0 )
            except:
                self.logger.debug( "Warning: Could not wait the TTS." )

    def processRecoInterruption(self):
        "Process speech recognition interruption (timeout, action on tactile sensor, word said, etc...)"
        # wait for the end of the reaction (help, not understood, etc...)
        while( self.sRecoInterruption == "" ):
            time.sleep( 0.2 )
        self.logger.debug( "The speech recognition has been interrupted because of: " + str(self.sRecoInterruption) + "." )
        if( self.sRecoInterruption == "timeout" ): # if recognition interrupted by timeout
            try:
                # stop recognition
                self.memory.unsubscribeToEvent( "WordRecognized", self.getName() )
                self.bRecoIsWaitingForVoice = False
                self.bRecoIsHearingOrAnalysing = False
                self.logger.debug( "Speech recognition stopped." )
                self.memory.unsubscribeToEvent( "SpeechDetected", self.getName() )
            except:
                pass
            if( self.bInConfirmation ): # if it was a confirmation question
                # leds noticing that the robot confirm its guessing
                thread.start_new_thread( self.ledsUnderstood, (True, False) )
                # if nothing has been said, we assume that the user agree
                self.bInConfirmation = False
                if( self.sPreviousAnswer in self.asHelpWords ): # if help asked
                    self.helpWhenAsked()
                elif( self.sPreviousAnswer in self.asRepeatWords ): # if repeat asked
                    self.repeatWhenNoQuestion()
                    # repeat the question
                else: # if not repeat nor help asked
                    self.goOut( self.sPreviousAnswer, "wordRecognised" )
            else:
                # reinitialize leds
                self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
                self.nCountNoReply += 1
                if( self.nCountNoReply >= self.nMaxCountNoReply ):
                    self.goOut( self.asExitWords[0], "timeout" )
        else:
            self.nCountNoReply = 0
            if( self.sRecoInterruption in [ "onStop" ] ):
                self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        self.sRecoInterruption = ""

    def repeatWhenNoQuestion(self):
        "Robot's reaction when it is asked to repeat the question when there is no question."
        if( self.sQuestion == "" ):
            sentenceNoQuestion = self.aAllSentences[self.tts.getLanguage()]["noQuestion"][0]
            sentenceNoQuestion += self.enumerateChoices( True ) # True to ask that the introduction is played
            if( len( self.aChoices ) - len( self.aDefaultChoices ) == 0 ): # if there is no choice
                sentenceNoQuestion += self.enumerateDefaultChoices( True ) # True to ask that the introduction is played
            # launch TTS
            idTTS = -1
            if( sentenceNoQuestion != ""):
                if( self.bInTactileSensorMenu ):
                    idTTS = self.tts.post.say( sentenceNoQuestion + "\\Pau=300\\" )
                else:
                    idTTS = self.tts.post.say( sentenceNoQuestion )
                self.aIdsTTS.append( idTTS )
                self.logger.debug( "Robot says: " + str(sentenceNoQuestion) )
                if( not self.bInTactileSensorMenu ):
                    # launch TTS movement animation
                    if( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ):
                        self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                        try:
                            self.getTimeline().goTo(self.nFrameNumber)
                        except: # if NAOqi < 1.14
                            try:
                                self.gotoAndStop(self.nFrameNumber)
                            except:
                                pass
            # wait for the end of the TTS
            if( idTTS != -1 ):
                try:
                    self.tts.wait( idTTS, 0 )
                except:
                    self.logger.debug( "Warning: Could not wait the TTS." )

# RECO OUTPUT PROCESSING --------------------------------------------------------------------------------------

    def onWordRecognized(self, pDataName, pValue, pMessage):
        "Handler for when a word is recognised by the speech recognition system."
        aState = pValue
        self.logger.debug( "The word '" + str(aState[0]) + "' has been recognised with a threshold of " + str(aState[1]) + "." )
        # interrupt loops:
            # - stop reco
            # - stop leds
            # - stop asking the question on and on
        try:
            self.memory.unsubscribeToEvent( "WordRecognized", self.getName() )
            self.logger.debug( "Speech recognition stopped." )
            self.memory.unsubscribeToEvent( "SpeechDetected", self.getName() )
        except:
            pass
        self.bRecoIsHearingOrAnalysing = False
        self.bRecoIsWaitingForVoice = False
        if( aState[0] != "" ):
            if( aState[1] >= self.rUnderstoodThreshold ):
                if( self.rUnderstoodThreshold <= self.arUnderstoodThreshold[1] - 0.02 ):
                    self.rUnderstoodThreshold += 0.02
                else:
                    self.rUnderstoodThreshold = self.arUnderstoodThreshold[1]
                if( self.bInConfirmation ):
                    if( aState[0] in self.asNegativeWords ):
                        thread.start_new_thread( self.ledsNegative, () )
                    else:
                        thread.start_new_thread( self.ledsUnderstood, (True, False) )
                else:
                    thread.start_new_thread( self.ledsUnderstood, (True, False) )
                self.reactionWordUnderstood( aState )
            else:
                if( self.rUnderstoodThreshold >= self.arUnderstoodThreshold[0] + 0.05 ):
                    self.rUnderstoodThreshold -= 0.05
                else:
                    self.rUnderstoodThreshold = self.arUnderstoodThreshold[0]
                aCurrentChoice = ""
                for choice in self.aChoices:
                    if( aCurrentChoice == "" ):
                        if( aState[0] in choice ):
                            aCurrentChoice = choice
                if( self.sPreviousAnswer in aCurrentChoice ): # if answer in the same choice as previously
                    # then ask confirmation
                    aState[1] = self.rConfirmationThreshold - 0.01
                    thread.start_new_thread( self.ledsUnderstood, (True, False) )
                    self.reactionWordUnderstood( aState )
                else:
                    # else not understood
                    if( self.bInConfirmation ):
                        thread.start_new_thread( self.ledsUnderstood, (True, False) )
                    else:
                        self.sPreviousAnswer = aState[0]
                        thread.start_new_thread( self.ledsNotUnderstood, () )
                    self.reactionNothingUnderstood()
        else:
            if( self.bInConfirmation ):
                thread.start_new_thread( self.ledsUnderstood, (True, False) )
            else:
                thread.start_new_thread( self.ledsNotUnderstood, () )
            self.reactionNothingUnderstood()
        if( pMessage == "" ):
            self.sRecoInterruption = "wordRecognised"
        else:
            self.sRecoInterruption = pMessage

    def onSpeechDetected(self, pDataName, pValue, pMessage):
        "Handler for when something has been heard by the speech recognition system."
        aState = pValue
        if( aState == 1):
            if( self.bRecoIsWaitingForVoice ):
                # make eyes leds switch from an animation to an other
                self.bRecoIsHearingOrAnalysing = True
                self.bRecoIsWaitingForVoice = False
                try:
                    self.timeToReply(time.time() - self.beginTime)
                except:
                    pass

    def reactionWordUnderstood(self, word):
        "Reaction depending on the word recognised (help, repeat, word in choices, etc...) and its recognition confidence."
        if( self.bInConfirmation ):
            self.bInConfirmation = False
            if( word[0] in self.asNegativeWords ):
                # update number of failures
                self.nCountFailure += 1
                if( self.sPreviousAnswer in self.asHelpWords ):
                    if( self.nCountFailure >= self.nMaxCountFailure ): # if maximum number of failures
                        # skip the question
                        self.goOut( self.asExitWords[0], "notUnderstood" )
                else:
                    self.helpAfterFailure()
            else:
                if( (self.sPreviousAnswer in self.asHelpWords) or (word[0] in self.asHelpWords) ):
                    self.helpWhenAsked()
                elif( self.sPreviousAnswer in self.asRepeatWords or (word[0] in self.asRepeatWords) ):
                    self.repeatWhenNoQuestion()
                    # repeat the question
                else:
                    self.goOut( self.sPreviousAnswer, "wordRecognised" )
                self.sPreviousAnswer = ""
        else:
            self.sPreviousAnswer = word[0]
            if( word[1] >= self.rConfirmationThreshold ):
                if( self.rConfirmationThreshold <= self.arConfirmationThreshold[1] - 0.02 ):
                    self.rConfirmationThreshold += 0.02
                else:
                    self.rConfirmationThreshold = self.arConfirmationThreshold[1]
                if( self.sPreviousAnswer in self.asHelpWords ):
                    self.helpWhenAsked()
                elif( self.sPreviousAnswer in self.asRepeatWords ):
                    self.repeatWhenNoQuestion()
                    # repeat the question
                else:
                    self.goOut( self.sPreviousAnswer, "wordRecognised" )
                self.sPreviousAnswer = ""
            else:
                if( self.rConfirmationThreshold >= self.arConfirmationThreshold[0] + 0.05 ):
                    self.rConfirmationThreshold -= 0.05
                else:
                    self.rConfirmationThreshold = self.arConfirmationThreshold[0]
                self.bInConfirmation = True

    def reactionNothingUnderstood(self):
        "Reaction when nothing has been understood or without an enough confidence."
        if( self.bInConfirmation ):
            # if the robot did not understand, we assume that the user agree
            self.bInConfirmation = False
            if( self.sPreviousAnswer in self.asHelpWords ): # if help asked
                self.helpWhenAsked()
            elif( self.sPreviousAnswer in self.asRepeatWords ): # if repeat asked
                self.repeatWhenNoQuestion()
                # repeat the question
            else: # if not repeat nor help asked
                self.goOut( self.sPreviousAnswer, "wordRecognised" )
        else:
            # update number of failures
            self.nCountFailure += 1
            if( self.nCountFailure <= 1 ): # if first failure
                sentence = self.aAllSentences[self.tts.getLanguage()]["notUnderstood"][0]
            else: # if second failure or more
                sentenceNotUnderstoodAnims = self.aAllSentences[self.tts.getLanguage()]["notUnderstoodAnims"]
                index = random.randint( 0, len( sentenceNotUnderstoodAnims ) - 1 )
                sentence = sentenceNotUnderstoodAnims[index]
                if( self.nFrameNumber != self.aFrameNumbers["notUnderstood"] + 10*index ):
                    self.nFrameNumber = self.aFrameNumbers["notUnderstood"] + 10*index
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
            self.helpAfterFailure( sentence )

# HELP ------------------------------------------------------------------------------------------------------

    def enumerateChoices(self, bIntroToSay):
        "Enumerate choices (only the first word of each choice is taken into account)."
        sentenceHelpEnumChoices = self.aAllSentences[self.tts.getLanguage()]["helpEnumChoices"]
        sentenceHelpEnumMarks = self.aAllSentences[self.tts.getLanguage()]["enumMarks"]
        enumWords = ""
        maxNbEnumChoices = 3
        indexes = []
        for i in range( min(maxNbEnumChoices, len( self.aChoices ) - len( self.aDefaultChoices )) ):
            if( len( self.aChoices ) - len( self.aDefaultChoices ) <= maxNbEnumChoices ):
                index = len( self.aDefaultChoices ) + i
            else:
                index = random.randint( len( self.aDefaultChoices ), len( self.aChoices ) - 1 )
                while( index in indexes ):
                    index = random.randint( len( self.aDefaultChoices ), len( self.aChoices ) - 1 )
            indexes.append( index )
            if( len( indexes ) != 1 ): # if it is not the first choice
                if( len( indexes ) != min(maxNbEnumChoices, len( self.aChoices ) - len( self.aDefaultChoices )) ): # if it is not the last choice
                    enumWords += sentenceHelpEnumMarks[0]
                else:
                    enumWords += sentenceHelpEnumMarks[1]
            enumWords += self.aChoices[index][0]
        sentenceTemplate = sentenceHelpEnumChoices[2]
        if( len( self.aChoices ) - len( self.aDefaultChoices ) <= maxNbEnumChoices ): # if there are 3 or less choices
            sentenceTemplate = sentenceHelpEnumChoices[1]
        if( not bIntroToSay ):
            sentenceTemplate = sentenceHelpEnumChoices[3]
        if( len( self.aChoices ) - len( self.aDefaultChoices ) == 0 ): # if there is no choice
            sentence = sentenceHelpEnumChoices[0]
        else:
            sentence = sentenceTemplate % enumWords
        return sentence

    def enumerateDefaultChoices(self, bIntroToSay):
        "Enumerate default choices (only the first word of each choice is taken into account)."
        sentenceHelpEnumChoices = self.aAllSentences[self.tts.getLanguage()]["helpEnumChoices"]
        sentenceHelpEnumDefault = self.aAllSentences[self.tts.getLanguage()]["helpEnumDefault"]
        sentenceHelpEnumMarks = self.aAllSentences[self.tts.getLanguage()]["enumMarks"]
        enumWords = ""
        indexes = []
        for i in range( len( self.aDefaultChoices ) ):
            indexes.append( i )
            if( len( indexes ) != 1 ): # if it is not the first choice
                if( len( indexes ) != len( self.aDefaultChoices ) ): # if it is not the last choice
                    enumWords += sentenceHelpEnumMarks[0]
                else:
                    enumWords += sentenceHelpEnumMarks[1]
            enumWords += self.aDefaultChoices[i][0]
        sentenceTemplate = sentenceHelpEnumDefault[0]
        if( not bIntroToSay ):
            sentenceTemplate = sentenceHelpEnumChoices[3]
        if( len( self.aDefaultChoices ) == 0 ): # if there is no default choice
            sentence = ""
        else:
            sentence = sentenceTemplate % enumWords
        return sentence

    def explanationTactileSensor(self):
        "Explain the possible interaction with the tactile sensor."
        sentenceHelpTactile = self.aAllSentences[self.tts.getLanguage()]["helpTactile"]
        if( self.bInTactileSensorMenu ):
            sentence = sentenceHelpTactile[1]
        else:
            sentence = sentenceHelpTactile[0]
        return sentence

    def helpWhenAsked(self, sentence = ""):
        "Help when the user asked it: enumerate choices, enumerate default choices and explain tactile sensor possible interaction."
        if( not self.bInTactileSensorMenu ):
            # enumeration of choices
            sentence += self.enumerateChoices( True ) # True to ask that the introduction is played
            # enumeration of default choices
            sentence += self.enumerateDefaultChoices( True ) # True to ask that the introduction is played
        # explanation about alternative modality (tactil sensor, arm motion)
        sentence += self.explanationTactileSensor()
        # launch TTS
        idTTS = -1
        if( sentence != "" ):
            if( self.bInTactileSensorMenu ):
                idTTS = self.tts.post.say( sentence + "\\Pau=300\\" )
            else:
                idTTS = self.tts.post.say( sentence )
            self.aIdsTTS.append( idTTS )
            self.logger.debug( "Robot says: " + str(sentence) )
            # launch TTS movement animation
            if( self.bInTactileSensorMenu ):
                if( self.nFrameNumber != self.aFrameNumbers["helpTactileSensor"] ):
                    self.nFrameNumber = self.aFrameNumbers["helpTactileSensor"]
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
            else:
                if( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ):
                    self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
        # wait for the end of the TTS
        if( idTTS != -1 ):
            try:
                self.tts.wait( idTTS, 0 )
            except:
                self.logger.debug( "Warning: Could not wait the TTS." )
        # repeat the question

    def helpAfterFailure(self, sentence = ""):
        "Help when the speech recognition failed (nothing understood or incorrect answer understood)."
        if( self.nCountFailure < self.nMaxCountFailure ): # if reasonable number of failures
            if( self.bActivateHelpWhenFailure ):
                if( self.nCountFailure in [1, 2] ): # if first or second failure
                    # enumeration of choices, or default words if there is no choice
                    if( len( self.aChoices ) - len( self.aDefaultChoices ) > 0 ): # if there is at least one choice
                        sentence += self.enumerateChoices( self.nCountFailure == 1 ) # the introduction is played if it is the first failure
                    else:
                        sentence += self.enumerateDefaultChoices( self.nCountFailure == 1 ) # the introduction is played if it is the first failure
                    if( self.nCountFailure == 2 ): # if second failure
                        # explanation about alternative modality (tactil sensor, arm motion)
                        sentence += self.explanationTactileSensor()
                # launch TTS
                idTTS = -1
                if( sentence != "" ):
                    idTTS = self.tts.post.say( sentence )
                    self.aIdsTTS.append( idTTS )
                    self.logger.debug( "Robot says: " + str(sentence) )
                    # launch TTS movement animation
                    listPossibleFrames = range( len( self.aAllSentences[self.tts.getLanguage()]["notUnderstoodAnims"] ) )
                    for i in range(len(listPossibleFrames)):
                        listPossibleFrames[i] = listPossibleFrames[i] * 10 + self.aFrameNumbers["notUnderstood"]
                    if( ( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ) and not ( self.nFrameNumber in listPossibleFrames ) ):
                        try:
                            self.getTimeline().goTo(self.aFrameNumbers["bodyTalk"])
                        except: # if NAOqi < 1.14
                            try:
                                self.gotoAndStop(self.aFrameNumbers["bodyTalk"])
                            except:
                                pass
                    self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                # wait for the end of the TTS
                if( idTTS != -1 ):
                    try:
                        self.tts.wait( idTTS, 0 )
                    except:
                        self.logger.debug( "Warning: Could not wait the TTS." )
            # repeat the question
        else: # if maximum number of failures
            # skip the question
            self.goOut( self.asExitWords[0], "notUnderstood" )

# LEDS ---------------------------------------------------------------------------------------------------

    def setLeds(self, eyesLight, earsLight, brainLight):
        "Set all LEDS (eyes, ears and brain lights)."
        rDuration = 1
        if( self.bActivateEyesLight ):
            # set eyes leds
            self.leds.post.fadeRGB( "FaceLeds", eyesLight, rDuration )
        if( self.bActivateEarsLight ):
            # set ears leds
            self.leds.fadeRGB( "EarLeds", earsLight, rDuration )
        if( self.bActivateBrainLight ):
            # set brain leds light
            self.setLedsBrain( brainLight, 500 )

    def ledsUnderstood(self, bFlashEars, bFlashBrain):
        "Sequence of LEDS for eyes, ears and brain when the robot understood what it heard."
        self.bBrainAnimPaused = True
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x00FF00, rDuration )
        if( self.bActivateEarsLight ):
            if( bFlashEars ):
                self.leds.fadeRGB( "EarLeds", 0x00FF00, rDuration )
        if( self.bActivateBrainLight ):
            if( bFlashBrain ):
                self.setLedsBrain( 0.5, int(rDuration * 1000) )
        time.sleep( 0.3 )
        rDuration = 0.2
        if( self.bActivateEyesLight ):
            if( self.bInTactileSensorMenu ):
                self.leds.fadeRGB( "FaceLeds", 0xFFFFFF, rDuration )
            else:
                self.leds.fadeRGB( "FaceLeds", 0x000000, rDuration )
        if( self.bActivateEarsLight ):
            if( bFlashEars ):
                self.leds.fadeRGB( "EarLeds", 0x000000, rDuration )
        if( self.bActivateBrainLight ):
            if( bFlashBrain ):
                self.setLedsBrain( 0., int(rDuration * 1000) )
        time.sleep( 0.1 )
        if( not self.bInTactileSensorMenu ):
            self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        time.sleep( 0.1 )
        self.bBrainAnimPaused = False

    def ledsNotUnderstood(self):
        "Sequence of LEDS for eyes and ears when the robot did not understand what it heard."
        self.bBrainAnimPaused = True
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFF0000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0xFF0000, rDuration )
        time.sleep( 0.05 )
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x000000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0x000000, rDuration )
        time.sleep( 0.05 )
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFF0000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0xFF0000, rDuration )
        time.sleep( 0.05 )
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x000000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0x000000, rDuration )
        time.sleep( 0.3 )
        self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        self.bBrainAnimPaused = False

    def ledsNegative(self):
        "Sequence of LEDS for eyes and ears when the robot understood 'no'."
        self.bBrainAnimPaused = True
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFF0000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0xFF0000, rDuration )
        time.sleep( 0.3 )
        rDuration = 0.2
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x000000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0x000000, rDuration )
        time.sleep( 0.1 )
        self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        time.sleep( 0.1 )
        self.bBrainAnimPaused = False

    def loopLedsReco(self):
        "LEDS (eyes and ears) process during the speech recognition."
        self.beginTime = time.time()
        if( self.bInConfirmation ):
            timerReco = self.beginTime + self.nTimeoutRecoConfirmation
        else:
            timerReco = self.beginTime + self.nTimeoutReco
        self.bHasAlreadyHearingEyes = False
        nEarLedsNextIndex = 0
        nEyesLed = -1
        while( self.bRecoIsWaitingForVoice or self.bRecoIsHearingOrAnalysing ):
            if( self.bMustStop ):
                try:
                    self.timeToReply(time.time() - self.beginTime)
                except:
                    pass
                break
            if( self.bRecoIsWaitingForVoice ):
                if( timerReco < time.time() ):
                    try:
                        self.timeToReply(timerReco - self.beginTime)
                    except:
                        pass
                    self.sRecoInterruption = "timeout"
                    break
            nEarLedsNextIndex = self.ledsEarsTurnOneStep( nEarLedsNextIndex )
            nEyesLed += 1
            self.ledsEyesTurnOneStep( 0x0055FF, nEyesLed%8 )
            time.sleep( 0.2 )

    def ledsEarsTurnOneStep(self, nEarLedsNextIndex):
        "One step of ears LEDS sequence (turn) when the robot is in speech recognition."
        if( self.bActivateEarsLight ):
            nNbrLedByEars = 10
            rTime = 0.7
            strTemplate = "Ears/Led/%s/%dDeg/Actuator/Value"
            nAngle = (360/nNbrLedByEars) * nEarLedsNextIndex
            # update index before sending movement in case of a fast/concurrent call of the function
            nEarLedsNextIndex -= 1 # more beautiful to turn in this way
            if( nEarLedsNextIndex < 0 ):
                nEarLedsNextIndex = nNbrLedByEars-1
            self.leds.post.fade( strTemplate % ( "Left", nAngle ), 1.0, rTime )
            self.leds.post.fade( strTemplate % ( "Right", nAngle ), 1.0, rTime )
            self.leds.post.fade( strTemplate % ( "Left", nAngle ), 0.0, rTime*1.2 )
            self.leds.post.fade( strTemplate % ( "Right", nAngle ), 0.0, rTime*1.2 )
        return nEarLedsNextIndex

    def ledsEyesTurnOneStep(self, nColor, nLed):
        "One step of eyes LEDS sequence (turn) when the robot is in speech recognition."
        if( self.bActivateEyesLight ):
            rTime = 0.7
            if( self.bRecoIsHearingOrAnalysing ):
                if( not self.bHasAlreadyHearingEyes ):
                    self.leds.fadeRGB( "FaceLeds", 0xF4FF22, 0.1 )
                    # start headcheck animation
                    if( self.nFrameNumber != self.aFrameNumbers["headCheck"] ):
                        self.nFrameNumber = self.aFrameNumbers["headCheck"]
                        try:
                            self.getTimeline().goTo(self.nFrameNumber)
                        except: # if NAOqi < 1.14
                            try:
                                self.gotoAndStop(self.nFrameNumber)
                            except:
                                pass
                    self.bHasAlreadyHearingEyes = True
            elif( self.bRecoIsWaitingForVoice ):
                self.leds.post.fadeRGB( "FaceLed%d" % (nLed) , nColor, rTime )
                self.leds.post.fadeRGB( "FaceLed%d" % (nLed) , 0x000000, rTime*1.25 )

    def ledsChangeOnTactile(self):
        self.bBrainAnimPaused = True
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x0055FF, rDuration )
        self.setLedsBrain( 0.5, int(rDuration * 1000) )
        time.sleep( 0.3 )
        rDuration = 0.2
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFFFFFF, rDuration )
        self.setLedsBrain( 0., int(rDuration * 1000) )
        time.sleep( 0.2 )
        self.bBrainAnimPaused = False

    def loopLedsBrainTurn(self):
        self.setLeds( 0xFFFFFF, 0xFFFFFF, 0. )
        rIntensity = 0.5
        nTime = 50
        bAlreadyPaused = False
        while( self.bInTactileSensorMenu ):
            if( not self.bBrainAnimPaused ):
                if( self.nFront == 1 or self.nMiddle == 1 or self.nRear == 1 ):
                    if( not bAlreadyPaused ):
                        bAlreadyPaused = True
                        self.setLedsBrain( 0., 50 )
                else:
                    bAlreadyPaused = False
                    if( self.bActivateBrainLight ):
                        for i in range( 12 ):
                            if( not self.bBrainAnimPaused and self.dcm != None):
                                riseTime = self.dcm.getTime(nTime)
                                strDeviceName = self.getBrainLedName(i)
                                self.dcm.set( [ strDeviceName, "Merge",  [[ rIntensity, riseTime ]] ] )
                                time.sleep( nTime/1000. )
                                if( not self.bBrainAnimPaused ):
                                    self.dcm.set( [ strDeviceName, "Merge",  [[ 0.0, riseTime + int(nTime)/4 ]] ] )
            time.sleep( nTime/1000. )
        self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )

    def loopLedsBrainTwinkle(self):
        rIntensity = 0.5
        bOnStep = True
        bAlreadyPaused = False
        while( not self.bInTactileSensorMenu and self.bIsRunning ):
            if( not self.bBrainAnimPaused ):
                if( self.nFront == 1 or self.nMiddle == 1 or self.nRear == 1 ):
                    if( not bAlreadyPaused ):
                        bAlreadyPaused = True
                        self.setLedsBrain( 0., 50 )
                else:
                    bAlreadyPaused = False
                    if( bOnStep ):
                        self.setLedsBrain( rIntensity, 700 )
                        bOnStep = False
                    else:
                        self.setLedsBrain( 0.0, 700 )
                        bOnStep = True
            time.sleep( 1 )

    def setLedsBrain(self, rIntensity, rTimeMs):
        "One step of brain LEDS sequence (twinkle) when the robot is in speech recognition."
        if( self.bActivateBrainLight and self.dcm != None):
            riseTime = self.dcm.getTime( rTimeMs )
            for i in range( 12 ):
                strDeviceName = self.getBrainLedName(i)
                self.dcm.set( [ strDeviceName, "Merge",  [[ rIntensity, riseTime ]] ] )

# TACTILE SENSOR MENU -------------------------------------------------------------------------------------

    def onAlternativeModalityAction(self, p):
        "Process actions from alternative modalities (sequence from the tactile sensor, simple click on the torso button...)."
        if( not self.bIsRunning ): # if the box is not running
            return # then go out without doing a thing
        if( not self.bInTactileSensorMenu ): # if we are not in the tactile sensor menu (so if we are in the question-recognition-reaction loop)
            if( p in ["TapFront", "TapMiddle", "TapRear", "LongFront", "LongMiddle", "LongRear"] ):
                bTTSRunning = False # to know if TTS is running
                for idTTS in self.aIdsTTS:
                    if( self.tts.isRunning( idTTS )):
                        bTTSRunning = True
                if( bTTSRunning ): # if TTS is running
                    # skip the TTS
                    self.skipTTS()
                else: # if TTS was not running (so if in recognition)
                    # prepare to start the tactile sensor menu
                    self.bInTactileSensorMenu = True
                    # and stop the question-recognition-reaction loop
                    self.goOutOfQuestionRecoReaction()
                    self.sRecoInterruption = "onTactileSensor"
                    # start the tactile sensor menu
                    self.sayCurrentChoice()
                    # start counting timeout
                    self.rTimeWhenActionMadeInTactileMenu = time.time()
                    thread.start_new_thread( self.loopCheckTimeoutInTactileMenu, (self.rTimeWhenActionMadeInTactileMenu,) )
            elif( p in ["Tap", "CalmDown"] ):
                # skip the TTS
                self.skipTTS()
                # then stop everything and cancel the question
                self.goOut( self.asExitWords[0], "onTactileSensor" )
                self.sRecoInterruption = "onTactileSensor"
                self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        else: # if we are in the tactile sensor menu
            self.rTimeWhenActionMadeInTactileMenu = -1.
            if( p in ["TapFront"] ):
                bTTSRunning = False # to know if TTS is running
                for idTTS in self.aIdsTTS:
                    if( self.tts.isRunning( idTTS ) ):
                        bTTSRunning = True
                if( self.bIsSayingChoice or not bTTSRunning ): # else just skip the TTS (in the sayCurrentChoice function)
                    # change choice
                    self.nIndexChoice += 1
                    if( self.nIndexChoice >= len( self.aChoices ) ):
                        self.nIndexChoice = 0
                # say the choice in the tactile sensor menu
                self.sayCurrentChoice()
                self.timeoutManagingInTactileMenu()
            elif( p in ["TapRear"] ):
                bTTSRunning = False # to know if TTS is running
                for idTTS in self.aIdsTTS:
                    if( self.tts.isRunning( idTTS )):
                        bTTSRunning = True
                if( self.bIsSayingChoice or not bTTSRunning ): # else just skip the TTS (in the sayCurrentChoice function)
                    # change choice
                    self.nIndexChoice -= 1
                    if( self.nIndexChoice < 0 ):
                        self.nIndexChoice = len( self.aChoices ) - 1
                # say the choice in the tactile sensor menu
                self.sayCurrentChoice()
                self.timeoutManagingInTactileMenu()
            elif( p in ["TapMiddle", "LongMiddle"] ):
                self.rTimeWhenActionMadeInTactileMenu = time.time()
                rTimeForThisAction = self.rTimeWhenActionMadeInTactileMenu
                bWasSayingChoice = self.bIsSayingChoice
                bTTSRunning = False # to know if TTS is running
                for idTTS in self.aIdsTTS:
                    if( self.tts.isRunning( idTTS )):
                        bTTSRunning = True
                # skip the TTS if it is running
                self.skipTTS()
                if( bWasSayingChoice or not bTTSRunning ):
                    # validate choice
                    thread.start_new_thread( self.ledsUnderstood, (False, True) )
                    if( self.aChoices[self.nIndexChoice][0] == self.asRepeatWords[0] ):
                        self.repeatWhenNoQuestion()
                        # launch TTS
                        idTTS = -1
                        if( self.sQuestion != ""):
                            idTTS = self.tts.post.say( self.sQuestion + "\\Pau=300\\" )
                            self.aIdsTTS.append( idTTS )
                            self.logger.debug( "Robot says: " + str(self.sQuestion) )
                        # wait for the end of the TTS
                        if( idTTS != -1 ):
                            try:
                                self.tts.wait( idTTS, 0 )
                            except:
                                self.logger.debug( "Warning: Could not wait the TTS." )
                    else:
                        self.reactionWordUnderstood( [ self.aChoices[self.nIndexChoice][0], 1.0 ] )
                if( self.bIsRunning and rTimeForThisAction == self.rTimeWhenActionMadeInTactileMenu ): #$$$
                    self.rTimeWhenActionMadeInTactileMenu = -1.
                    # say the choice in the tactile sensor menu
                    self.sayCurrentChoice()
                    self.timeoutManagingInTactileMenu()
            elif( p == "LongFront" ):
                if( not self.bPressed ):
                    self.bPressed = True
                    bLastElementSaid = False
                    while( self.bPressed ):
                        if( self.nFront == 0 ):
                            self.bPressed = False
                            break
                        bTTSRunning = False # to know if TTS is running
                        for idTTS in self.aIdsTTS:
                            if( self.tts.isRunning( idTTS )):
                                bTTSRunning = True
                        if( self.bIsSayingChoice or not bTTSRunning ):
                            # change choice
                            self.nIndexChoice += 1
                            if( self.nIndexChoice >= len( self.aChoices ) - 1 ):
                                self.nIndexChoice = len( self.aChoices ) - 1
                                if( not bLastElementSaid ):
                                    bLastElementSaid = True
                                    # say the choice in the tactile sensor menu
                                    thread.start_new_thread( self.sayCurrentChoice, () )
                            else:
                                # say the choice in the tactile sensor menu
                                thread.start_new_thread( self.sayCurrentChoice, () )
                        else:
                            if( self.nIndexChoice == len( self.aChoices ) - 1 ):
                                bLastElementSaid = True
                            # say the choice in the tactile sensor menu
                            thread.start_new_thread( self.sayCurrentChoice, () )
                        for i in range(8):
                            if( self.nFront == 0 ):
                                self.bPressed = False
                                break
                            time.sleep(0.1)
                    for idTTS in self.aIdsTTS:
                        if( self.tts.isRunning( idTTS ) ):
                            try:
                                self.tts.wait( idTTS, 0 )
                            except:
                                self.logger.debug( "Warning: Could not wait the TTS." )
                    self.timeoutManagingInTactileMenu()
            elif( p == "LongRear" ):
                if( not self.bPressed ):
                    self.bPressed = True
                    bFirstElementSaid = False
                    while( self.bPressed ):
                        if( self.nRear == 0 ):
                            self.bPressed = False
                            break
                        bTTSRunning = False # to know if TTS is running
                        for idTTS in self.aIdsTTS:
                            if( self.tts.isRunning( idTTS )):
                                bTTSRunning = True
                        if( self.bIsSayingChoice or not bTTSRunning ):
                            # change choice
                            self.nIndexChoice -= 1
                            if( self.nIndexChoice <= 0 ):
                                self.nIndexChoice = 0
                                if( not bFirstElementSaid ):
                                    bFirstElementSaid = True
                                    # say the choice in the tactile sensor menu
                                    thread.start_new_thread( self.sayCurrentChoice, () )
                            else:
                                # say the choice in the tactile sensor menu
                                thread.start_new_thread( self.sayCurrentChoice, () )
                        else:
                            if( self.nIndexChoice == 0 ):
                                bFirstElementSaid = True
                            # say the choice in the tactile sensor menu
                            thread.start_new_thread( self.sayCurrentChoice, () )
                        for i in range(8):
                            if( self.nRear == 0 ):
                                self.bPressed = False
                                break
                            time.sleep(0.1)
                    for idTTS in self.aIdsTTS:
                        if( self.tts.isRunning( idTTS ) ):
                            try:
                                self.tts.wait( idTTS, 0 )
                            except:
                                self.logger.debug( "Warning: Could not wait the TTS." )
                    self.timeoutManagingInTactileMenu()
            elif( p in ["Tap", "CalmDown"] ):
                # then stop everything and cancel the question
                self.goOut( self.asExitWords[0], "onTactileSensor" )

    def sayCurrentChoice(self):
        "In the tactile sensor menu, make the robot say the current selected choice"
        self.bIsSayingChoice = True
        rTimeCurrent = time.time()
        self.rTimeLastChoiceSaid = rTimeCurrent
        # stop previous TTS
        self.skipTTS()
        # launch TTS
        idTTS = -1
        if( self.aChoices[ self.nIndexChoice ][0] != "" ):
            if( self.nFrameNumber != self.aFrameNumbers["headDown"] ):
                self.nFrameNumber = self.aFrameNumbers["headDown"]
                try:
                    self.getTimeline().goTo(self.nFrameNumber)
                except: # if NAOqi < 1.14
                    try:
                        self.gotoAndStop(self.nFrameNumber)
                    except:
                        pass
            sentence = self.aChoices[ self.nIndexChoice ][0] + "?"
            idTTS = self.tts.post.say( sentence )
            self.aIdsTTS.append( idTTS )
            self.logger.debug( "Robot says: " + str(sentence) )
            # launch flash leds
            thread.start_new_thread( self.ledsChangeOnTactile, () )
        if( idTTS != -1 ):
            try:
                self.tts.wait( idTTS, 0 )
            except:
                self.logger.debug( "Warning: Could not wait the TTS." )
        if( self.rTimeLastChoiceSaid == rTimeCurrent ):
            self.rTimeLastChoiceSaid = -1.
            self.bIsSayingChoice = False

    def timeoutManagingInTactileMenu(self):
        # check if there has been an other action with tts made while this one was processed
        bTTSRunning = False # to know if TTS is running
        for idTTS in self.aIdsTTS:
            if( self.tts.isRunning( idTTS )):
                bTTSRunning = True
        if( not bTTSRunning ):
            # start counting timeout
            self.rTimeWhenActionMadeInTactileMenu = time.time()
            thread.start_new_thread( self.loopCheckTimeoutInTactileMenu, (self.rTimeWhenActionMadeInTactileMenu,) )

    def loopCheckTimeoutInTactileMenu(self, rTimeForThisAction):
        nTimeout = time.time() + self.nTimeoutTactile
        if( self.rTimeWhenActionMadeInTactileMenu == rTimeForThisAction ):
            while( time.time() < nTimeout and self.rTimeWhenActionMadeInTactileMenu == rTimeForThisAction and self.bIsRunning ):
                time.sleep( 0.1 )
            if( self.rTimeWhenActionMadeInTactileMenu != rTimeForThisAction ):
                self.nCountNoReply = 0
            elif( self.bIsRunning ):
                self.rTimeWhenActionMadeInTactileMenu = -1.
                self.nCountNoReply += 1
                if( self.nCountNoReply >= self.nMaxCountNoReply ):
                    self.goOut( self.asExitWords[0], "timeout" )
                else:
                    bTTSRunning = False # to know if TTS is running
                    for idTTS in self.aIdsTTS:
                        if( self.tts.isRunning( idTTS )):
                            bTTSRunning = True
                    if( not bTTSRunning ):
                        # say the choice in the tactile sensor menu
                        self.sayCurrentChoice()
                        # start counting timeout
                        self.rTimeWhenActionMadeInTactileMenu = time.time()
                        thread.start_new_thread( self.loopCheckTimeoutInTactileMenu, (self.rTimeWhenActionMadeInTactileMenu,) )

# TACTILE SENSOR HANDLER -------------------------------------------------------------------------------

    def initSeqDetected(self):
        "Initialize the sequence handler."
        self.bSeqStarted = False
        self.aDetectedSeqs = []
        self.aDetectedSeqs.extend(self.aSeqs)
        for seq in self.aDetectedSeqs:
            seq["index"] = 0
            seq["previousStepTime"] = 0

    def convertToArrayOfPossibleStates(self, states):
        "Check if the states described in the sequences using a string are in the right syntax, and then convert them to an array of the possible states."
        aStates = []
        aStates3 = [[1, 1, 1]]
        aStates2 = [[0, 1, 1], [1, 0, 1], [1, 1, 0]]
        aStates1 = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]
        aStates0 = [[0, 0, 0]]
        try:
            if( int(states) == states ): # if states is an integer
                states = str(states)
        except:
            pass
        if( self.isString(states) ):
            if( not states in ["*", "0+", "0", "0-", "1+", "1", "1-", "2+", "2", "2-", "3+", "3", "3-", "F+", "F", "F-", "M+", "M", "M-", "R+", "R", "R-"] ):
                raise Exception( "Error in sequences states description syntax: description expected in " + str(["*", "0+", "0", "0-", "1+", "1", "1-", "2+", "2", "2-", "3+", "3", "3-", "F+", "F", "F-", "M+", "M", "M-", "R+", "R", "R-"]) + " but " + str(p) + " found with this type: " + str(type(p)) )
            if( states in ["*", "0+", "1+", "2+", "3+", "3", "3-", "F+", "M+", "R+"] ):
                aStates.extend(aStates3)
            if( states in ["*", "0+", "1+", "2+", "2", "2-", "3-"] ):
                aStates.extend(aStates2)
            if( states in ["*", "0+", "1+", "1", "1-", "2-", "3-"] ):
                aStates.extend(aStates1)
            if( states in ["*", "0+", "0", "0-", "1-", "2-", "3-", "F-", "M-", "R-"] ):
                aStates.extend(aStates0)
            if( states in ["F", "F+", "F-"] ):
                aStates.append([1, 0, 0])
            if( states in ["M", "M+", "M-"] ):
                aStates.append([0, 1, 0])
            if( states in ["R", "R+", "R-"] ):
                aStates.append([0, 0, 1])
            if( states in ["F+", "M+"] ):
                aStates.append([1, 1, 0])
            if( states in ["R+", "M+"] ):
                aStates.append([0, 1, 1])
            if( states in ["F+", "R+"] ):
                aStates.append([1, 0, 1])
        elif( self.isArray(states) ):
            if( self.isArray(states[0]) ):
                aStates = states
            elif( int(states[0]) == states[0] ):
                aStates = [states]
            else:
                raise Exception( "Error in sequences states description syntax: description expected in " + str(["*", "0+", "0", "0-", "1+", "1", "1-", "2+", "2", "2-", "3+", "3", "3-", "F+", "F", "F-", "M+", "M", "M-", "R+", "R", "R-"]) + " but " + str(p) + " found with this type: " + str(type(p)) )
        else:
            raise Exception( "Error in sequences states description syntax:\nstring, array or int expected but " + str(type(p)) + " found" )
        return aStates

    def checkIfSeqsCorrespondingLeft(self, param):
        "If the sequence handler is done (there is no sequence detected left or the first in the list corresponds), then reinitialize the sequence handler, and give the corresponding sequence if there is one."
        if( self.aDetectedSeqs == [] ):
            # then no sequence corresponding in the list
            self.initSeqDetected()
        else:
            if( self.aDetectedSeqs[0]["index"] == -1 ): # if first sequence in left ones corresponds
                # then it is this sequence which is played
                thread.start_new_thread( self.onAlternativeModalityAction, (self.aDetectedSeqs[0]["name"],) )
                self.initSeqDetected()
        self.mutexCheckIfSeqsCorrespondingLeft.unlock()

    def loopCheckTimeoutMax(self, nTimeoutMax, seq, currentState, currentTime):
        "When timeout ellapsed, check the sequence status and process it."
        nPreviousIndex = seq["index"]
        time.sleep(nTimeoutMax + 0.1)
        aSeqsTemp = []
        aSeqsTemp.extend( self.aDetectedSeqs )
        currentState = [self.nFront, self.nMiddle, self.nRear]
        currentTime = time.time()
        if( nPreviousIndex == seq["index"] and not self.mutexProcessCurrentState.test() and not (1 in currentState) ): # if no change in the sequence step but timeout ellapsed and sequence handler is not processing (so if there is no action from the user and the sequence is still at the same point)
            if( seq in aSeqsTemp and seq["index"] != -1 ): # but if sequence is still in the possible ones and not completed
                if( currentState in seq["statesAndTimeout"][seq["index"]] ): # last check if the current state corresponds to the next one
                    # then we go to the next step
                    seq["previousStepTime"] = currentTime
                    seq["index"] += 2
                    if( seq["index"] > len( seq["statesAndTimeout"] ) ): # if there is no more step
                        seq["index"] = -1 # then the sequence is completed
                    else: # if there is at least one step left
                        nTimeoutMin = 0
                        nTimeoutMax = 5
                        if( self.isArray(seq["statesAndTimeout"][seq["index"]-1]) ):
                            if( seq["statesAndTimeout"][seq["index"]-1][0] < 0 ):
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][0]
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][1]
                            else:
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][0]
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][1]
                        else:
                            if( seq["statesAndTimeout"][seq["index"]-1] < 0 ):
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1]
                            else:
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1]
                        thread.start_new_thread( self.loopCheckTimeoutMax, (nTimeoutMax, seq, currentState, currentTime) )
                else:
                    # then remove the sequence from the possible ones
                    aSeqsTemp.remove(seq)
                    self.aDetectedSeqs = aSeqsTemp
                self.mutexCheckIfSeqsCorrespondingLeft.lock( self.checkIfSeqsCorrespondingLeft, None )

    def loopCheckTimeoutMin(self, nTimeoutMin, seq):
        "Wait that the minimum timeout ellapse to check if the new tactile sensor state corresponds to the expected one for this sequence."
        if( nTimeoutMin != 0 ):
            nPreviousIndex = seq["index"]
            time.sleep(nTimeoutMin - time.time() + seq["previousStepTime"])
            currentTime = time.time()
            currentState = [self.nFront, self.nMiddle, self.nRear]
            self.mutexProcessCurrentState.lock( self.processCurrentState, [0, currentState, currentTime] )

    def updateDetectedSeqs(self, seq, aSeqsTemp, currentState, currentTime):
        "Update a detected sequence."
        if( seq["index"] > 0 ): # if not the first step
            nTimeoutMin = 0
            nTimeoutMax = 5
            if( self.isArray(seq["statesAndTimeout"][seq["index"]-1]) ):
                if( seq["statesAndTimeout"][seq["index"]-1][0] < 0 ):
                    nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][0]
                    nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][1]
                else:
                    nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][0]
                    nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][1]
            else:
                if( seq["statesAndTimeout"][seq["index"]-1] < 0 ):
                    nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1]
                else:
                    nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1]
            if( currentTime > nTimeoutMax + seq["previousStepTime"] ): # if timeout of this step ellapsed
                aSeqsTemp.remove(seq) # then it is not this sequence which is played
            elif( not (currentState in seq["statesAndTimeout"][seq["index"]]) ): # if the current state does not correspond to one of the described ones but the timeout of this step did not ellaspe
                # then we check that this state could be an intermediate one
                aIntermediateStates = [[], [], []]
                for i in range( len( currentState ) ):
                    for j in range( len( seq["statesAndTimeout"][seq["index"]] ) ):
                        aIntermediateStates[i].append( seq["statesAndTimeout"][seq["index"]][j][i] )
                    for j in range( len( seq["statesAndTimeout"][seq["index"]-2] ) ):
                        aIntermediateStates[i].append( seq["statesAndTimeout"][seq["index"]-2][j][i] )
                bIsIntermediate = True
                for i in range( len( currentState ) ):
                    bIsIntermediate = bIsIntermediate and ( currentState[i] in aIntermediateStates[i] )
                if( not bIsIntermediate ):
                    aSeqsTemp.remove(seq) # then it is not this sequence which is played
            else: # if the current state correspond to one of the described ones
                if( currentTime > nTimeoutMin + seq["previousStepTime"] ): # if the minimum time to wait the next step is ellapsed
                    # then we go to the next step
                    seq["previousStepTime"] = currentTime
                    seq["index"] += 2
                    if( seq["index"] > len( seq["statesAndTimeout"] ) ): # if there is no more step
                        seq["index"] = -1 # then the sequence is completed
                    else: # if there is at least one step left
                        # start clock to timeout
                        nTimeoutMin = 0
                        nTimeoutMax = 5
                        if( self.isArray(seq["statesAndTimeout"][seq["index"]-1]) ):
                            if( seq["statesAndTimeout"][seq["index"]-1][0] < 0 ):
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][0]
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][1]
                            else:
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][0]
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][1]
                        else:
                            if( seq["statesAndTimeout"][seq["index"]-1] < 0 ):
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1]
                            else:
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1]
                        thread.start_new_thread( self.loopCheckTimeoutMin, (nTimeoutMin, seq) )
                        thread.start_new_thread( self.loopCheckTimeoutMax, (nTimeoutMax, seq, currentState, currentTime) )
                else: # if the minimum time to wait the next step is not ellapsed
                    # then we are going to wait until it is to check then
                    thread.start_new_thread( self.loopCheckTimeoutMin, (nTimeoutMin, seq) )
        elif( seq["index"] == 0 ): # for the first step
            if( currentState in seq["statesAndTimeout"][seq["index"]] ): # if the current state correspond to one of the described ones
                # then we go to the next step
                seq["previousStepTime"] = currentTime
                seq["index"] += 2
                if( seq["index"] > len( seq["statesAndTimeout"] ) ): # if there is no more step
                    seq["index"] = -1 # then the sequence is completed
                else: # if there is at least one step left
                    # start clock to timeout
                    nTimeoutMin = 0
                    nTimeoutMax = 5
                    if( self.isArray(seq["statesAndTimeout"][seq["index"]-1]) ):
                        if( seq["statesAndTimeout"][seq["index"]-1][0] < 0 ):
                            nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][0]
                            nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][1]
                        else:
                            nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][0]
                            nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][1]
                    else:
                        if( seq["statesAndTimeout"][seq["index"]-1] < 0 ):
                            nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1]
                        else:
                            nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1]
                    thread.start_new_thread( self.loopCheckTimeoutMin, (nTimeoutMin, seq) )
                    thread.start_new_thread( self.loopCheckTimeoutMax, (nTimeoutMax, seq, currentState, currentTime) )
            else: # if the current state does not correspond to the first described
                aSeqsTemp.remove(seq) # then it is not this sequence which has just been started

    def updateSeqsHandler(self, currentState, currentTime):
        "Update list of detected sequences."
        aSeqsTemp = []
        aSeqsTemp.extend( self.aDetectedSeqs )
        for seq in self.aDetectedSeqs:
            self.updateDetectedSeqs( seq, aSeqsTemp, currentState, currentTime )
        self.aDetectedSeqs = aSeqsTemp
        self.mutexCheckIfSeqsCorrespondingLeft.lock( self.checkIfSeqsCorrespondingLeft, None )

    def processCurrentState(self, param):
        "Process the current tactile sensor state."
        pValue = param[0]
        currentState = param[1]
        currentTime = param[2]
        if( pValue == 1 and not self.bSeqStarted ):
            self.bSeqStarted = True
            for seq in self.aDetectedSeqs:
                seq["previousStepTime"] = currentTime
        # update sequences handler
        if( self.bSeqStarted ):
            self.updateSeqsHandler(currentState, currentTime)
        self.mutexProcessCurrentState.unlock()

    def onFrontTactilTouched(self, param):
        "Handle an action (touch or release) on the front tactile sensor."
        self.logger.debug( "Change detected on the front tactile sensor: " + str(param[0]) )
        pValue = param[0]
        currentTime = param[1]
        currentState = [pValue, self.nMiddle, self.nRear]
        self.nFront = pValue
        self.mutexProcessCurrentState.lock( self.processCurrentState, [pValue, currentState, currentTime] )
        self.mutexTactilTouched.unlock()

    def onMiddleTactilTouched(self, param):
        "Handle an action (touch or release) on the middle tactile sensor."
        self.logger.debug( "Change detected on the middle tactile sensor: " + str(param[0]) )
        pValue = param[0]
        currentTime = param[1]
        currentState = [self.nFront, pValue, self.nRear]
        self.nMiddle = pValue
        self.mutexProcessCurrentState.lock( self.processCurrentState, [pValue, currentState, currentTime] )
        self.mutexTactilTouched.unlock()

    def onRearTactilTouched(self, param):
        "Handle an action (touch or release) on the rear tactile sensor."
        self.logger.debug( "Change detected on the rear tactile sensor: " + str(param[0]) )
        pValue = param[0]
        currentTime = param[1]
        currentState = [self.nFront, self.nMiddle, pValue]
        self.nRear = pValue
        self.mutexProcessCurrentState.lock( self.processCurrentState, [pValue, currentState, currentTime] )
        self.mutexTactilTouched.unlock()

    def onTactilTouched(self, pDataName, pValue, pMessage):
        "Handle an action (touch or release) on the tactile sensor."
        self.mutexTactilTouched.lock( getattr( self, "on" + pDataName ), [pValue, time.time()] )

# OUTPUTS ACTIVATION --------------------------------------------------------------------------------------

    def goOut(self, outputName, cancelReason = ""):
        "Activate the right output (a choice output or the other output)."
        try:
            self.memory.unsubscribeToEvent( "FrontTactilTouched", self.getName() )
            self.memory.unsubscribeToEvent( "MiddleTactilTouched", self.getName() )
            self.memory.unsubscribeToEvent( "RearTactilTouched", self.getName() )
        except:
            pass

        self.bGoOut = True
        self.bInTactileSensorMenu = False
        if( outputName in self.asExitWords ):
            try:
                self.other( cancelReason )
                self.logger.debug( "Output 'other' stimulated because cancel asked: " + str(cancelReason) + "." )
            except:
                try:
                    self.onStopped( cancelReason )
                    self.logger.debug( "Output 'onStopped' stimulated because cancel asked: " + str(cancelReason) + "." )
                except:
                    try:
                        self.onStopped()
                        self.logger.debug( "Output 'onStopped' stimulated because cancel asked." )
                    except:
                        choregraphe = ALProxy( "ALChoregraphe" )
                        choregraphe.onPythonError( self.getName(), "goOut", "Invalid output: the main output name needs to be 'other', and it needs to be dynamic (because it can be either a string, or an integer)." )
        else:
            nOutput = -1
            for i in range( len (self.aChoices) - len (self.aDefaultChoices) ):
                if( nOutput == -1 ):
                    if( outputName in self.aChoices[i+len( self.aDefaultChoices )] ):
                        nOutput = i
            if( nOutput != -1):
                if( self.bExternChoices ):
                    if( self.bRepeatValidatedChoice ):
                        self.skipTTS()
                        self.tts.say( outputName )
                        self.logger.debug( "Robot says: " + str(outputName) )
                    try:
                        self.other( self.aChoiceIndexes[nOutput] )
                        self.logger.debug( "Output 'other' stimulated with: " + str(self.aChoiceIndexes[nOutput]) + " (corresponding to the choice '" + str(self.aChoices[nOutput+len( self.aDefaultChoices )][0]) + "')." )
                    except:
                        try:
                            self.onStopped( self.aChoiceIndexes[nOutput] )
                            self.logger.debug( "Output 'onStopped' stimulated with: " + str(self.aChoiceIndexes[nOutput]) + " (corresponding to the choice '" + str(self.aChoices[nOutput+len( self.aDefaultChoices )][0]) + "')." )
                        except:
                            choregraphe = ALProxy( "ALChoregraphe" )
                            choregraphe.onPythonError( self.getName(), "goOut", "Invalid type of output: using the input 'choicesList', the main output needs to be dynamic (because it can be either a string, or an integer)." )
                else:
                    if( self.bRepeatValidatedChoice ):
                        self.skipTTS()
                        self.tts.say( outputName )
                        self.logger.debug( "Robot says: " + str(outputName) )
                    try:
                        func = getattr( self, "output_" + str(self.aChoiceIndexes[nOutput]+1) ) #+1 because the first one is output_1 corresponding to the element 0 in the list.
                        func(outputName)
                        self.logger.debug( "Output 'output_" + str(self.aChoiceIndexes[nOutput]+1) + "' stimulated with: " + str(outputName) + "." )
                    except:
                        choregraphe = ALProxy( "ALChoregraphe" )
                        choregraphe.onPythonError( self.getName(), "goOut", "Invalid output: the output 'output_" + str(self.aChoiceIndexes[nOutput]+1) + "' was expected to be stimulated with: " + str(outputName) + " but could not." )
        self.onUnload()
        # come back to an initial position and stop movement animation
        if( self.nFrameNumber != self.aFrameNumbers["end"] ):
            self.nFrameNumber = self.aFrameNumbers["end"]
            try:
                self.getTimeline().goTo(self.nFrameNumber)
            except: # if NAOqi < 1.14
                try:
                    self.gotoAndStop(self.nFrameNumber)
                except:
                    pass

# UNLOAD --------------------------------------------------------------------------------------------------

    def goOutOfQuestionRecoReaction(self):
        "Set some variables to go out of the question-recognition-reaction loop and reinitialize other variables which are going to be used again only on the next start of this box."
        self.bGoOut = True
        self.bMustStop = True
        self.nCountFailure = 0
        self.nCountNoReply = 0
        self.bInConfirmation = False
        self.bVocabularyLoaded = False
        self.skipTTS()
        for idTTS in self.aIdsTTS:
            try:
                self.aIdsTTS.remove( idTTS )
            except:
                self.logger.debug( "Warning: The task ID corresponding to the Text-To-Speech could not have been removed from the ID tasks list." )
        try:
            self.memory.unsubscribeToEvent( "WordRecognized", self.getName() )
            self.bRecoIsWaitingForVoice = False
            self.bRecoIsHearingOrAnalysing = False
            self.logger.debug( "Speech recognition stopped." )
            self.memory.unsubscribeToEvent( "SpeechDetected", self.getName() )
        except:
            pass

    def onUnload(self):
        "Reinitialize variables to default state."
        self.goOutOfQuestionRecoReaction()
        self.bExternChoices = False
        self.bInTactileSensorMenu = False
        try:
            self.memory.unsubscribeToEvent( "FrontTactilTouched", self.getName() )
            self.memory.unsubscribeToEvent( "MiddleTactilTouched", self.getName() )
            self.memory.unsubscribeToEvent( "RearTactilTouched", self.getName() )
        except:
            pass
        self.bIsRunning = False]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <keyword>نعم</keyword>
                                                        <keyword>لا</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </arabic>
                                                    <brazilian>
                                                        <keyword>sim</keyword>
                                                        <keyword>não</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </brazilian>
                                                    <chinese>
                                                        <keyword>是</keyword>
                                                        <keyword>不是</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </chinese>
                                                    <czech>
                                                        <keyword>ano</keyword>
                                                        <keyword>ne</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </czech>
                                                    <danish>
                                                        <keyword>ja</keyword>
                                                        <keyword>nej</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </danish>
                                                    <dutch>
                                                        <keyword>ja</keyword>
                                                        <keyword>nee</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </dutch>
                                                    <english>
                                                        <keyword></keyword>
                                                        <keyword>No</keyword>
                                                        <keyword>Yes</keyword>
                                                        <keyword></keyword>
                                                    </english>
                                                    <finnish>
                                                        <keyword>kyllä</keyword>
                                                        <keyword>ei</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </finnish>
                                                    <french>
                                                        <keyword>oui</keyword>
                                                        <keyword>non</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </french>
                                                    <german>
                                                        <keyword>ja</keyword>
                                                        <keyword>nein</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </german>
                                                    <greek>
                                                        <keyword>ναί</keyword>
                                                        <keyword>κανένα</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </greek>
                                                    <italian>
                                                        <keyword>sì</keyword>
                                                        <keyword>no</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </italian>
                                                    <japanese>
                                                        <keyword>はい</keyword>
                                                        <keyword>いいえ</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </japanese>
                                                    <korean>
                                                        <keyword>예</keyword>
                                                        <keyword>아니</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </korean>
                                                    <norwegian>
                                                        <keyword>ja</keyword>
                                                        <keyword>Nei</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </norwegian>
                                                    <polish>
                                                        <keyword>tak</keyword>
                                                        <keyword>nie</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </polish>
                                                    <portuguese>
                                                        <keyword>sim</keyword>
                                                        <keyword>não</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </portuguese>
                                                    <russian>
                                                        <keyword>да</keyword>
                                                        <keyword>нет</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </russian>
                                                    <spanish>
                                                        <keyword>si</keyword>
                                                        <keyword>no</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </spanish>
                                                    <swedish>
                                                        <keyword>ja</keyword>
                                                        <keyword>ingen</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </swedish>
                                                    <turkish>
                                                        <keyword>evet</keyword>
                                                        <keyword>hayır</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </turkish>
                                                    <language>english</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="0" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is&#x0A;received on this input. The signal can be&#x0A;either a string so that the robot asks a&#x0A;question before the recognition of a&#x0A;choice, or a bang so that the speech&#x0A;recognition starts immediately without any&#x0A;question." id="2" />
                                                <Input name="choicesList" type="0" type_size="1" nature="1" inner="0" tooltip="To have extern choices list (for example,&#x0A;depending on extern variables).&#x0A;!! Warning !! : Must be set before each&#x0A;time the box is started (with onStart&#x0A;input). Otherwise, the choices displayed&#x0A;on the box will be selected." id="3" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip='Box behavior stops when a signal is&#x0A;received on this input, the &apos;other&apos; output is&#x0A;stimulated by &quot;onStop&quot;.' id="4" />
                                                <Output name="other" type="0" type_size="1" nature="1" inner="0" tooltip='When the user skipped the question, this output gives how it has been&#x0A;skipped. Gives also the number of the choice chosen in case of external&#x0A;choices.&#x0A;This output can be:&#x0A;- &quot;timeout&quot; if the user has not replied.&#x0A;- &quot;notUnderstood&quot; if the interaction with the speech recognition failed.&#x0A;- &quot;onStop&quot; if the onStop input has been activated.&#x0A;- &quot;wordRecognised&quot; if the exit command has been understood.&#x0A;- &quot;onTactileSensor&quot; if the user has tapped the tactile sensor of the robot.&#x0A;- an integer being the number of the external choice in the input list.' id="5" />
                                                <Output name="output_1" type="0" type_size="1" nature="2" inner="0" tooltip="This IO has been automatically added by box. Read box tooltip for more information." id="6" />
                                                <Output name="output_2" type="0" type_size="1" nature="2" inner="0" tooltip="This IO has been automatically added by box. Read box tooltip for more information." id="7" />
                                                <Output name="output_3" type="0" type_size="1" nature="2" inner="0" tooltip="This IO has been automatically added by box. Read box tooltip for more information." id="8" />
                                                <Parameter name="Minimum threshold to understand" inherits_from_parent="0" content_type="2" value="0.2" default_value="0.2" min="0" max="1" tooltip="Minimum threshold to get in order to be understood by the robot." id="9" />
                                                <Parameter name="Minimum threshold to be sure" inherits_from_parent="0" content_type="2" value="0.3" default_value="0.3" min="0" max="1" tooltip="Minimum threshold to get so that the robot would be sure about the user&apos;s&#x0A;answer. Below this threshold, the robot asks a confirmation about what has been&#x0A;understood." id="10" />
                                                <Parameter name="Speech recognition timeout when confirmation" inherits_from_parent="0" content_type="1" value="6" default_value="6" min="1" max="20" tooltip="When the robot asks if what he understood is correct, after this time, if there has been&#x0A;nothing heard, the speech recognition is stopped and the answer understood is&#x0A;considered as correct." id="11" />
                                                <Parameter name="Speech recognition timeout" inherits_from_parent="0" content_type="1" value="6" default_value="6" min="1" max="20" tooltip="After this time, if there has been nothing heard, the speech recognition is stopped&#x0A;and the question is repeated or is skipped." id="12" />
                                                <Parameter name="Maximum number of repetition when no reply" inherits_from_parent="0" content_type="1" value="3" default_value="3" min="1" max="20" tooltip='After this number of times when the user did not reply, the question is skipped, and&#x0A;the output other is stimulated with &quot;timeout&quot;.' id="13" />
                                                <Parameter name="Repeat validated choice" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="If this option is activated, the robot repeats the validated choice when it exits the box." id="14" />
                                                <Parameter name="Activate ears light" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="Activate ears light animation (turn, flash, etc...)." id="15" />
                                                <Parameter name="Activate eyes light" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="Activate eyes light animation (turn, flash, etc...)." id="16" />
                                                <Parameter name="Activate brain light" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="Activate brain light animation (turn, flash, etc...)." id="17" />
                                                <Parameter name="Tactile sensor menu timeout" inherits_from_parent="0" content_type="1" value="10" default_value="10" min="1" max="20" tooltip="After this time, if there has been no action made on the tactile sensor or the torso&#x0A;button, the choice currently selected is repeated or the question is skipped." id="18" />
                                                <Parameter name="Maximum number of repetition when failure" inherits_from_parent="0" content_type="1" value="5" default_value="5" min="1" max="20" tooltip='After this number of times when the robot did not understand the user, the question&#x0A;is skipped, and the output other is stimulated with &quot;notUnderstood&quot;.' id="19" />
                                                <Parameter name="Activate help when failure" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="When this parameter is activated, when the robot did not understand the user, he&#x0A;says some help enumerating available choices and attracting attention on the&#x0A;other available modalities (head tactile sensor)." id="20" />
                                                <Parameter name="Activate help command" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip='Enable the help command. So you can say &quot;help&quot; during the speech recognition&#x0A;and the robot will tell you more information.&#x0A;You will still be able to ask help by clicking the torso button.' id="21" />
                                                <Parameter name="Activate repeat command" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip='Activate the repeat command. So you can say &quot;repeat&quot; during the speech&#x0A;recognition and the robot will repeat the question.' id="22" />
                                                <Parameter name="Activate exit command" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip='Enable the exit command. So you can say &quot;exit&quot; during the speech recognition&#x0A;and the box will be stopped and the &apos;other&apos; output will be stimulated with&#x0A;&quot;wordRecognised&quot;.&#x0A;You will still be able to exit the box with&#x0A;the tactile sensor.' id="23" />
                                                <Parameter name="Sentences file" inherits_from_parent="0" content_type="4" value="/Aldebaran/choice_sentences_light.xml" default_value="/Aldebaran/choice_sentences_light.xml" tooltip="File containing all necessary sentences in each supported language." id="24" />
                                            </Box>
                                            <Box name="Localized Text" id="5" localization="8" tooltip="Send on the output the text associated with the robot&apos;s current voice language.&#x0A;You can display and edit the text associated with any language by&#x0A;selecting the language in the combobox.&#x0A;&#x0A;!!Warning!! The text sent on the output is NOT the displayed one but the one&#x0A;associated with the robot&apos;s current voice language." plugin="localizationbox_plugin" x="59" y="54">
                                                <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		try: # disable autoBind
			GeneratedClass.__init__(self, False)
		except TypeError: # if NAOqi < 1.14
			GeneratedClass.__init__( self )

		self.tts = ALProxy("ALTextToSpeech")
		self.sentences = {
			"Arabic" : " هل تحب الشوكولاته؟ ",
			"Czech" : " Máš rád čokoládu? ",
			"Danish" : " Kan du lide chokolade? ",
			"German" : " Mögen Sie Schokolade? ",
			"Greek" : "  ",
			"English" : " Would you like to book an appointment  ",
			"Spanish" : " ¿Te gusta el chocolate? ",
			"Finnish" : " Pidätkö suklaasta? ",
			"French" : " Aimes-tu le chocolat ? ",
			"Italian" : " Ti piace il cioccolato? ",
			"Japanese" : " チョコレートが好きですか ",
			"Korean" : " 당신은 초콜렛을 좋아합니까? ",
			"Dutch" : " Hou je van chocolade? ",
			"Norwegian" : "  ",
			"Polish" : " Lubisz czekoladę? ",
			"Brazilian" : " Você gosta de chocolate? ",
			"Portuguese" : " Gostas de chocolate? ",
			"Russian" : " Вы любите шоколад? ",
			"Swedish" : " Gillar du choklad? ",
			"Turkish" : " Çikolata sever misin? ",
			"Chinese" : "  "
		}

	def onInput_onStart(self):
		sDefaultLang = self.tts.getLanguage()
		self.onStopped(self.sentences[sDefaultLang])]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <![CDATA[هل تحب الشوكولاته؟]]>
</arabic>
                                                    <czech>
                                                        <![CDATA[Máš rád čokoládu?]]>
</czech>
                                                    <danish>
                                                        <![CDATA[Kan du lide chokolade?]]>
</danish>
                                                    <german>
                                                        <![CDATA[Mögen Sie Schokolade?]]>
</german>
                                                    <greek>
                                                        <![CDATA[]]>
</greek>
                                                    <english>
                                                        <![CDATA[Would you like to book an appointment ]]>
</english>
                                                    <spanish>
                                                        <![CDATA[¿Te gusta el chocolate?]]>
</spanish>
                                                    <finnish>
                                                        <![CDATA[Pidätkö suklaasta?]]>
</finnish>
                                                    <french>
                                                        <![CDATA[Aimes-tu le chocolat ?]]>
</french>
                                                    <italian>
                                                        <![CDATA[Ti piace il cioccolato?]]>
</italian>
                                                    <japanese>
                                                        <![CDATA[チョコレートが好きですか]]>
</japanese>
                                                    <korean>
                                                        <![CDATA[당신은 초콜렛을 좋아합니까?]]>
</korean>
                                                    <dutch>
                                                        <![CDATA[Hou je van chocolade?]]>
</dutch>
                                                    <norwegian>
                                                        <![CDATA[]]>
</norwegian>
                                                    <polish>
                                                        <![CDATA[Lubisz czekoladę?]]>
</polish>
                                                    <brazilian>
                                                        <![CDATA[Você gosta de chocolate?]]>
</brazilian>
                                                    <portuguese>
                                                        <![CDATA[Gostas de chocolate?]]>
</portuguese>
                                                    <russian>
                                                        <![CDATA[Вы любите шоколад?]]>
</russian>
                                                    <swedish>
                                                        <![CDATA[Gillar du choklad?]]>
</swedish>
                                                    <turkish>
                                                        <![CDATA[Çikolata sever misin?]]>
</turkish>
                                                    <chinese>
                                                        <![CDATA[]]>
</chinese>
                                                    <language>3</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Data is sent on the output when this input is stimulated." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Data sent when asked." id="3" />
                                            </Box>
                                            <Link inputowner="1" indexofinput="2" outputowner="5" indexofoutput="3" />
                                            <Link inputowner="5" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="0" indexofinput="4" outputowner="1" indexofoutput="5" />
                                            <Link inputowner="0" indexofinput="5" outputowner="1" indexofoutput="6" />
                                            <Link inputowner="0" indexofinput="5" outputowner="1" indexofoutput="7" />
                                            <Link inputowner="0" indexofinput="6" outputowner="1" indexofoutput="8" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Speech" type="Lock" timeout="0" />
                            <Resource name="Speech recognition" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Choice (light) (1)" id="1" localization="8" tooltip="Launch speech recognition, and wait for one of a defined number of expected answers (written in the table of the box). the robot will prompt the speaker if he cannot understand and give suggestions as to available answers and other ways of selecting your choice. e.g. The tactile sensor on his head.&#x0A;&#x0A;Note that you must open this box to enter the question text and the available answers.&#x0A;&#x0A;This is a lighter version of Choice box from standard library which has no animation embedded.&#x0A;&#x0A;V1.1.0&#x0A;" x="1028" y="390">
                            <bitmap>media/images/box/interaction/choice.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                            <Output name="answer" type="3" type_size="1" nature="1" inner="0" tooltip="Answer recognized." id="5" />
                            <Output name="output" type="3" type_size="1" nature="1" inner="0" tooltip="" id="6" />
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Choice" id="1" localization="8" tooltip="Launch the speech recognition waiting for a defined number of predicted answers (written in the table on the box). Available help&#x0A;from the robot which gives some possible answers and attracts attention on the other modalities to answer (head tactile sensor).&#x0A;&#x0A;You can edit a choice by left double-clicking on the line. You can add a choice by right clicking on a line and selecting &apos;Insert a&#x0A;row&apos;. You can delete a choice by right clicking on a line and selecting &apos;Remove a row&apos;. You can also write several alternative&#x0A;answers for the same choice by writing them on the line separated by the character &apos;/&apos;.&#x0A;Ex: apple pie / pie / apple&#x0A;Then if any of these answers (&apos;apple pie&apos;, &apos;pie&apos; or &apos;apple&apos;) are said, the corresponding output will be activated. Indeed, each output&#x0A;which name begins with &apos;output_&apos; correspond to the choice in the list placed just in front of the output.&#x0A;&#x0A;Moreover, you have advanced options appearing when you click on the blue cross. Then you can make the robot calculate the threshold&#x0A;average of choices with the 1/2/3 button. Actually, it will calculate recognition threshold of each alternative answer and put them from&#x0A;highest to smallest threshold. The threshold displayed in front of each choice then is the highest&apos;s." plugin="ui_choice_plugin" x="312" y="51">
                                                <bitmap>media/images/box/interaction/choice.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
# -*- coding: utf-8 -*-
# script of the Choice box v8.8
# @author Desktop Application team
# (c) 2011 Aldebaran Robotics

import os
import time
import random
import thread
import mutex
import xml.dom.minidom

class MyClass(GeneratedClass):
    def __init__(self):
        try: # disable autoBind
          GeneratedClass.__init__(self, False)
        except TypeError: # if NAOqi < 1.14
          GeneratedClass.__init__( self )

        # PROXIES INITIALIZATION
        self.tts = ALProxy("ALTextToSpeech")
        self.ttsStop = ALProxy("ALTextToSpeech", True) #Create another proxy as wait is blocking if audioout is remote
        self.memory = ALProxy("ALMemory")
        try:
            self.asr = ALProxy("ALSpeechRecognition")
            self.ad = ALProxy("ALAudioDevice")
            self.player = ALProxy("ALAudioPlayer")
            self.dcm = ALProxy( "DCM" )
        except:
            self.logger.warning("cannot find ALSpeechRecognition, choice box will run in simulation mode")
            self.asr = None
            self.ad = None
            self.player = None
            self.dcm = None

        self.leds = ALProxy( "ALLeds" )
        # VARIABLES INITIALIZATION
        self.aIdsTTS = []
        self.bSentencesInitialized = False
        self.bMustStop = False
        self.bIsRunning = False
        self.bGoOut = False
        self.nCountNoReply = 0
        self.nCountFailure = 0
        self.aFrameNumbers = {"end" : 1,
                              "headDown" : 10,
                              "bodyTalk" : 20,
                              "reco" : 30,
                              "headCheck" : 40,
                              "helpTactileSensor" : 50,
                              "notUnderstood" : 70}
        self.nFrameNumber = self.aFrameNumbers["end"]
        self.bInConfirmation = False
        self.bVocabularyLoaded = False
        self.bRecoIsHearingOrAnalysing = False
        self.bRecoIsWaitingForVoice = False
        self.bHasAlreadyHearingEyes = False
        self.bInTactileSensorMenu = False
        self.bExternChoices = False
        self.bBrainAnimPaused = False
        self.rTimeLastChoiceSaid = -1.
        self.bIsSayingChoice = False
        self.nIndexChoice = 0
        self.sRecoInterruption = "" # = "wordRecognised" or "timeout" or "onStop" or "onTactileSensor"
        self.sPreviousAnswer = ""
        self.rTimeWhenActionMadeInTactileMenu = -1.
        # variables used for the tactile sensor
        self.nFront = 0
        self.nMiddle = 0
        self.nRear = 0
        self.bSeqStarted = False
        self.bIsStoringParam = False
        self.bPressed = False
        self.mutexProcessCurrentState = mutex.mutex()
        self.mutexTactilTouched = mutex.mutex()
        self.mutexCheckIfSeqsCorrespondingLeft = mutex.mutex()
        self.bSeqStarted = False
        # assuming that every sequence is after [0, 0, 0]
        # and then start with one tactil sensor activated
        # timeout must be either a number (int or float) not equal to 0 or an array of two numbers not equal to 0, a negative one and a positive one
        # a negative timeout means a minimum time that has to ellapse before the next step
        # a positive timeout means a maximum time before the next step must show up
        self.aSeqs = [{"name" : "Tap", "statesAndTimeout" : [ "1+", 0.35, "2+", 0.45, "0" ]},
                      {"name" : "TapFront", "statesAndTimeout" : [ "F", 1, "0" ]},
                      {"name" : "LongFront", "statesAndTimeout" : [ "F", -1, "F" ]},
                      {"name" : "TapMiddle", "statesAndTimeout" : [ "M", 1, "0" ]},
                      {"name" : "LongMiddle", "statesAndTimeout" : [ "M", -1, "M" ]},
                      {"name" : "TapRear", "statesAndTimeout" : [ "R", 1, "0" ]},
                      {"name" : "LongRear", "statesAndTimeout" : [ "R", -1, "R" ]},
                      {"name" : "CalmDown", "statesAndTimeout" : [ "1+", 0.5, "2+", -1, "2+" ]}]
        # sequences initialization
        aSeqsTemp = []
        for seq in self.aSeqs:
            try: # ensure that the sequence has at least a name and states and timeout defined
                seq["name"]
                seq["statesAndTimeout"]
                aSeqsTemp.append(seq)
            except:
                pass
        self.aSeqs = aSeqsTemp
        for seq in self.aSeqs:
            states = range( len( seq["statesAndTimeout"][0:len(seq["statesAndTimeout"]):2] ) )
            i = 0
            for state in seq["statesAndTimeout"][0:len(seq["statesAndTimeout"]):2]:
                states[i] = self.convertToArrayOfPossibleStates(state)
                i += 1
            seq["statesAndTimeout"][0:len(seq["statesAndTimeout"]):2] = states
        self.aDetectedSeqs = []
        self.aDetectedSeqs.extend(self.aSeqs)
        # end - variables used for the tactile sensor
        self.aChoices = []
        self.aChoiceIndexes = []
        # parameters which can be changed from the parameters edition window
        self.sQuestion = ""
        self.nTimeoutReco = 6
        self.nTimeoutRecoConfirmation = 6
        self.nTimeoutTactile = 10
        self.nMaxCountNoReply = 3
        self.nMaxCountFailure = 5
        self.arUnderstoodThreshold = [0.0, 1.0] # range of self.rUnderstoodThreshold
        self.arConfirmationThreshold = [0.0, 1.0] # range of self.rConfirmationThreshold (must be higher than self.arUnderstoodThreshold)
        self.rUnderstoodThreshold = 0.2
        self.rConfirmationThreshold = 0.4
        self.bActivateEyesLight = True
        self.bActivateEarsLight = True
        self.bActivateBrainLight = True
        self.bActivateHelpWhenFailure = True
        self.bRepeatValidatedChoice = True
        self.bActivateDefaultChoiceHelp = True
        self.bActivateDefaultChoiceRepeat = True
        self.bActivateDefaultChoiceExit = True
        self.BIND_PYTHON(self.getName(), "onTactilTouched")
        self.BIND_PYTHON(self.getName(), "onWordRecognized")
        self.BIND_PYTHON(self.getName(), "onSpeechDetected")


# FUNCTIONS ===============================================================================================

    def onLoad(self):
        # initialize sentences for each language
        if( not self.bSentencesInitialized ):
            self.initializeSentences()
            self.bSentencesInitialized = True

# XML PARSER FOR SENTENCES INITIALIZATION
    def initializeSentences(self):
        "Initialize necessary sentences in each language."
        framemanager = ALProxy("ALFrameManager")
        filename = framemanager.getBehaviorPath(self.behaviorId) + self.tryGetParameter( "Sentences file", "/Aldebaran/choice_sentences.xml" )
        if not self.fileExists(filename):
            raise RuntimeError("File " + filename + " could not be found. Please update your Choice box with a newer one from Choregraphe")
        try:
            doc = self.getFileContents( filename )
            dom = xml.dom.minidom.parseString( doc )
        except Exception as e:
            raise Exception( "The " + filename + " file is not in the right format. Check the special characters and that the syntax is correct.\n" + str(e) )
        try:
            tag = "sentences"
            mainBlock = dom.getElementsByTagName( tag )[0]
            tag = "translation"
            aTranslations = mainBlock.getElementsByTagName( tag )
            self.aAllWords = {}
            self.aAllSentences = {}
            for sTranslation in aTranslations:
                sLanguage = sTranslation.getAttribute("language")
                tag = "speechReco"
                blockSpeechReco = sTranslation.getElementsByTagName( tag )[0]
                # variable used for the speech recognition
                self.aAllWords[sLanguage] = {}
                aKinds = ["negative",
                          "positive",
                          "help",
                          "exit",
                          "repeat"]
                for sKind in aKinds:
                    tag = sKind
                    blockWordsForThisKind = blockSpeechReco.getElementsByTagName( sKind )[0]
                    self.aAllWords[sLanguage][sKind] = blockWordsForThisKind.getAttribute( "text" ).encode("utf-8").split("/")
                # end - variable used for the speech recognition
                tag = "tts"
                blockTTS = sTranslation.getElementsByTagName( tag )[0]
                # variable used for the Text-To-Speech
                self.aAllSentences[sLanguage] = {}
                aKinds = ["confirmation",
                          "enumMarks",
                          "helpEnumChoices",
                          "helpEnumDefault",
                          "helpTactile",
                          "notUnderstood",
                          "noQuestion",
                          "notUnderstoodAnims"]
                for sKind in aKinds:
                    tag = sKind
                    blockSentencesForThisKind = blockTTS.getElementsByTagName( sKind )[0]
                    self.aAllSentences[sLanguage][sKind] = blockSentencesForThisKind.getAttribute( "text" ).encode("utf-8").split("/")
                # end - variable used for the Text-To-Speech
        except Exception as e:
            raise Exception( "The " + filename + " file is not in the right format. Check that the '" + tag + "' tag is defined and with the right format.\n" + str(e) )

        # choices
        # !!! don't remove any comments from this variable !!!
        # (they are here to make the plugin work)
        self.aListAllChoices = {"Arabic": ["نعم", "لا", "", ""], "Brazilian": ["sim", "não", "", ""], "Chinese": ["是", "不是", "", ""], "Czech": ["ano", "ne", "", ""], "Danish": ["ja", "nej", "", ""], "Dutch": ["ja", "nee", "", ""], "English": ["", "No", "Yes", ""], "Finnish": ["kyllä", "ei", "", ""], "French": ["oui", "non", "", ""], "German": ["ja", "nein", "", ""], "Greek": ["ναί", "κανένα", "", ""], "Italian": ["sì", "no", "", ""], "Japanese": ["はい", "いいえ", "", ""], "Korean": ["예", "아니", "", ""], "Norwegian": ["ja", "Nei", "", ""], "Polish": ["tak", "nie", "", ""], "Portuguese": ["sim", "não", "", ""], "Russian": ["да", "нет", "", ""], "Spanish": ["si", "no", "", ""], "Swedish": ["ja", "ingen", "", ""], "Turkish": ["evet", "hayır", "", ""]
                               }
        # end - choices

# INPUTS ACTIVATION PROCESSING ------------------------------------------------------------------------------
    def onInput_onStart(self, question=None):
        "Initialize variables and start box behaviour."
        self.logger.debug( "Input onStart stimulated." )
        if( self.bIsRunning): # to avoid starting the process twice
            return
        self.bIsRunning = True
        if(self.asr != None):
            self.asr.setVisualExpression( False )
        language = self.tts.getLanguage()
        if(self.asr != None):
            self.asr.setLanguage( language )
        try:
            self.aAllWords[language]
            self.aAllSentences[language]
        except:
            raise Exception( "The current language is not supported by this Choice box. It is probably deprecated. Try to use the one supplied in Choregraphe library instead." )
        self.asNegativeWords = self.aAllWords[language]["negative"]
        self.asPositiveWords = self.aAllWords[language]["positive"]
        self.asHelpWords = self.aAllWords[language]["help"]
        self.asExitWords = self.aAllWords[language]["exit"]
        self.asRepeatWords = self.aAllWords[language]["repeat"]
        self.bGoOut = False
        self.bVocabularyLoaded = False
        self.bRecoIsHearingOrAnalysing = False
        self.bRecoIsWaitingForVoice = False
        self.bHasAlreadyHearingEyes = False
        self.sRecoInterruption = ""
        self.sPreviousAnswer = ""
        self.bMustStop = False
        self.nCountNoReply = 0
        self.nCountFailure = 0
        self.nFrameNumber = self.aFrameNumbers["end"]
        self.beginTime = time.time()
        self.bInConfirmation = False
        self.bInTactileSensorMenu = False
        self.bBrainAnimPaused = False
        self.bPressed = False
        self.rTimeWhenActionMadeInTactileMenu = -1.
        self.nFront = 0
        self.nMiddle = 0
        self.nRear = 0
        self.bSeqStarted = False
        self.bIsStoringParam = False
        self.rUnderstoodThreshold = self.tryGetParameter( "Minimum threshold to understand", 0.2 )
        self.rConfirmationThreshold = self.tryGetParameter( "Minimum threshold to be sure", 0.4 )
        self.nTimeoutReco = self.tryGetParameter( "Speech recognition timeout", 6 )
        self.nTimeoutRecoConfirmation = self.tryGetParameter( "Speech recognition timeout when confirmation", 6 )
        self.nTimeoutTactile = self.tryGetParameter( "Tactile sensor menu timeout", 10 )
        self.nMaxCountNoReply = self.tryGetParameter( "Maximum number of repetition when no reply", 3 )
        self.nMaxCountFailure = self.tryGetParameter( "Maximum number of repetition when failure", 5 )
        self.bActivateEyesLight = self.tryGetParameter( "Activate eyes light", True )
        self.bActivateEarsLight = self.tryGetParameter( "Activate ears light", True )
        self.bActivateBrainLight = self.tryGetParameter( "Activate brain light", True )
        self.bActivateHelpWhenFailure = self.tryGetParameter( "Activate help when failure", True )
        self.bRepeatValidatedChoice = self.tryGetParameter( "Repeat validated choice", True )
        self.bActivateDefaultChoiceHelp = self.tryGetParameter( "Activate help command", True )
        self.bActivateDefaultChoiceRepeat = self.tryGetParameter( "Activate repeat command", True )
        self.bActivateDefaultChoiceExit = self.tryGetParameter( "Activate exit command", True )
        self.aDefaultChoices = []
        if (self.bActivateDefaultChoiceHelp):
            self.aDefaultChoices.append( self.asHelpWords )
        if (self.bActivateDefaultChoiceRepeat):
            self.aDefaultChoices.append( self.asRepeatWords )
        if (self.bActivateDefaultChoiceExit):
            self.aDefaultChoices.append( self.asExitWords )
        if( question == None ):
            question = ""
        self.initQuestionAndChoices( question )
        if( len( self.aChoices ) > len( self.aDefaultChoices ) ): # if there is at least one choice (not a default one)
            self.nIndexChoice = len( self.aDefaultChoices )
        else: # if there are only default words
            self.nIndexChoice = 0
        self.bGoOut = False
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFFFFFF, 0.1 )
        # initialize tactile sensor handler
        self.initSeqDetected()
        # subscribe to tactile sensors extractors (launch tactile sensor handler)
        self.memory.subscribeToEvent( "FrontTactilTouched", self.getName(), "onTactilTouched" )
        self.memory.subscribeToEvent( "MiddleTactilTouched", self.getName(), "onTactilTouched" )
        self.memory.subscribeToEvent( "RearTactilTouched", self.getName(), "onTactilTouched" )
        thread.start_new_thread( self.loopLedsBrainTwinkle, () )
        while( not self.bGoOut ):
            self.questionRecognitionReaction()
        if( self.bInTactileSensorMenu ):
            self.nCountNoReply = 0
            if( self.nFrameNumber != self.aFrameNumbers["headDown"] ):
                self.nFrameNumber = self.aFrameNumbers["headDown"]
                try:
                    self.getTimeline().goTo(self.nFrameNumber)
                except: # if NAOqi < 1.14
                    try:
                        self.gotoAndStop(self.nFrameNumber)
                    except:
                        pass
            self.loopLedsBrainTurn()
        else:
            self.bIsRunning = False

    def onInput_choicesList(self, p):
        "Set choices list."
        self.logger.debug( "Input choicesList stimulated." )
        if( not self.bIsRunning ):
            self.bExternChoices = True
            language = "English"
            if(self.asr != None):
                language =  self.asr.getLanguage()
            self.asNegativeWords = self.aAllWords[language]["negative"]
            self.asPositiveWords = self.aAllWords[language]["positive"]
            self.asHelpWords = self.aAllWords[language]["help"]
            self.asExitWords = self.aAllWords[language]["exit"]
            self.asRepeatWords = self.aAllWords[language]["repeat"]
            self.bActivateDefaultChoiceHelp = self.tryGetParameter( "Activate help command", True )
            self.bActivateDefaultChoiceRepeat = self.tryGetParameter( "Activate repeat command", True )
            self.bActivateDefaultChoiceExit = self.tryGetParameter( "Activate exit command", True )
            self.aDefaultChoices = []
            if (self.bActivateDefaultChoiceHelp):
                self.aDefaultChoices.append( self.asHelpWords )
            if (self.bActivateDefaultChoiceRepeat):
                self.aDefaultChoices.append( self.asRepeatWords )
            if (self.bActivateDefaultChoiceExit):
                self.aDefaultChoices.append( self.asExitWords )
            self.aChoices = []
            self.aChoiceIndexes = []
            self.aChoices.extend( self.aDefaultChoices )
            index = 0
            for choice in p:
                if( self.isString(choice) ):
                    choice = choice.strip(" \t,;.\n") # remove space or tabs at beginning or end of a choice
                    if( choice != "" ):
                        choice = [ choice ]
                    else:
                        choice = []
                elif( self.isArray(choice) ):
                    if( choice != [] ):
                        for i in range( len( choice ) ):
                            if( self.isString(choice[i]) ):
                                choice[i] = choice[i].strip(" \t,;.\n") # remove space or tabs at beginning or end of a choice
                                if( len( choice[i] ) < 1 ):
                                    del choice[i]
                                    i -= 1 # to parse the good one next loop
                            else:
                                raise Exception( "Error in choices input syntax:\nIt must be an array of choices and each choice can be either a string or an array of strings (several possibilities for one choice)\nEx: ['choice1',['choice2a','choice2b']]\nbut: " + str(p) + " found" )
                else:
                    raise Exception( "Error in choices input syntax:\nIt must be an array of choices and each choice can be either a string or an array of strings (several possibilities for one choice)\nEx: ['choice1',['choice2a','choice2b']]\nbut: " + str(p) + " found" )
                if( len( choice ) > 0 ):
                    for sWord in choice:
                        for aDefaultChoice in self.aDefaultChoices:
                            if( sWord in aDefaultChoice ):
                                raise Exception( "Error in input choices list: You chose a word which is already used for default choices:\n" + str(sWord) + " is used for the default choice: " + str(aDefaultChoice[0]) )
                    self.aChoices.append( choice )
                    self.aChoiceIndexes.append( index )
                index += 1

    def onInput_onStop(self):
        "Stop box behaviour."
        self.logger.debug( "Input onStop stimulated." )
        if( self.bIsRunning ):
            self.goOut( self.asExitWords[0], "onStop" )
            self.sRecoInterruption = "onStop"
        else:
            self.onUnload()

# GENERAL FUNCTIONS ------------------------------------------------------------------------------------------

    def isString(self, strVariable):
        try:
            if( type( strVariable ) == type( "some string" ) ):
                return True
        except:
            pass
        return False

    def isArray(self, aVariable):
        try:
            if( type( aVariable ) == type( ["some array"] ) ):
                return True
        except:
            pass
        return False

    def fileExists(self, strPathFilename ):
        try:
            file = open( strPathFilename, 'r' )
            if( file ):
                file.close()
                return True
        except (IOError, os.error), err:
            pass
        return False

    def getFileContents(self, sFilename ):
        "read a file and return it's contents, or '' if not found, empty, ..."
        try:
            fileContent = open( sFilename )
            aBuf = fileContent.read()
            fileContent.close()
        except:
            try:
                fileContent.close()
            except:
                pass
            return ""
        return aBuf

    def getBrainLedName(self, nNumLed):
        "Get the name of the DCM led device from its number"
        "0 => front left; 1 => next in clock wise; until 11"
        numLed = nNumLed%12
        if( numLed <= 1 ):
            return "Head/Led/Front/Right/%d/Actuator/Value" % (1-numLed)
        elif( numLed >= 10 ):
            return "Head/Led/Front/Left/%d/Actuator/Value" % (numLed-10)
        elif( numLed <= 2 ):
            return "Head/Led/Middle/Right/%d/Actuator/Value" % (2-numLed)
        elif( numLed >= 9 ):
            return "Head/Led/Middle/Left/%d/Actuator/Value" % (numLed-9)
        elif( numLed <= 5 ):
            return "Head/Led/Rear/Right/%d/Actuator/Value" % (numLed-3)
        else:
            return "Head/Led/Rear/Left/%d/Actuator/Value" % (8-numLed)

    def skipTTS(self):
        for idtts in self.aIdsTTS:
            try:
                self.ttsStop.stop(idtts)
            except:
                self.logger.debug( "Warning: The Text-To-Speech could not have been stopped." )

    def tryGetParameter(self, sParameterName, defaultValue):
        try:
            return self.getParameter( sParameterName )
        except:
            return defaultValue

# QUESTION AND CHOICES INITIALIZATION ----------------------------------------------------------------------

    def initQuestionAndChoices(self, p):
        "Initialize the question and the choices."
        # question processing
        if( self.isString(p) ):
            self.sQuestion = p
        else:
            raise Exception( "Error in question input syntax:\nQuestion text\nexpected for example, but:\n" + str(p[0]) + "\nfound" )
        # choices processing
        if( not self.bExternChoices ):
            self.aChoices = []
            self.aChoiceIndexes = []
            self.aChoices.extend( self.aDefaultChoices )
            index = 0
            listChoices = self.aListAllChoices[self.tts.getLanguage()]
            for choice in listChoices:
                aChoice = choice.split( "/" )
                if( aChoice != [] ):
                    for i in range( len( aChoice ) ):
                        aChoice[i] = aChoice[i].strip(" \t,;.\n") # remove space or tabs at beginning or end of a choice
                        if( len( aChoice[i] ) < 1 ):
                            del aChoice[i]
                            i -= 1 # to parse the good one next loop
                if( len( aChoice ) > 0 ):
                    # check if there is a word which is already used for the default choices
                    for sWord in aChoice:
                        for aDefaultChoice in self.aDefaultChoices:
                            if( sWord in aDefaultChoice ):
                                raise Exception( "Error in choices list: You chose a word which is already used for default choices:\n" + str(sWord) + " is used for the default choice: " + str(aDefaultChoice[0]) )
                    # append the choice to the list if everything worked well
                    self.aChoices.append( aChoice )
                    self.aChoiceIndexes.append( index )
                index += 1
        # check that there is at least one choice (a default one or not)
        if( len( self.aChoices ) < 1 ):
            raise Exception( "Error in choices list: It is empty. There is no default choice nor choice entered." )

# QUESTION-RECOGNITION-REACTION -----------------------------------------------------------------------------

    def questionRecognitionReaction(self):
        "Ask question, launch speech recognition and process answer."
        self.ttsQuestionAndRecoInit()
        if( not self.bMustStop ):
            # stop movement animation
            if( self.nFrameNumber != self.aFrameNumbers["reco"] ):
                self.nFrameNumber = self.aFrameNumbers["reco"]
                try:
                    self.getTimeline().goTo(self.nFrameNumber)
                except: # if NAOqi < 1.14
                    try:
                        self.gotoAndStop(self.nFrameNumber)
                    except:
                        pass
            # start speech recognition
            self.logger.debug( "Speech recognition started." )
            self.memory.subscribeToEvent( "WordRecognized", self.getName(), "onWordRecognized" )
            self.bRecoIsWaitingForVoice = True
            self.memory.subscribeToEvent( "SpeechDetected", self.getName(), "onSpeechDetected" )
        # leds during the recognition
        self.loopLedsReco()
        # process the reco loop break
        self.processRecoInterruption()

    def ttsQuestionAndRecoInit(self):
        "Ask question and initialize the speech recognition during the question to gain time in the interaction."
        if( not self.bInConfirmation ):
            # launch TTS
            idTTS = -1
            if( self.sQuestion != ""):
                idTTS = self.tts.post.say( self.sQuestion )
                self.aIdsTTS.append( idTTS )
                self.logger.debug( "Robot says: " + str(self.sQuestion) )
                # launch TTS movement animation
                if( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ):
                    self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
            # prepare speech recognition
            if(self.asr != None):
                self.asr.setLanguage( self.tts.getLanguage() )
            if( not self.bVocabularyLoaded ):
                aWordsRecognised = []
                for i in range( len( self.aChoices ) ):
                    if( self.aChoices[i] != [] ):
                        aWordsRecognised.extend( self.aChoices[i] )
                sWordsRecognised = "You can say: "
                if( len( aWordsRecognised ) > 1 ):
                    for i in range( len( aWordsRecognised ) - 1 ):
                        sWordsRecognised += "'" + aWordsRecognised[i] + "', "
                if( len( aWordsRecognised ) > 0 ):
                    sWordsRecognised += "'" + aWordsRecognised[len( aWordsRecognised ) - 1] + "'"
                sWordsRecognised += "."
                self.logger.debug( sWordsRecognised )
                if(self.asr != None):
                    self.asr.setVocabulary( aWordsRecognised, False )
                self.bVocabularyLoaded = True
        else:
            # launch TTS
            sentence = self.aAllSentences[self.tts.getLanguage()]["confirmation"][0]
            idTTS = -1
            sentenceToSay = sentence % self.sPreviousAnswer
            if( sentenceToSay != ""):
                idTTS = self.tts.post.say( sentenceToSay )
                self.aIdsTTS.append( idTTS )
                self.logger.debug( "Robot says: " + str(sentenceToSay) )
                # launch TTS movement animation
                if( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ):
                    self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
            # prepare speech recognition
            aWordsRecognised = []
            aWordsRecognised.extend( self.asNegativeWords )
            aWordsRecognised.extend( self.asPositiveWords )
            sWordsRecognised = "You can say: "
            if( len( aWordsRecognised ) > 1 ):
                for i in range( len( aWordsRecognised ) - 1 ):
                    sWordsRecognised += "'" + aWordsRecognised[i] + "', "
            if( len( aWordsRecognised ) > 0 ):
                sWordsRecognised += "'" + aWordsRecognised[len( aWordsRecognised ) - 1] + "'"
            sWordsRecognised += "."
            self.logger.debug( sWordsRecognised )
            if(self.asr != None):
                self.asr.setVocabulary( aWordsRecognised, False )
            self.bVocabularyLoaded = False
        # wait for the end of the TTS
        if( idTTS != -1 ):
            try:
                self.tts.wait( idTTS, 0 )
            except:
                self.logger.debug( "Warning: Could not wait the TTS." )

    def processRecoInterruption(self):
        "Process speech recognition interruption (timeout, action on tactile sensor, word said, etc...)"
        # wait for the end of the reaction (help, not understood, etc...)
        while( self.sRecoInterruption == "" ):
            time.sleep( 0.2 )
        self.logger.debug( "The speech recognition has been interrupted because of: " + str(self.sRecoInterruption) + "." )
        if( self.sRecoInterruption == "timeout" ): # if recognition interrupted by timeout
            try:
                # stop recognition
                self.memory.unsubscribeToEvent( "WordRecognized", self.getName() )
                self.bRecoIsWaitingForVoice = False
                self.bRecoIsHearingOrAnalysing = False
                self.logger.debug( "Speech recognition stopped." )
                self.memory.unsubscribeToEvent( "SpeechDetected", self.getName() )
            except:
                pass
            if( self.bInConfirmation ): # if it was a confirmation question
                # leds noticing that the robot confirm its guessing
                thread.start_new_thread( self.ledsUnderstood, (True, False) )
                # if nothing has been said, we assume that the user agree
                self.bInConfirmation = False
                if( self.sPreviousAnswer in self.asHelpWords ): # if help asked
                    self.helpWhenAsked()
                elif( self.sPreviousAnswer in self.asRepeatWords ): # if repeat asked
                    self.repeatWhenNoQuestion()
                    # repeat the question
                else: # if not repeat nor help asked
                    self.goOut( self.sPreviousAnswer, "wordRecognised" )
            else:
                # reinitialize leds
                self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
                self.nCountNoReply += 1
                if( self.nCountNoReply >= self.nMaxCountNoReply ):
                    self.goOut( self.asExitWords[0], "timeout" )
        else:
            self.nCountNoReply = 0
            if( self.sRecoInterruption in [ "onStop" ] ):
                self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        self.sRecoInterruption = ""

    def repeatWhenNoQuestion(self):
        "Robot's reaction when it is asked to repeat the question when there is no question."
        if( self.sQuestion == "" ):
            sentenceNoQuestion = self.aAllSentences[self.tts.getLanguage()]["noQuestion"][0]
            sentenceNoQuestion += self.enumerateChoices( True ) # True to ask that the introduction is played
            if( len( self.aChoices ) - len( self.aDefaultChoices ) == 0 ): # if there is no choice
                sentenceNoQuestion += self.enumerateDefaultChoices( True ) # True to ask that the introduction is played
            # launch TTS
            idTTS = -1
            if( sentenceNoQuestion != ""):
                if( self.bInTactileSensorMenu ):
                    idTTS = self.tts.post.say( sentenceNoQuestion + "\\Pau=300\\" )
                else:
                    idTTS = self.tts.post.say( sentenceNoQuestion )
                self.aIdsTTS.append( idTTS )
                self.logger.debug( "Robot says: " + str(sentenceNoQuestion) )
                if( not self.bInTactileSensorMenu ):
                    # launch TTS movement animation
                    if( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ):
                        self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                        try:
                            self.getTimeline().goTo(self.nFrameNumber)
                        except: # if NAOqi < 1.14
                            try:
                                self.gotoAndStop(self.nFrameNumber)
                            except:
                                pass
            # wait for the end of the TTS
            if( idTTS != -1 ):
                try:
                    self.tts.wait( idTTS, 0 )
                except:
                    self.logger.debug( "Warning: Could not wait the TTS." )

# RECO OUTPUT PROCESSING --------------------------------------------------------------------------------------

    def onWordRecognized(self, pDataName, pValue, pMessage):
        "Handler for when a word is recognised by the speech recognition system."
        aState = pValue
        self.logger.debug( "The word '" + str(aState[0]) + "' has been recognised with a threshold of " + str(aState[1]) + "." )
        # interrupt loops:
            # - stop reco
            # - stop leds
            # - stop asking the question on and on
        try:
            self.memory.unsubscribeToEvent( "WordRecognized", self.getName() )
            self.logger.debug( "Speech recognition stopped." )
            self.memory.unsubscribeToEvent( "SpeechDetected", self.getName() )
        except:
            pass
        self.bRecoIsHearingOrAnalysing = False
        self.bRecoIsWaitingForVoice = False
        if( aState[0] != "" ):
            if( aState[1] >= self.rUnderstoodThreshold ):
                if( self.rUnderstoodThreshold <= self.arUnderstoodThreshold[1] - 0.02 ):
                    self.rUnderstoodThreshold += 0.02
                else:
                    self.rUnderstoodThreshold = self.arUnderstoodThreshold[1]
                if( self.bInConfirmation ):
                    if( aState[0] in self.asNegativeWords ):
                        thread.start_new_thread( self.ledsNegative, () )
                    else:
                        thread.start_new_thread( self.ledsUnderstood, (True, False) )
                else:
                    thread.start_new_thread( self.ledsUnderstood, (True, False) )
                self.reactionWordUnderstood( aState )
            else:
                if( self.rUnderstoodThreshold >= self.arUnderstoodThreshold[0] + 0.05 ):
                    self.rUnderstoodThreshold -= 0.05
                else:
                    self.rUnderstoodThreshold = self.arUnderstoodThreshold[0]
                aCurrentChoice = ""
                for choice in self.aChoices:
                    if( aCurrentChoice == "" ):
                        if( aState[0] in choice ):
                            aCurrentChoice = choice
                if( self.sPreviousAnswer in aCurrentChoice ): # if answer in the same choice as previously
                    # then ask confirmation
                    aState[1] = self.rConfirmationThreshold - 0.01
                    thread.start_new_thread( self.ledsUnderstood, (True, False) )
                    self.reactionWordUnderstood( aState )
                else:
                    # else not understood
                    if( self.bInConfirmation ):
                        thread.start_new_thread( self.ledsUnderstood, (True, False) )
                    else:
                        self.sPreviousAnswer = aState[0]
                        thread.start_new_thread( self.ledsNotUnderstood, () )
                    self.reactionNothingUnderstood()
        else:
            if( self.bInConfirmation ):
                thread.start_new_thread( self.ledsUnderstood, (True, False) )
            else:
                thread.start_new_thread( self.ledsNotUnderstood, () )
            self.reactionNothingUnderstood()
        if( pMessage == "" ):
            self.sRecoInterruption = "wordRecognised"
        else:
            self.sRecoInterruption = pMessage

    def onSpeechDetected(self, pDataName, pValue, pMessage):
        "Handler for when something has been heard by the speech recognition system."
        aState = pValue
        if( aState == 1):
            if( self.bRecoIsWaitingForVoice ):
                # make eyes leds switch from an animation to an other
                self.bRecoIsHearingOrAnalysing = True
                self.bRecoIsWaitingForVoice = False
                try:
                    self.timeToReply(time.time() - self.beginTime)
                except:
                    pass

    def reactionWordUnderstood(self, word):
        "Reaction depending on the word recognised (help, repeat, word in choices, etc...) and its recognition confidence."
        if( self.bInConfirmation ):
            self.bInConfirmation = False
            if( word[0] in self.asNegativeWords ):
                # update number of failures
                self.nCountFailure += 1
                if( self.sPreviousAnswer in self.asHelpWords ):
                    if( self.nCountFailure >= self.nMaxCountFailure ): # if maximum number of failures
                        # skip the question
                        self.goOut( self.asExitWords[0], "notUnderstood" )
                else:
                    self.helpAfterFailure()
            else:
                if( (self.sPreviousAnswer in self.asHelpWords) or (word[0] in self.asHelpWords) ):
                    self.helpWhenAsked()
                elif( self.sPreviousAnswer in self.asRepeatWords or (word[0] in self.asRepeatWords) ):
                    self.repeatWhenNoQuestion()
                    # repeat the question
                else:
                    self.goOut( self.sPreviousAnswer, "wordRecognised" )
                self.sPreviousAnswer = ""
        else:
            self.sPreviousAnswer = word[0]
            if( word[1] >= self.rConfirmationThreshold ):
                if( self.rConfirmationThreshold <= self.arConfirmationThreshold[1] - 0.02 ):
                    self.rConfirmationThreshold += 0.02
                else:
                    self.rConfirmationThreshold = self.arConfirmationThreshold[1]
                if( self.sPreviousAnswer in self.asHelpWords ):
                    self.helpWhenAsked()
                elif( self.sPreviousAnswer in self.asRepeatWords ):
                    self.repeatWhenNoQuestion()
                    # repeat the question
                else:
                    self.goOut( self.sPreviousAnswer, "wordRecognised" )
                self.sPreviousAnswer = ""
            else:
                if( self.rConfirmationThreshold >= self.arConfirmationThreshold[0] + 0.05 ):
                    self.rConfirmationThreshold -= 0.05
                else:
                    self.rConfirmationThreshold = self.arConfirmationThreshold[0]
                self.bInConfirmation = True

    def reactionNothingUnderstood(self):
        "Reaction when nothing has been understood or without an enough confidence."
        if( self.bInConfirmation ):
            # if the robot did not understand, we assume that the user agree
            self.bInConfirmation = False
            if( self.sPreviousAnswer in self.asHelpWords ): # if help asked
                self.helpWhenAsked()
            elif( self.sPreviousAnswer in self.asRepeatWords ): # if repeat asked
                self.repeatWhenNoQuestion()
                # repeat the question
            else: # if not repeat nor help asked
                self.goOut( self.sPreviousAnswer, "wordRecognised" )
        else:
            # update number of failures
            self.nCountFailure += 1
            if( self.nCountFailure <= 1 ): # if first failure
                sentence = self.aAllSentences[self.tts.getLanguage()]["notUnderstood"][0]
            else: # if second failure or more
                sentenceNotUnderstoodAnims = self.aAllSentences[self.tts.getLanguage()]["notUnderstoodAnims"]
                index = random.randint( 0, len( sentenceNotUnderstoodAnims ) - 1 )
                sentence = sentenceNotUnderstoodAnims[index]
                if( self.nFrameNumber != self.aFrameNumbers["notUnderstood"] + 10*index ):
                    self.nFrameNumber = self.aFrameNumbers["notUnderstood"] + 10*index
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
            self.helpAfterFailure( sentence )

# HELP ------------------------------------------------------------------------------------------------------

    def enumerateChoices(self, bIntroToSay):
        "Enumerate choices (only the first word of each choice is taken into account)."
        sentenceHelpEnumChoices = self.aAllSentences[self.tts.getLanguage()]["helpEnumChoices"]
        sentenceHelpEnumMarks = self.aAllSentences[self.tts.getLanguage()]["enumMarks"]
        enumWords = ""
        maxNbEnumChoices = 3
        indexes = []
        for i in range( min(maxNbEnumChoices, len( self.aChoices ) - len( self.aDefaultChoices )) ):
            if( len( self.aChoices ) - len( self.aDefaultChoices ) <= maxNbEnumChoices ):
                index = len( self.aDefaultChoices ) + i
            else:
                index = random.randint( len( self.aDefaultChoices ), len( self.aChoices ) - 1 )
                while( index in indexes ):
                    index = random.randint( len( self.aDefaultChoices ), len( self.aChoices ) - 1 )
            indexes.append( index )
            if( len( indexes ) != 1 ): # if it is not the first choice
                if( len( indexes ) != min(maxNbEnumChoices, len( self.aChoices ) - len( self.aDefaultChoices )) ): # if it is not the last choice
                    enumWords += sentenceHelpEnumMarks[0]
                else:
                    enumWords += sentenceHelpEnumMarks[1]
            enumWords += self.aChoices[index][0]
        sentenceTemplate = sentenceHelpEnumChoices[2]
        if( len( self.aChoices ) - len( self.aDefaultChoices ) <= maxNbEnumChoices ): # if there are 3 or less choices
            sentenceTemplate = sentenceHelpEnumChoices[1]
        if( not bIntroToSay ):
            sentenceTemplate = sentenceHelpEnumChoices[3]
        if( len( self.aChoices ) - len( self.aDefaultChoices ) == 0 ): # if there is no choice
            sentence = sentenceHelpEnumChoices[0]
        else:
            sentence = sentenceTemplate % enumWords
        return sentence

    def enumerateDefaultChoices(self, bIntroToSay):
        "Enumerate default choices (only the first word of each choice is taken into account)."
        sentenceHelpEnumChoices = self.aAllSentences[self.tts.getLanguage()]["helpEnumChoices"]
        sentenceHelpEnumDefault = self.aAllSentences[self.tts.getLanguage()]["helpEnumDefault"]
        sentenceHelpEnumMarks = self.aAllSentences[self.tts.getLanguage()]["enumMarks"]
        enumWords = ""
        indexes = []
        for i in range( len( self.aDefaultChoices ) ):
            indexes.append( i )
            if( len( indexes ) != 1 ): # if it is not the first choice
                if( len( indexes ) != len( self.aDefaultChoices ) ): # if it is not the last choice
                    enumWords += sentenceHelpEnumMarks[0]
                else:
                    enumWords += sentenceHelpEnumMarks[1]
            enumWords += self.aDefaultChoices[i][0]
        sentenceTemplate = sentenceHelpEnumDefault[0]
        if( not bIntroToSay ):
            sentenceTemplate = sentenceHelpEnumChoices[3]
        if( len( self.aDefaultChoices ) == 0 ): # if there is no default choice
            sentence = ""
        else:
            sentence = sentenceTemplate % enumWords
        return sentence

    def explanationTactileSensor(self):
        "Explain the possible interaction with the tactile sensor."
        sentenceHelpTactile = self.aAllSentences[self.tts.getLanguage()]["helpTactile"]
        if( self.bInTactileSensorMenu ):
            sentence = sentenceHelpTactile[1]
        else:
            sentence = sentenceHelpTactile[0]
        return sentence

    def helpWhenAsked(self, sentence = ""):
        "Help when the user asked it: enumerate choices, enumerate default choices and explain tactile sensor possible interaction."
        if( not self.bInTactileSensorMenu ):
            # enumeration of choices
            sentence += self.enumerateChoices( True ) # True to ask that the introduction is played
            # enumeration of default choices
            sentence += self.enumerateDefaultChoices( True ) # True to ask that the introduction is played
        # explanation about alternative modality (tactil sensor, arm motion)
        sentence += self.explanationTactileSensor()
        # launch TTS
        idTTS = -1
        if( sentence != "" ):
            if( self.bInTactileSensorMenu ):
                idTTS = self.tts.post.say( sentence + "\\Pau=300\\" )
            else:
                idTTS = self.tts.post.say( sentence )
            self.aIdsTTS.append( idTTS )
            self.logger.debug( "Robot says: " + str(sentence) )
            # launch TTS movement animation
            if( self.bInTactileSensorMenu ):
                if( self.nFrameNumber != self.aFrameNumbers["helpTactileSensor"] ):
                    self.nFrameNumber = self.aFrameNumbers["helpTactileSensor"]
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
            else:
                if( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ):
                    self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
        # wait for the end of the TTS
        if( idTTS != -1 ):
            try:
                self.tts.wait( idTTS, 0 )
            except:
                self.logger.debug( "Warning: Could not wait the TTS." )
        # repeat the question

    def helpAfterFailure(self, sentence = ""):
        "Help when the speech recognition failed (nothing understood or incorrect answer understood)."
        if( self.nCountFailure < self.nMaxCountFailure ): # if reasonable number of failures
            if( self.bActivateHelpWhenFailure ):
                if( self.nCountFailure in [1, 2] ): # if first or second failure
                    # enumeration of choices, or default words if there is no choice
                    if( len( self.aChoices ) - len( self.aDefaultChoices ) > 0 ): # if there is at least one choice
                        sentence += self.enumerateChoices( self.nCountFailure == 1 ) # the introduction is played if it is the first failure
                    else:
                        sentence += self.enumerateDefaultChoices( self.nCountFailure == 1 ) # the introduction is played if it is the first failure
                    if( self.nCountFailure == 2 ): # if second failure
                        # explanation about alternative modality (tactil sensor, arm motion)
                        sentence += self.explanationTactileSensor()
                # launch TTS
                idTTS = -1
                if( sentence != "" ):
                    idTTS = self.tts.post.say( sentence )
                    self.aIdsTTS.append( idTTS )
                    self.logger.debug( "Robot says: " + str(sentence) )
                    # launch TTS movement animation
                    listPossibleFrames = range( len( self.aAllSentences[self.tts.getLanguage()]["notUnderstoodAnims"] ) )
                    for i in range(len(listPossibleFrames)):
                        listPossibleFrames[i] = listPossibleFrames[i] * 10 + self.aFrameNumbers["notUnderstood"]
                    if( ( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ) and not ( self.nFrameNumber in listPossibleFrames ) ):
                        try:
                            self.getTimeline().goTo(self.aFrameNumbers["bodyTalk"])
                        except: # if NAOqi < 1.14
                            try:
                                self.gotoAndStop(self.aFrameNumbers["bodyTalk"])
                            except:
                                pass
                    self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                # wait for the end of the TTS
                if( idTTS != -1 ):
                    try:
                        self.tts.wait( idTTS, 0 )
                    except:
                        self.logger.debug( "Warning: Could not wait the TTS." )
            # repeat the question
        else: # if maximum number of failures
            # skip the question
            self.goOut( self.asExitWords[0], "notUnderstood" )

# LEDS ---------------------------------------------------------------------------------------------------

    def setLeds(self, eyesLight, earsLight, brainLight):
        "Set all LEDS (eyes, ears and brain lights)."
        rDuration = 1
        if( self.bActivateEyesLight ):
            # set eyes leds
            self.leds.post.fadeRGB( "FaceLeds", eyesLight, rDuration )
        if( self.bActivateEarsLight ):
            # set ears leds
            self.leds.fadeRGB( "EarLeds", earsLight, rDuration )
        if( self.bActivateBrainLight ):
            # set brain leds light
            self.setLedsBrain( brainLight, 500 )

    def ledsUnderstood(self, bFlashEars, bFlashBrain):
        "Sequence of LEDS for eyes, ears and brain when the robot understood what it heard."
        self.bBrainAnimPaused = True
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x00FF00, rDuration )
        if( self.bActivateEarsLight ):
            if( bFlashEars ):
                self.leds.fadeRGB( "EarLeds", 0x00FF00, rDuration )
        if( self.bActivateBrainLight ):
            if( bFlashBrain ):
                self.setLedsBrain( 0.5, int(rDuration * 1000) )
        time.sleep( 0.3 )
        rDuration = 0.2
        if( self.bActivateEyesLight ):
            if( self.bInTactileSensorMenu ):
                self.leds.fadeRGB( "FaceLeds", 0xFFFFFF, rDuration )
            else:
                self.leds.fadeRGB( "FaceLeds", 0x000000, rDuration )
        if( self.bActivateEarsLight ):
            if( bFlashEars ):
                self.leds.fadeRGB( "EarLeds", 0x000000, rDuration )
        if( self.bActivateBrainLight ):
            if( bFlashBrain ):
                self.setLedsBrain( 0., int(rDuration * 1000) )
        time.sleep( 0.1 )
        if( not self.bInTactileSensorMenu ):
            self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        time.sleep( 0.1 )
        self.bBrainAnimPaused = False

    def ledsNotUnderstood(self):
        "Sequence of LEDS for eyes and ears when the robot did not understand what it heard."
        self.bBrainAnimPaused = True
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFF0000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0xFF0000, rDuration )
        time.sleep( 0.05 )
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x000000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0x000000, rDuration )
        time.sleep( 0.05 )
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFF0000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0xFF0000, rDuration )
        time.sleep( 0.05 )
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x000000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0x000000, rDuration )
        time.sleep( 0.3 )
        self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        self.bBrainAnimPaused = False

    def ledsNegative(self):
        "Sequence of LEDS for eyes and ears when the robot understood 'no'."
        self.bBrainAnimPaused = True
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFF0000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0xFF0000, rDuration )
        time.sleep( 0.3 )
        rDuration = 0.2
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x000000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0x000000, rDuration )
        time.sleep( 0.1 )
        self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        time.sleep( 0.1 )
        self.bBrainAnimPaused = False

    def loopLedsReco(self):
        "LEDS (eyes and ears) process during the speech recognition."
        self.beginTime = time.time()
        if( self.bInConfirmation ):
            timerReco = self.beginTime + self.nTimeoutRecoConfirmation
        else:
            timerReco = self.beginTime + self.nTimeoutReco
        self.bHasAlreadyHearingEyes = False
        nEarLedsNextIndex = 0
        nEyesLed = -1
        while( self.bRecoIsWaitingForVoice or self.bRecoIsHearingOrAnalysing ):
            if( self.bMustStop ):
                try:
                    self.timeToReply(time.time() - self.beginTime)
                except:
                    pass
                break
            if( self.bRecoIsWaitingForVoice ):
                if( timerReco < time.time() ):
                    try:
                        self.timeToReply(timerReco - self.beginTime)
                    except:
                        pass
                    self.sRecoInterruption = "timeout"
                    break
            nEarLedsNextIndex = self.ledsEarsTurnOneStep( nEarLedsNextIndex )
            nEyesLed += 1
            self.ledsEyesTurnOneStep( 0x0055FF, nEyesLed%8 )
            time.sleep( 0.2 )

    def ledsEarsTurnOneStep(self, nEarLedsNextIndex):
        "One step of ears LEDS sequence (turn) when the robot is in speech recognition."
        if( self.bActivateEarsLight ):
            nNbrLedByEars = 10
            rTime = 0.7
            strTemplate = "Ears/Led/%s/%dDeg/Actuator/Value"
            nAngle = (360/nNbrLedByEars) * nEarLedsNextIndex
            # update index before sending movement in case of a fast/concurrent call of the function
            nEarLedsNextIndex -= 1 # more beautiful to turn in this way
            if( nEarLedsNextIndex < 0 ):
                nEarLedsNextIndex = nNbrLedByEars-1
            self.leds.post.fade( strTemplate % ( "Left", nAngle ), 1.0, rTime )
            self.leds.post.fade( strTemplate % ( "Right", nAngle ), 1.0, rTime )
            self.leds.post.fade( strTemplate % ( "Left", nAngle ), 0.0, rTime*1.2 )
            self.leds.post.fade( strTemplate % ( "Right", nAngle ), 0.0, rTime*1.2 )
        return nEarLedsNextIndex

    def ledsEyesTurnOneStep(self, nColor, nLed):
        "One step of eyes LEDS sequence (turn) when the robot is in speech recognition."
        if( self.bActivateEyesLight ):
            rTime = 0.7
            if( self.bRecoIsHearingOrAnalysing ):
                if( not self.bHasAlreadyHearingEyes ):
                    self.leds.fadeRGB( "FaceLeds", 0xF4FF22, 0.1 )
                    # start headcheck animation
                    if( self.nFrameNumber != self.aFrameNumbers["headCheck"] ):
                        self.nFrameNumber = self.aFrameNumbers["headCheck"]
                        try:
                            self.getTimeline().goTo(self.nFrameNumber)
                        except: # if NAOqi < 1.14
                            try:
                                self.gotoAndStop(self.nFrameNumber)
                            except:
                                pass
                    self.bHasAlreadyHearingEyes = True
            elif( self.bRecoIsWaitingForVoice ):
                self.leds.post.fadeRGB( "FaceLed%d" % (nLed) , nColor, rTime )
                self.leds.post.fadeRGB( "FaceLed%d" % (nLed) , 0x000000, rTime*1.25 )

    def ledsChangeOnTactile(self):
        self.bBrainAnimPaused = True
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x0055FF, rDuration )
        self.setLedsBrain( 0.5, int(rDuration * 1000) )
        time.sleep( 0.3 )
        rDuration = 0.2
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFFFFFF, rDuration )
        self.setLedsBrain( 0., int(rDuration * 1000) )
        time.sleep( 0.2 )
        self.bBrainAnimPaused = False

    def loopLedsBrainTurn(self):
        self.setLeds( 0xFFFFFF, 0xFFFFFF, 0. )
        rIntensity = 0.5
        nTime = 50
        bAlreadyPaused = False
        while( self.bInTactileSensorMenu ):
            if( not self.bBrainAnimPaused ):
                if( self.nFront == 1 or self.nMiddle == 1 or self.nRear == 1 ):
                    if( not bAlreadyPaused ):
                        bAlreadyPaused = True
                        self.setLedsBrain( 0., 50 )
                else:
                    bAlreadyPaused = False
                    if( self.bActivateBrainLight ):
                        for i in range( 12 ):
                            if( not self.bBrainAnimPaused and self.dcm != None):
                                riseTime = self.dcm.getTime(nTime)
                                strDeviceName = self.getBrainLedName(i)
                                self.dcm.set( [ strDeviceName, "Merge",  [[ rIntensity, riseTime ]] ] )
                                time.sleep( nTime/1000. )
                                if( not self.bBrainAnimPaused ):
                                    self.dcm.set( [ strDeviceName, "Merge",  [[ 0.0, riseTime + int(nTime)/4 ]] ] )
            time.sleep( nTime/1000. )
        self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )

    def loopLedsBrainTwinkle(self):
        rIntensity = 0.5
        bOnStep = True
        bAlreadyPaused = False
        while( not self.bInTactileSensorMenu and self.bIsRunning ):
            if( not self.bBrainAnimPaused ):
                if( self.nFront == 1 or self.nMiddle == 1 or self.nRear == 1 ):
                    if( not bAlreadyPaused ):
                        bAlreadyPaused = True
                        self.setLedsBrain( 0., 50 )
                else:
                    bAlreadyPaused = False
                    if( bOnStep ):
                        self.setLedsBrain( rIntensity, 700 )
                        bOnStep = False
                    else:
                        self.setLedsBrain( 0.0, 700 )
                        bOnStep = True
            time.sleep( 1 )

    def setLedsBrain(self, rIntensity, rTimeMs):
        "One step of brain LEDS sequence (twinkle) when the robot is in speech recognition."
        if( self.bActivateBrainLight and self.dcm != None):
            riseTime = self.dcm.getTime( rTimeMs )
            for i in range( 12 ):
                strDeviceName = self.getBrainLedName(i)
                self.dcm.set( [ strDeviceName, "Merge",  [[ rIntensity, riseTime ]] ] )

# TACTILE SENSOR MENU -------------------------------------------------------------------------------------

    def onAlternativeModalityAction(self, p):
        "Process actions from alternative modalities (sequence from the tactile sensor, simple click on the torso button...)."
        if( not self.bIsRunning ): # if the box is not running
            return # then go out without doing a thing
        if( not self.bInTactileSensorMenu ): # if we are not in the tactile sensor menu (so if we are in the question-recognition-reaction loop)
            if( p in ["TapFront", "TapMiddle", "TapRear", "LongFront", "LongMiddle", "LongRear"] ):
                bTTSRunning = False # to know if TTS is running
                for idTTS in self.aIdsTTS:
                    if( self.tts.isRunning( idTTS )):
                        bTTSRunning = True
                if( bTTSRunning ): # if TTS is running
                    # skip the TTS
                    self.skipTTS()
                else: # if TTS was not running (so if in recognition)
                    # prepare to start the tactile sensor menu
                    self.bInTactileSensorMenu = True
                    # and stop the question-recognition-reaction loop
                    self.goOutOfQuestionRecoReaction()
                    self.sRecoInterruption = "onTactileSensor"
                    # start the tactile sensor menu
                    self.sayCurrentChoice()
                    # start counting timeout
                    self.rTimeWhenActionMadeInTactileMenu = time.time()
                    thread.start_new_thread( self.loopCheckTimeoutInTactileMenu, (self.rTimeWhenActionMadeInTactileMenu,) )
            elif( p in ["Tap", "CalmDown"] ):
                # skip the TTS
                self.skipTTS()
                # then stop everything and cancel the question
                self.goOut( self.asExitWords[0], "onTactileSensor" )
                self.sRecoInterruption = "onTactileSensor"
                self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        else: # if we are in the tactile sensor menu
            self.rTimeWhenActionMadeInTactileMenu = -1.
            if( p in ["TapFront"] ):
                bTTSRunning = False # to know if TTS is running
                for idTTS in self.aIdsTTS:
                    if( self.tts.isRunning( idTTS ) ):
                        bTTSRunning = True
                if( self.bIsSayingChoice or not bTTSRunning ): # else just skip the TTS (in the sayCurrentChoice function)
                    # change choice
                    self.nIndexChoice += 1
                    if( self.nIndexChoice >= len( self.aChoices ) ):
                        self.nIndexChoice = 0
                # say the choice in the tactile sensor menu
                self.sayCurrentChoice()
                self.timeoutManagingInTactileMenu()
            elif( p in ["TapRear"] ):
                bTTSRunning = False # to know if TTS is running
                for idTTS in self.aIdsTTS:
                    if( self.tts.isRunning( idTTS )):
                        bTTSRunning = True
                if( self.bIsSayingChoice or not bTTSRunning ): # else just skip the TTS (in the sayCurrentChoice function)
                    # change choice
                    self.nIndexChoice -= 1
                    if( self.nIndexChoice < 0 ):
                        self.nIndexChoice = len( self.aChoices ) - 1
                # say the choice in the tactile sensor menu
                self.sayCurrentChoice()
                self.timeoutManagingInTactileMenu()
            elif( p in ["TapMiddle", "LongMiddle"] ):
                self.rTimeWhenActionMadeInTactileMenu = time.time()
                rTimeForThisAction = self.rTimeWhenActionMadeInTactileMenu
                bWasSayingChoice = self.bIsSayingChoice
                bTTSRunning = False # to know if TTS is running
                for idTTS in self.aIdsTTS:
                    if( self.tts.isRunning( idTTS )):
                        bTTSRunning = True
                # skip the TTS if it is running
                self.skipTTS()
                if( bWasSayingChoice or not bTTSRunning ):
                    # validate choice
                    thread.start_new_thread( self.ledsUnderstood, (False, True) )
                    if( self.aChoices[self.nIndexChoice][0] == self.asRepeatWords[0] ):
                        self.repeatWhenNoQuestion()
                        # launch TTS
                        idTTS = -1
                        if( self.sQuestion != ""):
                            idTTS = self.tts.post.say( self.sQuestion + "\\Pau=300\\" )
                            self.aIdsTTS.append( idTTS )
                            self.logger.debug( "Robot says: " + str(self.sQuestion) )
                        # wait for the end of the TTS
                        if( idTTS != -1 ):
                            try:
                                self.tts.wait( idTTS, 0 )
                            except:
                                self.logger.debug( "Warning: Could not wait the TTS." )
                    else:
                        self.reactionWordUnderstood( [ self.aChoices[self.nIndexChoice][0], 1.0 ] )
                if( self.bIsRunning and rTimeForThisAction == self.rTimeWhenActionMadeInTactileMenu ): #$$$
                    self.rTimeWhenActionMadeInTactileMenu = -1.
                    # say the choice in the tactile sensor menu
                    self.sayCurrentChoice()
                    self.timeoutManagingInTactileMenu()
            elif( p == "LongFront" ):
                if( not self.bPressed ):
                    self.bPressed = True
                    bLastElementSaid = False
                    while( self.bPressed ):
                        if( self.nFront == 0 ):
                            self.bPressed = False
                            break
                        bTTSRunning = False # to know if TTS is running
                        for idTTS in self.aIdsTTS:
                            if( self.tts.isRunning( idTTS )):
                                bTTSRunning = True
                        if( self.bIsSayingChoice or not bTTSRunning ):
                            # change choice
                            self.nIndexChoice += 1
                            if( self.nIndexChoice >= len( self.aChoices ) - 1 ):
                                self.nIndexChoice = len( self.aChoices ) - 1
                                if( not bLastElementSaid ):
                                    bLastElementSaid = True
                                    # say the choice in the tactile sensor menu
                                    thread.start_new_thread( self.sayCurrentChoice, () )
                            else:
                                # say the choice in the tactile sensor menu
                                thread.start_new_thread( self.sayCurrentChoice, () )
                        else:
                            if( self.nIndexChoice == len( self.aChoices ) - 1 ):
                                bLastElementSaid = True
                            # say the choice in the tactile sensor menu
                            thread.start_new_thread( self.sayCurrentChoice, () )
                        for i in range(8):
                            if( self.nFront == 0 ):
                                self.bPressed = False
                                break
                            time.sleep(0.1)
                    for idTTS in self.aIdsTTS:
                        if( self.tts.isRunning( idTTS ) ):
                            try:
                                self.tts.wait( idTTS, 0 )
                            except:
                                self.logger.debug( "Warning: Could not wait the TTS." )
                    self.timeoutManagingInTactileMenu()
            elif( p == "LongRear" ):
                if( not self.bPressed ):
                    self.bPressed = True
                    bFirstElementSaid = False
                    while( self.bPressed ):
                        if( self.nRear == 0 ):
                            self.bPressed = False
                            break
                        bTTSRunning = False # to know if TTS is running
                        for idTTS in self.aIdsTTS:
                            if( self.tts.isRunning( idTTS )):
                                bTTSRunning = True
                        if( self.bIsSayingChoice or not bTTSRunning ):
                            # change choice
                            self.nIndexChoice -= 1
                            if( self.nIndexChoice <= 0 ):
                                self.nIndexChoice = 0
                                if( not bFirstElementSaid ):
                                    bFirstElementSaid = True
                                    # say the choice in the tactile sensor menu
                                    thread.start_new_thread( self.sayCurrentChoice, () )
                            else:
                                # say the choice in the tactile sensor menu
                                thread.start_new_thread( self.sayCurrentChoice, () )
                        else:
                            if( self.nIndexChoice == 0 ):
                                bFirstElementSaid = True
                            # say the choice in the tactile sensor menu
                            thread.start_new_thread( self.sayCurrentChoice, () )
                        for i in range(8):
                            if( self.nRear == 0 ):
                                self.bPressed = False
                                break
                            time.sleep(0.1)
                    for idTTS in self.aIdsTTS:
                        if( self.tts.isRunning( idTTS ) ):
                            try:
                                self.tts.wait( idTTS, 0 )
                            except:
                                self.logger.debug( "Warning: Could not wait the TTS." )
                    self.timeoutManagingInTactileMenu()
            elif( p in ["Tap", "CalmDown"] ):
                # then stop everything and cancel the question
                self.goOut( self.asExitWords[0], "onTactileSensor" )

    def sayCurrentChoice(self):
        "In the tactile sensor menu, make the robot say the current selected choice"
        self.bIsSayingChoice = True
        rTimeCurrent = time.time()
        self.rTimeLastChoiceSaid = rTimeCurrent
        # stop previous TTS
        self.skipTTS()
        # launch TTS
        idTTS = -1
        if( self.aChoices[ self.nIndexChoice ][0] != "" ):
            if( self.nFrameNumber != self.aFrameNumbers["headDown"] ):
                self.nFrameNumber = self.aFrameNumbers["headDown"]
                try:
                    self.getTimeline().goTo(self.nFrameNumber)
                except: # if NAOqi < 1.14
                    try:
                        self.gotoAndStop(self.nFrameNumber)
                    except:
                        pass
            sentence = self.aChoices[ self.nIndexChoice ][0] + "?"
            idTTS = self.tts.post.say( sentence )
            self.aIdsTTS.append( idTTS )
            self.logger.debug( "Robot says: " + str(sentence) )
            # launch flash leds
            thread.start_new_thread( self.ledsChangeOnTactile, () )
        if( idTTS != -1 ):
            try:
                self.tts.wait( idTTS, 0 )
            except:
                self.logger.debug( "Warning: Could not wait the TTS." )
        if( self.rTimeLastChoiceSaid == rTimeCurrent ):
            self.rTimeLastChoiceSaid = -1.
            self.bIsSayingChoice = False

    def timeoutManagingInTactileMenu(self):
        # check if there has been an other action with tts made while this one was processed
        bTTSRunning = False # to know if TTS is running
        for idTTS in self.aIdsTTS:
            if( self.tts.isRunning( idTTS )):
                bTTSRunning = True
        if( not bTTSRunning ):
            # start counting timeout
            self.rTimeWhenActionMadeInTactileMenu = time.time()
            thread.start_new_thread( self.loopCheckTimeoutInTactileMenu, (self.rTimeWhenActionMadeInTactileMenu,) )

    def loopCheckTimeoutInTactileMenu(self, rTimeForThisAction):
        nTimeout = time.time() + self.nTimeoutTactile
        if( self.rTimeWhenActionMadeInTactileMenu == rTimeForThisAction ):
            while( time.time() < nTimeout and self.rTimeWhenActionMadeInTactileMenu == rTimeForThisAction and self.bIsRunning ):
                time.sleep( 0.1 )
            if( self.rTimeWhenActionMadeInTactileMenu != rTimeForThisAction ):
                self.nCountNoReply = 0
            elif( self.bIsRunning ):
                self.rTimeWhenActionMadeInTactileMenu = -1.
                self.nCountNoReply += 1
                if( self.nCountNoReply >= self.nMaxCountNoReply ):
                    self.goOut( self.asExitWords[0], "timeout" )
                else:
                    bTTSRunning = False # to know if TTS is running
                    for idTTS in self.aIdsTTS:
                        if( self.tts.isRunning( idTTS )):
                            bTTSRunning = True
                    if( not bTTSRunning ):
                        # say the choice in the tactile sensor menu
                        self.sayCurrentChoice()
                        # start counting timeout
                        self.rTimeWhenActionMadeInTactileMenu = time.time()
                        thread.start_new_thread( self.loopCheckTimeoutInTactileMenu, (self.rTimeWhenActionMadeInTactileMenu,) )

# TACTILE SENSOR HANDLER -------------------------------------------------------------------------------

    def initSeqDetected(self):
        "Initialize the sequence handler."
        self.bSeqStarted = False
        self.aDetectedSeqs = []
        self.aDetectedSeqs.extend(self.aSeqs)
        for seq in self.aDetectedSeqs:
            seq["index"] = 0
            seq["previousStepTime"] = 0

    def convertToArrayOfPossibleStates(self, states):
        "Check if the states described in the sequences using a string are in the right syntax, and then convert them to an array of the possible states."
        aStates = []
        aStates3 = [[1, 1, 1]]
        aStates2 = [[0, 1, 1], [1, 0, 1], [1, 1, 0]]
        aStates1 = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]
        aStates0 = [[0, 0, 0]]
        try:
            if( int(states) == states ): # if states is an integer
                states = str(states)
        except:
            pass
        if( self.isString(states) ):
            if( not states in ["*", "0+", "0", "0-", "1+", "1", "1-", "2+", "2", "2-", "3+", "3", "3-", "F+", "F", "F-", "M+", "M", "M-", "R+", "R", "R-"] ):
                raise Exception( "Error in sequences states description syntax: description expected in " + str(["*", "0+", "0", "0-", "1+", "1", "1-", "2+", "2", "2-", "3+", "3", "3-", "F+", "F", "F-", "M+", "M", "M-", "R+", "R", "R-"]) + " but " + str(p) + " found with this type: " + str(type(p)) )
            if( states in ["*", "0+", "1+", "2+", "3+", "3", "3-", "F+", "M+", "R+"] ):
                aStates.extend(aStates3)
            if( states in ["*", "0+", "1+", "2+", "2", "2-", "3-"] ):
                aStates.extend(aStates2)
            if( states in ["*", "0+", "1+", "1", "1-", "2-", "3-"] ):
                aStates.extend(aStates1)
            if( states in ["*", "0+", "0", "0-", "1-", "2-", "3-", "F-", "M-", "R-"] ):
                aStates.extend(aStates0)
            if( states in ["F", "F+", "F-"] ):
                aStates.append([1, 0, 0])
            if( states in ["M", "M+", "M-"] ):
                aStates.append([0, 1, 0])
            if( states in ["R", "R+", "R-"] ):
                aStates.append([0, 0, 1])
            if( states in ["F+", "M+"] ):
                aStates.append([1, 1, 0])
            if( states in ["R+", "M+"] ):
                aStates.append([0, 1, 1])
            if( states in ["F+", "R+"] ):
                aStates.append([1, 0, 1])
        elif( self.isArray(states) ):
            if( self.isArray(states[0]) ):
                aStates = states
            elif( int(states[0]) == states[0] ):
                aStates = [states]
            else:
                raise Exception( "Error in sequences states description syntax: description expected in " + str(["*", "0+", "0", "0-", "1+", "1", "1-", "2+", "2", "2-", "3+", "3", "3-", "F+", "F", "F-", "M+", "M", "M-", "R+", "R", "R-"]) + " but " + str(p) + " found with this type: " + str(type(p)) )
        else:
            raise Exception( "Error in sequences states description syntax:\nstring, array or int expected but " + str(type(p)) + " found" )
        return aStates

    def checkIfSeqsCorrespondingLeft(self, param):
        "If the sequence handler is done (there is no sequence detected left or the first in the list corresponds), then reinitialize the sequence handler, and give the corresponding sequence if there is one."
        if( self.aDetectedSeqs == [] ):
            # then no sequence corresponding in the list
            self.initSeqDetected()
        else:
            if( self.aDetectedSeqs[0]["index"] == -1 ): # if first sequence in left ones corresponds
                # then it is this sequence which is played
                thread.start_new_thread( self.onAlternativeModalityAction, (self.aDetectedSeqs[0]["name"],) )
                self.initSeqDetected()
        self.mutexCheckIfSeqsCorrespondingLeft.unlock()

    def loopCheckTimeoutMax(self, nTimeoutMax, seq, currentState, currentTime):
        "When timeout ellapsed, check the sequence status and process it."
        nPreviousIndex = seq["index"]
        time.sleep(nTimeoutMax + 0.1)
        aSeqsTemp = []
        aSeqsTemp.extend( self.aDetectedSeqs )
        currentState = [self.nFront, self.nMiddle, self.nRear]
        currentTime = time.time()
        if( nPreviousIndex == seq["index"] and not self.mutexProcessCurrentState.test() and not (1 in currentState) ): # if no change in the sequence step but timeout ellapsed and sequence handler is not processing (so if there is no action from the user and the sequence is still at the same point)
            if( seq in aSeqsTemp and seq["index"] != -1 ): # but if sequence is still in the possible ones and not completed
                if( currentState in seq["statesAndTimeout"][seq["index"]] ): # last check if the current state corresponds to the next one
                    # then we go to the next step
                    seq["previousStepTime"] = currentTime
                    seq["index"] += 2
                    if( seq["index"] > len( seq["statesAndTimeout"] ) ): # if there is no more step
                        seq["index"] = -1 # then the sequence is completed
                    else: # if there is at least one step left
                        nTimeoutMin = 0
                        nTimeoutMax = 5
                        if( self.isArray(seq["statesAndTimeout"][seq["index"]-1]) ):
                            if( seq["statesAndTimeout"][seq["index"]-1][0] < 0 ):
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][0]
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][1]
                            else:
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][0]
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][1]
                        else:
                            if( seq["statesAndTimeout"][seq["index"]-1] < 0 ):
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1]
                            else:
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1]
                        thread.start_new_thread( self.loopCheckTimeoutMax, (nTimeoutMax, seq, currentState, currentTime) )
                else:
                    # then remove the sequence from the possible ones
                    aSeqsTemp.remove(seq)
                    self.aDetectedSeqs = aSeqsTemp
                self.mutexCheckIfSeqsCorrespondingLeft.lock( self.checkIfSeqsCorrespondingLeft, None )

    def loopCheckTimeoutMin(self, nTimeoutMin, seq):
        "Wait that the minimum timeout ellapse to check if the new tactile sensor state corresponds to the expected one for this sequence."
        if( nTimeoutMin != 0 ):
            nPreviousIndex = seq["index"]
            time.sleep(nTimeoutMin - time.time() + seq["previousStepTime"])
            currentTime = time.time()
            currentState = [self.nFront, self.nMiddle, self.nRear]
            self.mutexProcessCurrentState.lock( self.processCurrentState, [0, currentState, currentTime] )

    def updateDetectedSeqs(self, seq, aSeqsTemp, currentState, currentTime):
        "Update a detected sequence."
        if( seq["index"] > 0 ): # if not the first step
            nTimeoutMin = 0
            nTimeoutMax = 5
            if( self.isArray(seq["statesAndTimeout"][seq["index"]-1]) ):
                if( seq["statesAndTimeout"][seq["index"]-1][0] < 0 ):
                    nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][0]
                    nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][1]
                else:
                    nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][0]
                    nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][1]
            else:
                if( seq["statesAndTimeout"][seq["index"]-1] < 0 ):
                    nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1]
                else:
                    nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1]
            if( currentTime > nTimeoutMax + seq["previousStepTime"] ): # if timeout of this step ellapsed
                aSeqsTemp.remove(seq) # then it is not this sequence which is played
            elif( not (currentState in seq["statesAndTimeout"][seq["index"]]) ): # if the current state does not correspond to one of the described ones but the timeout of this step did not ellaspe
                # then we check that this state could be an intermediate one
                aIntermediateStates = [[], [], []]
                for i in range( len( currentState ) ):
                    for j in range( len( seq["statesAndTimeout"][seq["index"]] ) ):
                        aIntermediateStates[i].append( seq["statesAndTimeout"][seq["index"]][j][i] )
                    for j in range( len( seq["statesAndTimeout"][seq["index"]-2] ) ):
                        aIntermediateStates[i].append( seq["statesAndTimeout"][seq["index"]-2][j][i] )
                bIsIntermediate = True
                for i in range( len( currentState ) ):
                    bIsIntermediate = bIsIntermediate and ( currentState[i] in aIntermediateStates[i] )
                if( not bIsIntermediate ):
                    aSeqsTemp.remove(seq) # then it is not this sequence which is played
            else: # if the current state correspond to one of the described ones
                if( currentTime > nTimeoutMin + seq["previousStepTime"] ): # if the minimum time to wait the next step is ellapsed
                    # then we go to the next step
                    seq["previousStepTime"] = currentTime
                    seq["index"] += 2
                    if( seq["index"] > len( seq["statesAndTimeout"] ) ): # if there is no more step
                        seq["index"] = -1 # then the sequence is completed
                    else: # if there is at least one step left
                        # start clock to timeout
                        nTimeoutMin = 0
                        nTimeoutMax = 5
                        if( self.isArray(seq["statesAndTimeout"][seq["index"]-1]) ):
                            if( seq["statesAndTimeout"][seq["index"]-1][0] < 0 ):
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][0]
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][1]
                            else:
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][0]
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][1]
                        else:
                            if( seq["statesAndTimeout"][seq["index"]-1] < 0 ):
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1]
                            else:
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1]
                        thread.start_new_thread( self.loopCheckTimeoutMin, (nTimeoutMin, seq) )
                        thread.start_new_thread( self.loopCheckTimeoutMax, (nTimeoutMax, seq, currentState, currentTime) )
                else: # if the minimum time to wait the next step is not ellapsed
                    # then we are going to wait until it is to check then
                    thread.start_new_thread( self.loopCheckTimeoutMin, (nTimeoutMin, seq) )
        elif( seq["index"] == 0 ): # for the first step
            if( currentState in seq["statesAndTimeout"][seq["index"]] ): # if the current state correspond to one of the described ones
                # then we go to the next step
                seq["previousStepTime"] = currentTime
                seq["index"] += 2
                if( seq["index"] > len( seq["statesAndTimeout"] ) ): # if there is no more step
                    seq["index"] = -1 # then the sequence is completed
                else: # if there is at least one step left
                    # start clock to timeout
                    nTimeoutMin = 0
                    nTimeoutMax = 5
                    if( self.isArray(seq["statesAndTimeout"][seq["index"]-1]) ):
                        if( seq["statesAndTimeout"][seq["index"]-1][0] < 0 ):
                            nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][0]
                            nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][1]
                        else:
                            nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][0]
                            nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][1]
                    else:
                        if( seq["statesAndTimeout"][seq["index"]-1] < 0 ):
                            nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1]
                        else:
                            nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1]
                    thread.start_new_thread( self.loopCheckTimeoutMin, (nTimeoutMin, seq) )
                    thread.start_new_thread( self.loopCheckTimeoutMax, (nTimeoutMax, seq, currentState, currentTime) )
            else: # if the current state does not correspond to the first described
                aSeqsTemp.remove(seq) # then it is not this sequence which has just been started

    def updateSeqsHandler(self, currentState, currentTime):
        "Update list of detected sequences."
        aSeqsTemp = []
        aSeqsTemp.extend( self.aDetectedSeqs )
        for seq in self.aDetectedSeqs:
            self.updateDetectedSeqs( seq, aSeqsTemp, currentState, currentTime )
        self.aDetectedSeqs = aSeqsTemp
        self.mutexCheckIfSeqsCorrespondingLeft.lock( self.checkIfSeqsCorrespondingLeft, None )

    def processCurrentState(self, param):
        "Process the current tactile sensor state."
        pValue = param[0]
        currentState = param[1]
        currentTime = param[2]
        if( pValue == 1 and not self.bSeqStarted ):
            self.bSeqStarted = True
            for seq in self.aDetectedSeqs:
                seq["previousStepTime"] = currentTime
        # update sequences handler
        if( self.bSeqStarted ):
            self.updateSeqsHandler(currentState, currentTime)
        self.mutexProcessCurrentState.unlock()

    def onFrontTactilTouched(self, param):
        "Handle an action (touch or release) on the front tactile sensor."
        self.logger.debug( "Change detected on the front tactile sensor: " + str(param[0]) )
        pValue = param[0]
        currentTime = param[1]
        currentState = [pValue, self.nMiddle, self.nRear]
        self.nFront = pValue
        self.mutexProcessCurrentState.lock( self.processCurrentState, [pValue, currentState, currentTime] )
        self.mutexTactilTouched.unlock()

    def onMiddleTactilTouched(self, param):
        "Handle an action (touch or release) on the middle tactile sensor."
        self.logger.debug( "Change detected on the middle tactile sensor: " + str(param[0]) )
        pValue = param[0]
        currentTime = param[1]
        currentState = [self.nFront, pValue, self.nRear]
        self.nMiddle = pValue
        self.mutexProcessCurrentState.lock( self.processCurrentState, [pValue, currentState, currentTime] )
        self.mutexTactilTouched.unlock()

    def onRearTactilTouched(self, param):
        "Handle an action (touch or release) on the rear tactile sensor."
        self.logger.debug( "Change detected on the rear tactile sensor: " + str(param[0]) )
        pValue = param[0]
        currentTime = param[1]
        currentState = [self.nFront, self.nMiddle, pValue]
        self.nRear = pValue
        self.mutexProcessCurrentState.lock( self.processCurrentState, [pValue, currentState, currentTime] )
        self.mutexTactilTouched.unlock()

    def onTactilTouched(self, pDataName, pValue, pMessage):
        "Handle an action (touch or release) on the tactile sensor."
        self.mutexTactilTouched.lock( getattr( self, "on" + pDataName ), [pValue, time.time()] )

# OUTPUTS ACTIVATION --------------------------------------------------------------------------------------

    def goOut(self, outputName, cancelReason = ""):
        "Activate the right output (a choice output or the other output)."
        try:
            self.memory.unsubscribeToEvent( "FrontTactilTouched", self.getName() )
            self.memory.unsubscribeToEvent( "MiddleTactilTouched", self.getName() )
            self.memory.unsubscribeToEvent( "RearTactilTouched", self.getName() )
        except:
            pass

        self.bGoOut = True
        self.bInTactileSensorMenu = False
        if( outputName in self.asExitWords ):
            try:
                self.other( cancelReason )
                self.logger.debug( "Output 'other' stimulated because cancel asked: " + str(cancelReason) + "." )
            except:
                try:
                    self.onStopped( cancelReason )
                    self.logger.debug( "Output 'onStopped' stimulated because cancel asked: " + str(cancelReason) + "." )
                except:
                    try:
                        self.onStopped()
                        self.logger.debug( "Output 'onStopped' stimulated because cancel asked." )
                    except:
                        choregraphe = ALProxy( "ALChoregraphe" )
                        choregraphe.onPythonError( self.getName(), "goOut", "Invalid output: the main output name needs to be 'other', and it needs to be dynamic (because it can be either a string, or an integer)." )
        else:
            nOutput = -1
            for i in range( len (self.aChoices) - len (self.aDefaultChoices) ):
                if( nOutput == -1 ):
                    if( outputName in self.aChoices[i+len( self.aDefaultChoices )] ):
                        nOutput = i
            if( nOutput != -1):
                if( self.bExternChoices ):
                    if( self.bRepeatValidatedChoice ):
                        self.skipTTS()
                        self.tts.say( outputName )
                        self.logger.debug( "Robot says: " + str(outputName) )
                    try:
                        self.other( self.aChoiceIndexes[nOutput] )
                        self.logger.debug( "Output 'other' stimulated with: " + str(self.aChoiceIndexes[nOutput]) + " (corresponding to the choice '" + str(self.aChoices[nOutput+len( self.aDefaultChoices )][0]) + "')." )
                    except:
                        try:
                            self.onStopped( self.aChoiceIndexes[nOutput] )
                            self.logger.debug( "Output 'onStopped' stimulated with: " + str(self.aChoiceIndexes[nOutput]) + " (corresponding to the choice '" + str(self.aChoices[nOutput+len( self.aDefaultChoices )][0]) + "')." )
                        except:
                            choregraphe = ALProxy( "ALChoregraphe" )
                            choregraphe.onPythonError( self.getName(), "goOut", "Invalid type of output: using the input 'choicesList', the main output needs to be dynamic (because it can be either a string, or an integer)." )
                else:
                    if( self.bRepeatValidatedChoice ):
                        self.skipTTS()
                        self.tts.say( outputName )
                        self.logger.debug( "Robot says: " + str(outputName) )
                    try:
                        func = getattr( self, "output_" + str(self.aChoiceIndexes[nOutput]+1) ) #+1 because the first one is output_1 corresponding to the element 0 in the list.
                        func(outputName)
                        self.logger.debug( "Output 'output_" + str(self.aChoiceIndexes[nOutput]+1) + "' stimulated with: " + str(outputName) + "." )
                    except:
                        choregraphe = ALProxy( "ALChoregraphe" )
                        choregraphe.onPythonError( self.getName(), "goOut", "Invalid output: the output 'output_" + str(self.aChoiceIndexes[nOutput]+1) + "' was expected to be stimulated with: " + str(outputName) + " but could not." )
        self.onUnload()
        # come back to an initial position and stop movement animation
        if( self.nFrameNumber != self.aFrameNumbers["end"] ):
            self.nFrameNumber = self.aFrameNumbers["end"]
            try:
                self.getTimeline().goTo(self.nFrameNumber)
            except: # if NAOqi < 1.14
                try:
                    self.gotoAndStop(self.nFrameNumber)
                except:
                    pass

# UNLOAD --------------------------------------------------------------------------------------------------

    def goOutOfQuestionRecoReaction(self):
        "Set some variables to go out of the question-recognition-reaction loop and reinitialize other variables which are going to be used again only on the next start of this box."
        self.bGoOut = True
        self.bMustStop = True
        self.nCountFailure = 0
        self.nCountNoReply = 0
        self.bInConfirmation = False
        self.bVocabularyLoaded = False
        self.skipTTS()
        for idTTS in self.aIdsTTS:
            try:
                self.aIdsTTS.remove( idTTS )
            except:
                self.logger.debug( "Warning: The task ID corresponding to the Text-To-Speech could not have been removed from the ID tasks list." )
        try:
            self.memory.unsubscribeToEvent( "WordRecognized", self.getName() )
            self.bRecoIsWaitingForVoice = False
            self.bRecoIsHearingOrAnalysing = False
            self.logger.debug( "Speech recognition stopped." )
            self.memory.unsubscribeToEvent( "SpeechDetected", self.getName() )
        except:
            pass

    def onUnload(self):
        "Reinitialize variables to default state."
        self.goOutOfQuestionRecoReaction()
        self.bExternChoices = False
        self.bInTactileSensorMenu = False
        try:
            self.memory.unsubscribeToEvent( "FrontTactilTouched", self.getName() )
            self.memory.unsubscribeToEvent( "MiddleTactilTouched", self.getName() )
            self.memory.unsubscribeToEvent( "RearTactilTouched", self.getName() )
        except:
            pass
        self.bIsRunning = False]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <keyword>نعم</keyword>
                                                        <keyword>لا</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </arabic>
                                                    <brazilian>
                                                        <keyword>sim</keyword>
                                                        <keyword>não</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </brazilian>
                                                    <chinese>
                                                        <keyword>是</keyword>
                                                        <keyword>不是</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </chinese>
                                                    <czech>
                                                        <keyword>ano</keyword>
                                                        <keyword>ne</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </czech>
                                                    <danish>
                                                        <keyword>ja</keyword>
                                                        <keyword>nej</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </danish>
                                                    <dutch>
                                                        <keyword>ja</keyword>
                                                        <keyword>nee</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </dutch>
                                                    <english>
                                                        <keyword></keyword>
                                                        <keyword>No</keyword>
                                                        <keyword>Yes</keyword>
                                                        <keyword></keyword>
                                                    </english>
                                                    <finnish>
                                                        <keyword>kyllä</keyword>
                                                        <keyword>ei</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </finnish>
                                                    <french>
                                                        <keyword>oui</keyword>
                                                        <keyword>non</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </french>
                                                    <german>
                                                        <keyword>ja</keyword>
                                                        <keyword>nein</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </german>
                                                    <greek>
                                                        <keyword>ναί</keyword>
                                                        <keyword>κανένα</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </greek>
                                                    <italian>
                                                        <keyword>sì</keyword>
                                                        <keyword>no</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </italian>
                                                    <japanese>
                                                        <keyword>はい</keyword>
                                                        <keyword>いいえ</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </japanese>
                                                    <korean>
                                                        <keyword>예</keyword>
                                                        <keyword>아니</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </korean>
                                                    <norwegian>
                                                        <keyword>ja</keyword>
                                                        <keyword>Nei</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </norwegian>
                                                    <polish>
                                                        <keyword>tak</keyword>
                                                        <keyword>nie</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </polish>
                                                    <portuguese>
                                                        <keyword>sim</keyword>
                                                        <keyword>não</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </portuguese>
                                                    <russian>
                                                        <keyword>да</keyword>
                                                        <keyword>нет</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </russian>
                                                    <spanish>
                                                        <keyword>si</keyword>
                                                        <keyword>no</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </spanish>
                                                    <swedish>
                                                        <keyword>ja</keyword>
                                                        <keyword>ingen</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </swedish>
                                                    <turkish>
                                                        <keyword>evet</keyword>
                                                        <keyword>hayır</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </turkish>
                                                    <language>english</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="0" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is&#x0A;received on this input. The signal can be&#x0A;either a string so that the robot asks a&#x0A;question before the recognition of a&#x0A;choice, or a bang so that the speech&#x0A;recognition starts immediately without any&#x0A;question." id="2" />
                                                <Input name="choicesList" type="0" type_size="1" nature="1" inner="0" tooltip="To have extern choices list (for example,&#x0A;depending on extern variables).&#x0A;!! Warning !! : Must be set before each&#x0A;time the box is started (with onStart&#x0A;input). Otherwise, the choices displayed&#x0A;on the box will be selected." id="3" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip='Box behavior stops when a signal is&#x0A;received on this input, the &apos;other&apos; output is&#x0A;stimulated by &quot;onStop&quot;.' id="4" />
                                                <Output name="other" type="0" type_size="1" nature="1" inner="0" tooltip='When the user skipped the question, this output gives how it has been&#x0A;skipped. Gives also the number of the choice chosen in case of external&#x0A;choices.&#x0A;This output can be:&#x0A;- &quot;timeout&quot; if the user has not replied.&#x0A;- &quot;notUnderstood&quot; if the interaction with the speech recognition failed.&#x0A;- &quot;onStop&quot; if the onStop input has been activated.&#x0A;- &quot;wordRecognised&quot; if the exit command has been understood.&#x0A;- &quot;onTactileSensor&quot; if the user has tapped the tactile sensor of the robot.&#x0A;- an integer being the number of the external choice in the input list.' id="5" />
                                                <Output name="output_1" type="0" type_size="1" nature="2" inner="0" tooltip="This IO has been automatically added by box. Read box tooltip for more information." id="6" />
                                                <Output name="output_2" type="0" type_size="1" nature="2" inner="0" tooltip="This IO has been automatically added by box. Read box tooltip for more information." id="7" />
                                                <Output name="output_3" type="0" type_size="1" nature="2" inner="0" tooltip="This IO has been automatically added by box. Read box tooltip for more information." id="8" />
                                                <Parameter name="Minimum threshold to understand" inherits_from_parent="0" content_type="2" value="0.2" default_value="0.2" min="0" max="1" tooltip="Minimum threshold to get in order to be understood by the robot." id="9" />
                                                <Parameter name="Minimum threshold to be sure" inherits_from_parent="0" content_type="2" value="0.3" default_value="0.3" min="0" max="1" tooltip="Minimum threshold to get so that the robot would be sure about the user&apos;s&#x0A;answer. Below this threshold, the robot asks a confirmation about what has been&#x0A;understood." id="10" />
                                                <Parameter name="Speech recognition timeout when confirmation" inherits_from_parent="0" content_type="1" value="6" default_value="6" min="1" max="20" tooltip="When the robot asks if what he understood is correct, after this time, if there has been&#x0A;nothing heard, the speech recognition is stopped and the answer understood is&#x0A;considered as correct." id="11" />
                                                <Parameter name="Speech recognition timeout" inherits_from_parent="0" content_type="1" value="6" default_value="6" min="1" max="20" tooltip="After this time, if there has been nothing heard, the speech recognition is stopped&#x0A;and the question is repeated or is skipped." id="12" />
                                                <Parameter name="Maximum number of repetition when no reply" inherits_from_parent="0" content_type="1" value="3" default_value="3" min="1" max="20" tooltip='After this number of times when the user did not reply, the question is skipped, and&#x0A;the output other is stimulated with &quot;timeout&quot;.' id="13" />
                                                <Parameter name="Repeat validated choice" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="If this option is activated, the robot repeats the validated choice when it exits the box." id="14" />
                                                <Parameter name="Activate ears light" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="Activate ears light animation (turn, flash, etc...)." id="15" />
                                                <Parameter name="Activate eyes light" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="Activate eyes light animation (turn, flash, etc...)." id="16" />
                                                <Parameter name="Activate brain light" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="Activate brain light animation (turn, flash, etc...)." id="17" />
                                                <Parameter name="Tactile sensor menu timeout" inherits_from_parent="0" content_type="1" value="10" default_value="10" min="1" max="20" tooltip="After this time, if there has been no action made on the tactile sensor or the torso&#x0A;button, the choice currently selected is repeated or the question is skipped." id="18" />
                                                <Parameter name="Maximum number of repetition when failure" inherits_from_parent="0" content_type="1" value="5" default_value="5" min="1" max="20" tooltip='After this number of times when the robot did not understand the user, the question&#x0A;is skipped, and the output other is stimulated with &quot;notUnderstood&quot;.' id="19" />
                                                <Parameter name="Activate help when failure" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="When this parameter is activated, when the robot did not understand the user, he&#x0A;says some help enumerating available choices and attracting attention on the&#x0A;other available modalities (head tactile sensor)." id="20" />
                                                <Parameter name="Activate help command" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip='Enable the help command. So you can say &quot;help&quot; during the speech recognition&#x0A;and the robot will tell you more information.&#x0A;You will still be able to ask help by clicking the torso button.' id="21" />
                                                <Parameter name="Activate repeat command" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip='Activate the repeat command. So you can say &quot;repeat&quot; during the speech&#x0A;recognition and the robot will repeat the question.' id="22" />
                                                <Parameter name="Activate exit command" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip='Enable the exit command. So you can say &quot;exit&quot; during the speech recognition&#x0A;and the box will be stopped and the &apos;other&apos; output will be stimulated with&#x0A;&quot;wordRecognised&quot;.&#x0A;You will still be able to exit the box with&#x0A;the tactile sensor.' id="23" />
                                                <Parameter name="Sentences file" inherits_from_parent="0" content_type="4" value="/Aldebaran/choice_sentences_light.xml" default_value="/Aldebaran/choice_sentences_light.xml" tooltip="File containing all necessary sentences in each supported language." id="24" />
                                            </Box>
                                            <Box name="Localized Text" id="5" localization="8" tooltip="Send on the output the text associated with the robot&apos;s current voice language.&#x0A;You can display and edit the text associated with any language by&#x0A;selecting the language in the combobox.&#x0A;&#x0A;!!Warning!! The text sent on the output is NOT the displayed one but the one&#x0A;associated with the robot&apos;s current voice language." plugin="localizationbox_plugin" x="59" y="54">
                                                <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		try: # disable autoBind
			GeneratedClass.__init__(self, False)
		except TypeError: # if NAOqi < 1.14
			GeneratedClass.__init__( self )

		self.tts = ALProxy("ALTextToSpeech")
		self.sentences = {
			"Arabic" : "  ",
			"Czech" : " Máš rád čokoládu? ",
			"Danish" : " Kan du lide chokolade? ",
			"German" : " Mögen Sie Schokolade? ",
			"Greek" : "  ",
			"English" : " Do you have an appointment ",
			"Spanish" : " ¿Te gusta el chocolate? ",
			"Finnish" : " Pidätkö suklaasta? ",
			"French" : " Aimes-tu le chocolat ? ",
			"Italian" : " Ti piace il cioccolato? ",
			"Japanese" : " チョコレートが好きですか ",
			"Korean" : " 당신은 초콜렛을 좋아합니까? ",
			"Dutch" : " Hou je van chocolade? ",
			"Norwegian" : "  ",
			"Polish" : " Lubisz czekoladę? ",
			"Brazilian" : " Você gosta de chocolate? ",
			"Portuguese" : " Gostas de chocolate? ",
			"Russian" : " Вы любите шоколад? ",
			"Swedish" : " Gillar du choklad? ",
			"Turkish" : " Çikolata sever misin? ",
			"Chinese" : "  "
		}

	def onInput_onStart(self):
		sDefaultLang = self.tts.getLanguage()
		self.onStopped(self.sentences[sDefaultLang])]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <![CDATA[]]>
</arabic>
                                                    <czech>
                                                        <![CDATA[Máš rád čokoládu?]]>
</czech>
                                                    <danish>
                                                        <![CDATA[Kan du lide chokolade?]]>
</danish>
                                                    <german>
                                                        <![CDATA[Mögen Sie Schokolade?]]>
</german>
                                                    <greek>
                                                        <![CDATA[]]>
</greek>
                                                    <english>
                                                        <![CDATA[Do you have an appointment]]>
</english>
                                                    <spanish>
                                                        <![CDATA[¿Te gusta el chocolate?]]>
</spanish>
                                                    <finnish>
                                                        <![CDATA[Pidätkö suklaasta?]]>
</finnish>
                                                    <french>
                                                        <![CDATA[Aimes-tu le chocolat ?]]>
</french>
                                                    <italian>
                                                        <![CDATA[Ti piace il cioccolato?]]>
</italian>
                                                    <japanese>
                                                        <![CDATA[チョコレートが好きですか]]>
</japanese>
                                                    <korean>
                                                        <![CDATA[당신은 초콜렛을 좋아합니까?]]>
</korean>
                                                    <dutch>
                                                        <![CDATA[Hou je van chocolade?]]>
</dutch>
                                                    <norwegian>
                                                        <![CDATA[]]>
</norwegian>
                                                    <polish>
                                                        <![CDATA[Lubisz czekoladę?]]>
</polish>
                                                    <brazilian>
                                                        <![CDATA[Você gosta de chocolate?]]>
</brazilian>
                                                    <portuguese>
                                                        <![CDATA[Gostas de chocolate?]]>
</portuguese>
                                                    <russian>
                                                        <![CDATA[Вы любите шоколад?]]>
</russian>
                                                    <swedish>
                                                        <![CDATA[Gillar du choklad?]]>
</swedish>
                                                    <turkish>
                                                        <![CDATA[Çikolata sever misin?]]>
</turkish>
                                                    <chinese>
                                                        <![CDATA[]]>
</chinese>
                                                    <language>5</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Data is sent on the output when this input is stimulated." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Data sent when asked." id="3" />
                                            </Box>
                                            <Link inputowner="1" indexofinput="2" outputowner="5" indexofoutput="3" />
                                            <Link inputowner="5" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="0" indexofinput="4" outputowner="1" indexofoutput="5" />
                                            <Link inputowner="0" indexofinput="5" outputowner="1" indexofoutput="6" />
                                            <Link inputowner="0" indexofinput="5" outputowner="1" indexofoutput="7" />
                                            <Link inputowner="0" indexofinput="6" outputowner="1" indexofoutput="8" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Speech" type="Lock" timeout="0" />
                            <Resource name="Speech recognition" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Choice (light) (2)" id="4" localization="8" tooltip="Launch speech recognition, and wait for one of a defined number of expected answers (written in the table of the box). the robot will prompt the speaker if he cannot understand and give suggestions as to available answers and other ways of selecting your choice. e.g. The tactile sensor on his head.&#x0A;&#x0A;Note that you must open this box to enter the question text and the available answers.&#x0A;&#x0A;This is a lighter version of Choice box from standard library which has no animation embedded.&#x0A;&#x0A;V1.1.0&#x0A;" x="993" y="611">
                            <bitmap>media/images/box/interaction/choice.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                            <Output name="answer" type="3" type_size="1" nature="1" inner="0" tooltip="Answer recognized." id="5" />
                            <Output name="output" type="3" type_size="1" nature="1" inner="0" tooltip="" id="6" />
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Choice" id="1" localization="8" tooltip="Launch the speech recognition waiting for a defined number of predicted answers (written in the table on the box). Available help&#x0A;from the robot which gives some possible answers and attracts attention on the other modalities to answer (head tactile sensor).&#x0A;&#x0A;You can edit a choice by left double-clicking on the line. You can add a choice by right clicking on a line and selecting &apos;Insert a&#x0A;row&apos;. You can delete a choice by right clicking on a line and selecting &apos;Remove a row&apos;. You can also write several alternative&#x0A;answers for the same choice by writing them on the line separated by the character &apos;/&apos;.&#x0A;Ex: apple pie / pie / apple&#x0A;Then if any of these answers (&apos;apple pie&apos;, &apos;pie&apos; or &apos;apple&apos;) are said, the corresponding output will be activated. Indeed, each output&#x0A;which name begins with &apos;output_&apos; correspond to the choice in the list placed just in front of the output.&#x0A;&#x0A;Moreover, you have advanced options appearing when you click on the blue cross. Then you can make the robot calculate the threshold&#x0A;average of choices with the 1/2/3 button. Actually, it will calculate recognition threshold of each alternative answer and put them from&#x0A;highest to smallest threshold. The threshold displayed in front of each choice then is the highest&apos;s." plugin="ui_choice_plugin" x="312" y="51">
                                                <bitmap>media/images/box/interaction/choice.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
# -*- coding: utf-8 -*-
# script of the Choice box v8.8
# @author Desktop Application team
# (c) 2011 Aldebaran Robotics

import os
import time
import random
import thread
import mutex
import xml.dom.minidom

class MyClass(GeneratedClass):
    def __init__(self):
        try: # disable autoBind
          GeneratedClass.__init__(self, False)
        except TypeError: # if NAOqi < 1.14
          GeneratedClass.__init__( self )

        # PROXIES INITIALIZATION
        self.tts = ALProxy("ALTextToSpeech")
        self.ttsStop = ALProxy("ALTextToSpeech", True) #Create another proxy as wait is blocking if audioout is remote
        self.memory = ALProxy("ALMemory")
        try:
            self.asr = ALProxy("ALSpeechRecognition")
            self.ad = ALProxy("ALAudioDevice")
            self.player = ALProxy("ALAudioPlayer")
            self.dcm = ALProxy( "DCM" )
        except:
            self.logger.warning("cannot find ALSpeechRecognition, choice box will run in simulation mode")
            self.asr = None
            self.ad = None
            self.player = None
            self.dcm = None

        self.leds = ALProxy( "ALLeds" )
        # VARIABLES INITIALIZATION
        self.aIdsTTS = []
        self.bSentencesInitialized = False
        self.bMustStop = False
        self.bIsRunning = False
        self.bGoOut = False
        self.nCountNoReply = 0
        self.nCountFailure = 0
        self.aFrameNumbers = {"end" : 1,
                              "headDown" : 10,
                              "bodyTalk" : 20,
                              "reco" : 30,
                              "headCheck" : 40,
                              "helpTactileSensor" : 50,
                              "notUnderstood" : 70}
        self.nFrameNumber = self.aFrameNumbers["end"]
        self.bInConfirmation = False
        self.bVocabularyLoaded = False
        self.bRecoIsHearingOrAnalysing = False
        self.bRecoIsWaitingForVoice = False
        self.bHasAlreadyHearingEyes = False
        self.bInTactileSensorMenu = False
        self.bExternChoices = False
        self.bBrainAnimPaused = False
        self.rTimeLastChoiceSaid = -1.
        self.bIsSayingChoice = False
        self.nIndexChoice = 0
        self.sRecoInterruption = "" # = "wordRecognised" or "timeout" or "onStop" or "onTactileSensor"
        self.sPreviousAnswer = ""
        self.rTimeWhenActionMadeInTactileMenu = -1.
        # variables used for the tactile sensor
        self.nFront = 0
        self.nMiddle = 0
        self.nRear = 0
        self.bSeqStarted = False
        self.bIsStoringParam = False
        self.bPressed = False
        self.mutexProcessCurrentState = mutex.mutex()
        self.mutexTactilTouched = mutex.mutex()
        self.mutexCheckIfSeqsCorrespondingLeft = mutex.mutex()
        self.bSeqStarted = False
        # assuming that every sequence is after [0, 0, 0]
        # and then start with one tactil sensor activated
        # timeout must be either a number (int or float) not equal to 0 or an array of two numbers not equal to 0, a negative one and a positive one
        # a negative timeout means a minimum time that has to ellapse before the next step
        # a positive timeout means a maximum time before the next step must show up
        self.aSeqs = [{"name" : "Tap", "statesAndTimeout" : [ "1+", 0.35, "2+", 0.45, "0" ]},
                      {"name" : "TapFront", "statesAndTimeout" : [ "F", 1, "0" ]},
                      {"name" : "LongFront", "statesAndTimeout" : [ "F", -1, "F" ]},
                      {"name" : "TapMiddle", "statesAndTimeout" : [ "M", 1, "0" ]},
                      {"name" : "LongMiddle", "statesAndTimeout" : [ "M", -1, "M" ]},
                      {"name" : "TapRear", "statesAndTimeout" : [ "R", 1, "0" ]},
                      {"name" : "LongRear", "statesAndTimeout" : [ "R", -1, "R" ]},
                      {"name" : "CalmDown", "statesAndTimeout" : [ "1+", 0.5, "2+", -1, "2+" ]}]
        # sequences initialization
        aSeqsTemp = []
        for seq in self.aSeqs:
            try: # ensure that the sequence has at least a name and states and timeout defined
                seq["name"]
                seq["statesAndTimeout"]
                aSeqsTemp.append(seq)
            except:
                pass
        self.aSeqs = aSeqsTemp
        for seq in self.aSeqs:
            states = range( len( seq["statesAndTimeout"][0:len(seq["statesAndTimeout"]):2] ) )
            i = 0
            for state in seq["statesAndTimeout"][0:len(seq["statesAndTimeout"]):2]:
                states[i] = self.convertToArrayOfPossibleStates(state)
                i += 1
            seq["statesAndTimeout"][0:len(seq["statesAndTimeout"]):2] = states
        self.aDetectedSeqs = []
        self.aDetectedSeqs.extend(self.aSeqs)
        # end - variables used for the tactile sensor
        self.aChoices = []
        self.aChoiceIndexes = []
        # parameters which can be changed from the parameters edition window
        self.sQuestion = ""
        self.nTimeoutReco = 6
        self.nTimeoutRecoConfirmation = 6
        self.nTimeoutTactile = 10
        self.nMaxCountNoReply = 3
        self.nMaxCountFailure = 5
        self.arUnderstoodThreshold = [0.0, 1.0] # range of self.rUnderstoodThreshold
        self.arConfirmationThreshold = [0.0, 1.0] # range of self.rConfirmationThreshold (must be higher than self.arUnderstoodThreshold)
        self.rUnderstoodThreshold = 0.2
        self.rConfirmationThreshold = 0.4
        self.bActivateEyesLight = True
        self.bActivateEarsLight = True
        self.bActivateBrainLight = True
        self.bActivateHelpWhenFailure = True
        self.bRepeatValidatedChoice = True
        self.bActivateDefaultChoiceHelp = True
        self.bActivateDefaultChoiceRepeat = True
        self.bActivateDefaultChoiceExit = True
        self.BIND_PYTHON(self.getName(), "onTactilTouched")
        self.BIND_PYTHON(self.getName(), "onWordRecognized")
        self.BIND_PYTHON(self.getName(), "onSpeechDetected")


# FUNCTIONS ===============================================================================================

    def onLoad(self):
        # initialize sentences for each language
        if( not self.bSentencesInitialized ):
            self.initializeSentences()
            self.bSentencesInitialized = True

# XML PARSER FOR SENTENCES INITIALIZATION
    def initializeSentences(self):
        "Initialize necessary sentences in each language."
        framemanager = ALProxy("ALFrameManager")
        filename = framemanager.getBehaviorPath(self.behaviorId) + self.tryGetParameter( "Sentences file", "/Aldebaran/choice_sentences.xml" )
        if not self.fileExists(filename):
            raise RuntimeError("File " + filename + " could not be found. Please update your Choice box with a newer one from Choregraphe")
        try:
            doc = self.getFileContents( filename )
            dom = xml.dom.minidom.parseString( doc )
        except Exception as e:
            raise Exception( "The " + filename + " file is not in the right format. Check the special characters and that the syntax is correct.\n" + str(e) )
        try:
            tag = "sentences"
            mainBlock = dom.getElementsByTagName( tag )[0]
            tag = "translation"
            aTranslations = mainBlock.getElementsByTagName( tag )
            self.aAllWords = {}
            self.aAllSentences = {}
            for sTranslation in aTranslations:
                sLanguage = sTranslation.getAttribute("language")
                tag = "speechReco"
                blockSpeechReco = sTranslation.getElementsByTagName( tag )[0]
                # variable used for the speech recognition
                self.aAllWords[sLanguage] = {}
                aKinds = ["negative",
                          "positive",
                          "help",
                          "exit",
                          "repeat"]
                for sKind in aKinds:
                    tag = sKind
                    blockWordsForThisKind = blockSpeechReco.getElementsByTagName( sKind )[0]
                    self.aAllWords[sLanguage][sKind] = blockWordsForThisKind.getAttribute( "text" ).encode("utf-8").split("/")
                # end - variable used for the speech recognition
                tag = "tts"
                blockTTS = sTranslation.getElementsByTagName( tag )[0]
                # variable used for the Text-To-Speech
                self.aAllSentences[sLanguage] = {}
                aKinds = ["confirmation",
                          "enumMarks",
                          "helpEnumChoices",
                          "helpEnumDefault",
                          "helpTactile",
                          "notUnderstood",
                          "noQuestion",
                          "notUnderstoodAnims"]
                for sKind in aKinds:
                    tag = sKind
                    blockSentencesForThisKind = blockTTS.getElementsByTagName( sKind )[0]
                    self.aAllSentences[sLanguage][sKind] = blockSentencesForThisKind.getAttribute( "text" ).encode("utf-8").split("/")
                # end - variable used for the Text-To-Speech
        except Exception as e:
            raise Exception( "The " + filename + " file is not in the right format. Check that the '" + tag + "' tag is defined and with the right format.\n" + str(e) )

        # choices
        # !!! don't remove any comments from this variable !!!
        # (they are here to make the plugin work)
        self.aListAllChoices = {"Arabic": ["نعم", "لا", "", ""], "Brazilian": ["sim", "não", "", ""], "Chinese": ["是", "不是", "", ""], "Czech": ["ano", "ne", "", ""], "Danish": ["ja", "nej", "", ""], "Dutch": ["ja", "nee", "", ""], "English": ["", "Yes", "No", ""], "Finnish": ["kyllä", "ei", "", ""], "French": ["oui", "non", "", ""], "German": ["ja", "nein", "", ""], "Greek": ["ναί", "κανένα", "", ""], "Italian": ["sì", "no", "", ""], "Japanese": ["はい", "いいえ", "", ""], "Korean": ["예", "아니", "", ""], "Norwegian": ["ja", "Nei", "", ""], "Polish": ["tak", "nie", "", ""], "Portuguese": ["sim", "não", "", ""], "Russian": ["да", "нет", "", ""], "Spanish": ["si", "no", "", ""], "Swedish": ["ja", "ingen", "", ""], "Turkish": ["evet", "hayır", "", ""]
                               }
        # end - choices

# INPUTS ACTIVATION PROCESSING ------------------------------------------------------------------------------
    def onInput_onStart(self, question=None):
        "Initialize variables and start box behaviour."
        self.logger.debug( "Input onStart stimulated." )
        if( self.bIsRunning): # to avoid starting the process twice
            return
        self.bIsRunning = True
        if(self.asr != None):
            self.asr.setVisualExpression( False )
        language = self.tts.getLanguage()
        if(self.asr != None):
            self.asr.setLanguage( language )
        try:
            self.aAllWords[language]
            self.aAllSentences[language]
        except:
            raise Exception( "The current language is not supported by this Choice box. It is probably deprecated. Try to use the one supplied in Choregraphe library instead." )
        self.asNegativeWords = self.aAllWords[language]["negative"]
        self.asPositiveWords = self.aAllWords[language]["positive"]
        self.asHelpWords = self.aAllWords[language]["help"]
        self.asExitWords = self.aAllWords[language]["exit"]
        self.asRepeatWords = self.aAllWords[language]["repeat"]
        self.bGoOut = False
        self.bVocabularyLoaded = False
        self.bRecoIsHearingOrAnalysing = False
        self.bRecoIsWaitingForVoice = False
        self.bHasAlreadyHearingEyes = False
        self.sRecoInterruption = ""
        self.sPreviousAnswer = ""
        self.bMustStop = False
        self.nCountNoReply = 0
        self.nCountFailure = 0
        self.nFrameNumber = self.aFrameNumbers["end"]
        self.beginTime = time.time()
        self.bInConfirmation = False
        self.bInTactileSensorMenu = False
        self.bBrainAnimPaused = False
        self.bPressed = False
        self.rTimeWhenActionMadeInTactileMenu = -1.
        self.nFront = 0
        self.nMiddle = 0
        self.nRear = 0
        self.bSeqStarted = False
        self.bIsStoringParam = False
        self.rUnderstoodThreshold = self.tryGetParameter( "Minimum threshold to understand", 0.2 )
        self.rConfirmationThreshold = self.tryGetParameter( "Minimum threshold to be sure", 0.4 )
        self.nTimeoutReco = self.tryGetParameter( "Speech recognition timeout", 6 )
        self.nTimeoutRecoConfirmation = self.tryGetParameter( "Speech recognition timeout when confirmation", 6 )
        self.nTimeoutTactile = self.tryGetParameter( "Tactile sensor menu timeout", 10 )
        self.nMaxCountNoReply = self.tryGetParameter( "Maximum number of repetition when no reply", 3 )
        self.nMaxCountFailure = self.tryGetParameter( "Maximum number of repetition when failure", 5 )
        self.bActivateEyesLight = self.tryGetParameter( "Activate eyes light", True )
        self.bActivateEarsLight = self.tryGetParameter( "Activate ears light", True )
        self.bActivateBrainLight = self.tryGetParameter( "Activate brain light", True )
        self.bActivateHelpWhenFailure = self.tryGetParameter( "Activate help when failure", True )
        self.bRepeatValidatedChoice = self.tryGetParameter( "Repeat validated choice", True )
        self.bActivateDefaultChoiceHelp = self.tryGetParameter( "Activate help command", True )
        self.bActivateDefaultChoiceRepeat = self.tryGetParameter( "Activate repeat command", True )
        self.bActivateDefaultChoiceExit = self.tryGetParameter( "Activate exit command", True )
        self.aDefaultChoices = []
        if (self.bActivateDefaultChoiceHelp):
            self.aDefaultChoices.append( self.asHelpWords )
        if (self.bActivateDefaultChoiceRepeat):
            self.aDefaultChoices.append( self.asRepeatWords )
        if (self.bActivateDefaultChoiceExit):
            self.aDefaultChoices.append( self.asExitWords )
        if( question == None ):
            question = ""
        self.initQuestionAndChoices( question )
        if( len( self.aChoices ) > len( self.aDefaultChoices ) ): # if there is at least one choice (not a default one)
            self.nIndexChoice = len( self.aDefaultChoices )
        else: # if there are only default words
            self.nIndexChoice = 0
        self.bGoOut = False
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFFFFFF, 0.1 )
        # initialize tactile sensor handler
        self.initSeqDetected()
        # subscribe to tactile sensors extractors (launch tactile sensor handler)
        self.memory.subscribeToEvent( "FrontTactilTouched", self.getName(), "onTactilTouched" )
        self.memory.subscribeToEvent( "MiddleTactilTouched", self.getName(), "onTactilTouched" )
        self.memory.subscribeToEvent( "RearTactilTouched", self.getName(), "onTactilTouched" )
        thread.start_new_thread( self.loopLedsBrainTwinkle, () )
        while( not self.bGoOut ):
            self.questionRecognitionReaction()
        if( self.bInTactileSensorMenu ):
            self.nCountNoReply = 0
            if( self.nFrameNumber != self.aFrameNumbers["headDown"] ):
                self.nFrameNumber = self.aFrameNumbers["headDown"]
                try:
                    self.getTimeline().goTo(self.nFrameNumber)
                except: # if NAOqi < 1.14
                    try:
                        self.gotoAndStop(self.nFrameNumber)
                    except:
                        pass
            self.loopLedsBrainTurn()
        else:
            self.bIsRunning = False

    def onInput_choicesList(self, p):
        "Set choices list."
        self.logger.debug( "Input choicesList stimulated." )
        if( not self.bIsRunning ):
            self.bExternChoices = True
            language = "English"
            if(self.asr != None):
                language =  self.asr.getLanguage()
            self.asNegativeWords = self.aAllWords[language]["negative"]
            self.asPositiveWords = self.aAllWords[language]["positive"]
            self.asHelpWords = self.aAllWords[language]["help"]
            self.asExitWords = self.aAllWords[language]["exit"]
            self.asRepeatWords = self.aAllWords[language]["repeat"]
            self.bActivateDefaultChoiceHelp = self.tryGetParameter( "Activate help command", True )
            self.bActivateDefaultChoiceRepeat = self.tryGetParameter( "Activate repeat command", True )
            self.bActivateDefaultChoiceExit = self.tryGetParameter( "Activate exit command", True )
            self.aDefaultChoices = []
            if (self.bActivateDefaultChoiceHelp):
                self.aDefaultChoices.append( self.asHelpWords )
            if (self.bActivateDefaultChoiceRepeat):
                self.aDefaultChoices.append( self.asRepeatWords )
            if (self.bActivateDefaultChoiceExit):
                self.aDefaultChoices.append( self.asExitWords )
            self.aChoices = []
            self.aChoiceIndexes = []
            self.aChoices.extend( self.aDefaultChoices )
            index = 0
            for choice in p:
                if( self.isString(choice) ):
                    choice = choice.strip(" \t,;.\n") # remove space or tabs at beginning or end of a choice
                    if( choice != "" ):
                        choice = [ choice ]
                    else:
                        choice = []
                elif( self.isArray(choice) ):
                    if( choice != [] ):
                        for i in range( len( choice ) ):
                            if( self.isString(choice[i]) ):
                                choice[i] = choice[i].strip(" \t,;.\n") # remove space or tabs at beginning or end of a choice
                                if( len( choice[i] ) < 1 ):
                                    del choice[i]
                                    i -= 1 # to parse the good one next loop
                            else:
                                raise Exception( "Error in choices input syntax:\nIt must be an array of choices and each choice can be either a string or an array of strings (several possibilities for one choice)\nEx: ['choice1',['choice2a','choice2b']]\nbut: " + str(p) + " found" )
                else:
                    raise Exception( "Error in choices input syntax:\nIt must be an array of choices and each choice can be either a string or an array of strings (several possibilities for one choice)\nEx: ['choice1',['choice2a','choice2b']]\nbut: " + str(p) + " found" )
                if( len( choice ) > 0 ):
                    for sWord in choice:
                        for aDefaultChoice in self.aDefaultChoices:
                            if( sWord in aDefaultChoice ):
                                raise Exception( "Error in input choices list: You chose a word which is already used for default choices:\n" + str(sWord) + " is used for the default choice: " + str(aDefaultChoice[0]) )
                    self.aChoices.append( choice )
                    self.aChoiceIndexes.append( index )
                index += 1

    def onInput_onStop(self):
        "Stop box behaviour."
        self.logger.debug( "Input onStop stimulated." )
        if( self.bIsRunning ):
            self.goOut( self.asExitWords[0], "onStop" )
            self.sRecoInterruption = "onStop"
        else:
            self.onUnload()

# GENERAL FUNCTIONS ------------------------------------------------------------------------------------------

    def isString(self, strVariable):
        try:
            if( type( strVariable ) == type( "some string" ) ):
                return True
        except:
            pass
        return False

    def isArray(self, aVariable):
        try:
            if( type( aVariable ) == type( ["some array"] ) ):
                return True
        except:
            pass
        return False

    def fileExists(self, strPathFilename ):
        try:
            file = open( strPathFilename, 'r' )
            if( file ):
                file.close()
                return True
        except (IOError, os.error), err:
            pass
        return False

    def getFileContents(self, sFilename ):
        "read a file and return it's contents, or '' if not found, empty, ..."
        try:
            fileContent = open( sFilename )
            aBuf = fileContent.read()
            fileContent.close()
        except:
            try:
                fileContent.close()
            except:
                pass
            return ""
        return aBuf

    def getBrainLedName(self, nNumLed):
        "Get the name of the DCM led device from its number"
        "0 => front left; 1 => next in clock wise; until 11"
        numLed = nNumLed%12
        if( numLed <= 1 ):
            return "Head/Led/Front/Right/%d/Actuator/Value" % (1-numLed)
        elif( numLed >= 10 ):
            return "Head/Led/Front/Left/%d/Actuator/Value" % (numLed-10)
        elif( numLed <= 2 ):
            return "Head/Led/Middle/Right/%d/Actuator/Value" % (2-numLed)
        elif( numLed >= 9 ):
            return "Head/Led/Middle/Left/%d/Actuator/Value" % (numLed-9)
        elif( numLed <= 5 ):
            return "Head/Led/Rear/Right/%d/Actuator/Value" % (numLed-3)
        else:
            return "Head/Led/Rear/Left/%d/Actuator/Value" % (8-numLed)

    def skipTTS(self):
        for idtts in self.aIdsTTS:
            try:
                self.ttsStop.stop(idtts)
            except:
                self.logger.debug( "Warning: The Text-To-Speech could not have been stopped." )

    def tryGetParameter(self, sParameterName, defaultValue):
        try:
            return self.getParameter( sParameterName )
        except:
            return defaultValue

# QUESTION AND CHOICES INITIALIZATION ----------------------------------------------------------------------

    def initQuestionAndChoices(self, p):
        "Initialize the question and the choices."
        # question processing
        if( self.isString(p) ):
            self.sQuestion = p
        else:
            raise Exception( "Error in question input syntax:\nQuestion text\nexpected for example, but:\n" + str(p[0]) + "\nfound" )
        # choices processing
        if( not self.bExternChoices ):
            self.aChoices = []
            self.aChoiceIndexes = []
            self.aChoices.extend( self.aDefaultChoices )
            index = 0
            listChoices = self.aListAllChoices[self.tts.getLanguage()]
            for choice in listChoices:
                aChoice = choice.split( "/" )
                if( aChoice != [] ):
                    for i in range( len( aChoice ) ):
                        aChoice[i] = aChoice[i].strip(" \t,;.\n") # remove space or tabs at beginning or end of a choice
                        if( len( aChoice[i] ) < 1 ):
                            del aChoice[i]
                            i -= 1 # to parse the good one next loop
                if( len( aChoice ) > 0 ):
                    # check if there is a word which is already used for the default choices
                    for sWord in aChoice:
                        for aDefaultChoice in self.aDefaultChoices:
                            if( sWord in aDefaultChoice ):
                                raise Exception( "Error in choices list: You chose a word which is already used for default choices:\n" + str(sWord) + " is used for the default choice: " + str(aDefaultChoice[0]) )
                    # append the choice to the list if everything worked well
                    self.aChoices.append( aChoice )
                    self.aChoiceIndexes.append( index )
                index += 1
        # check that there is at least one choice (a default one or not)
        if( len( self.aChoices ) < 1 ):
            raise Exception( "Error in choices list: It is empty. There is no default choice nor choice entered." )

# QUESTION-RECOGNITION-REACTION -----------------------------------------------------------------------------

    def questionRecognitionReaction(self):
        "Ask question, launch speech recognition and process answer."
        self.ttsQuestionAndRecoInit()
        if( not self.bMustStop ):
            # stop movement animation
            if( self.nFrameNumber != self.aFrameNumbers["reco"] ):
                self.nFrameNumber = self.aFrameNumbers["reco"]
                try:
                    self.getTimeline().goTo(self.nFrameNumber)
                except: # if NAOqi < 1.14
                    try:
                        self.gotoAndStop(self.nFrameNumber)
                    except:
                        pass
            # start speech recognition
            self.logger.debug( "Speech recognition started." )
            self.memory.subscribeToEvent( "WordRecognized", self.getName(), "onWordRecognized" )
            self.bRecoIsWaitingForVoice = True
            self.memory.subscribeToEvent( "SpeechDetected", self.getName(), "onSpeechDetected" )
        # leds during the recognition
        self.loopLedsReco()
        # process the reco loop break
        self.processRecoInterruption()

    def ttsQuestionAndRecoInit(self):
        "Ask question and initialize the speech recognition during the question to gain time in the interaction."
        if( not self.bInConfirmation ):
            # launch TTS
            idTTS = -1
            if( self.sQuestion != ""):
                idTTS = self.tts.post.say( self.sQuestion )
                self.aIdsTTS.append( idTTS )
                self.logger.debug( "Robot says: " + str(self.sQuestion) )
                # launch TTS movement animation
                if( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ):
                    self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
            # prepare speech recognition
            if(self.asr != None):
                self.asr.setLanguage( self.tts.getLanguage() )
            if( not self.bVocabularyLoaded ):
                aWordsRecognised = []
                for i in range( len( self.aChoices ) ):
                    if( self.aChoices[i] != [] ):
                        aWordsRecognised.extend( self.aChoices[i] )
                sWordsRecognised = "You can say: "
                if( len( aWordsRecognised ) > 1 ):
                    for i in range( len( aWordsRecognised ) - 1 ):
                        sWordsRecognised += "'" + aWordsRecognised[i] + "', "
                if( len( aWordsRecognised ) > 0 ):
                    sWordsRecognised += "'" + aWordsRecognised[len( aWordsRecognised ) - 1] + "'"
                sWordsRecognised += "."
                self.logger.debug( sWordsRecognised )
                if(self.asr != None):
                    self.asr.setVocabulary( aWordsRecognised, False )
                self.bVocabularyLoaded = True
        else:
            # launch TTS
            sentence = self.aAllSentences[self.tts.getLanguage()]["confirmation"][0]
            idTTS = -1
            sentenceToSay = sentence % self.sPreviousAnswer
            if( sentenceToSay != ""):
                idTTS = self.tts.post.say( sentenceToSay )
                self.aIdsTTS.append( idTTS )
                self.logger.debug( "Robot says: " + str(sentenceToSay) )
                # launch TTS movement animation
                if( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ):
                    self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
            # prepare speech recognition
            aWordsRecognised = []
            aWordsRecognised.extend( self.asNegativeWords )
            aWordsRecognised.extend( self.asPositiveWords )
            sWordsRecognised = "You can say: "
            if( len( aWordsRecognised ) > 1 ):
                for i in range( len( aWordsRecognised ) - 1 ):
                    sWordsRecognised += "'" + aWordsRecognised[i] + "', "
            if( len( aWordsRecognised ) > 0 ):
                sWordsRecognised += "'" + aWordsRecognised[len( aWordsRecognised ) - 1] + "'"
            sWordsRecognised += "."
            self.logger.debug( sWordsRecognised )
            if(self.asr != None):
                self.asr.setVocabulary( aWordsRecognised, False )
            self.bVocabularyLoaded = False
        # wait for the end of the TTS
        if( idTTS != -1 ):
            try:
                self.tts.wait( idTTS, 0 )
            except:
                self.logger.debug( "Warning: Could not wait the TTS." )

    def processRecoInterruption(self):
        "Process speech recognition interruption (timeout, action on tactile sensor, word said, etc...)"
        # wait for the end of the reaction (help, not understood, etc...)
        while( self.sRecoInterruption == "" ):
            time.sleep( 0.2 )
        self.logger.debug( "The speech recognition has been interrupted because of: " + str(self.sRecoInterruption) + "." )
        if( self.sRecoInterruption == "timeout" ): # if recognition interrupted by timeout
            try:
                # stop recognition
                self.memory.unsubscribeToEvent( "WordRecognized", self.getName() )
                self.bRecoIsWaitingForVoice = False
                self.bRecoIsHearingOrAnalysing = False
                self.logger.debug( "Speech recognition stopped." )
                self.memory.unsubscribeToEvent( "SpeechDetected", self.getName() )
            except:
                pass
            if( self.bInConfirmation ): # if it was a confirmation question
                # leds noticing that the robot confirm its guessing
                thread.start_new_thread( self.ledsUnderstood, (True, False) )
                # if nothing has been said, we assume that the user agree
                self.bInConfirmation = False
                if( self.sPreviousAnswer in self.asHelpWords ): # if help asked
                    self.helpWhenAsked()
                elif( self.sPreviousAnswer in self.asRepeatWords ): # if repeat asked
                    self.repeatWhenNoQuestion()
                    # repeat the question
                else: # if not repeat nor help asked
                    self.goOut( self.sPreviousAnswer, "wordRecognised" )
            else:
                # reinitialize leds
                self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
                self.nCountNoReply += 1
                if( self.nCountNoReply >= self.nMaxCountNoReply ):
                    self.goOut( self.asExitWords[0], "timeout" )
        else:
            self.nCountNoReply = 0
            if( self.sRecoInterruption in [ "onStop" ] ):
                self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        self.sRecoInterruption = ""

    def repeatWhenNoQuestion(self):
        "Robot's reaction when it is asked to repeat the question when there is no question."
        if( self.sQuestion == "" ):
            sentenceNoQuestion = self.aAllSentences[self.tts.getLanguage()]["noQuestion"][0]
            sentenceNoQuestion += self.enumerateChoices( True ) # True to ask that the introduction is played
            if( len( self.aChoices ) - len( self.aDefaultChoices ) == 0 ): # if there is no choice
                sentenceNoQuestion += self.enumerateDefaultChoices( True ) # True to ask that the introduction is played
            # launch TTS
            idTTS = -1
            if( sentenceNoQuestion != ""):
                if( self.bInTactileSensorMenu ):
                    idTTS = self.tts.post.say( sentenceNoQuestion + "\\Pau=300\\" )
                else:
                    idTTS = self.tts.post.say( sentenceNoQuestion )
                self.aIdsTTS.append( idTTS )
                self.logger.debug( "Robot says: " + str(sentenceNoQuestion) )
                if( not self.bInTactileSensorMenu ):
                    # launch TTS movement animation
                    if( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ):
                        self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                        try:
                            self.getTimeline().goTo(self.nFrameNumber)
                        except: # if NAOqi < 1.14
                            try:
                                self.gotoAndStop(self.nFrameNumber)
                            except:
                                pass
            # wait for the end of the TTS
            if( idTTS != -1 ):
                try:
                    self.tts.wait( idTTS, 0 )
                except:
                    self.logger.debug( "Warning: Could not wait the TTS." )

# RECO OUTPUT PROCESSING --------------------------------------------------------------------------------------

    def onWordRecognized(self, pDataName, pValue, pMessage):
        "Handler for when a word is recognised by the speech recognition system."
        aState = pValue
        self.logger.debug( "The word '" + str(aState[0]) + "' has been recognised with a threshold of " + str(aState[1]) + "." )
        # interrupt loops:
            # - stop reco
            # - stop leds
            # - stop asking the question on and on
        try:
            self.memory.unsubscribeToEvent( "WordRecognized", self.getName() )
            self.logger.debug( "Speech recognition stopped." )
            self.memory.unsubscribeToEvent( "SpeechDetected", self.getName() )
        except:
            pass
        self.bRecoIsHearingOrAnalysing = False
        self.bRecoIsWaitingForVoice = False
        if( aState[0] != "" ):
            if( aState[1] >= self.rUnderstoodThreshold ):
                if( self.rUnderstoodThreshold <= self.arUnderstoodThreshold[1] - 0.02 ):
                    self.rUnderstoodThreshold += 0.02
                else:
                    self.rUnderstoodThreshold = self.arUnderstoodThreshold[1]
                if( self.bInConfirmation ):
                    if( aState[0] in self.asNegativeWords ):
                        thread.start_new_thread( self.ledsNegative, () )
                    else:
                        thread.start_new_thread( self.ledsUnderstood, (True, False) )
                else:
                    thread.start_new_thread( self.ledsUnderstood, (True, False) )
                self.reactionWordUnderstood( aState )
            else:
                if( self.rUnderstoodThreshold >= self.arUnderstoodThreshold[0] + 0.05 ):
                    self.rUnderstoodThreshold -= 0.05
                else:
                    self.rUnderstoodThreshold = self.arUnderstoodThreshold[0]
                aCurrentChoice = ""
                for choice in self.aChoices:
                    if( aCurrentChoice == "" ):
                        if( aState[0] in choice ):
                            aCurrentChoice = choice
                if( self.sPreviousAnswer in aCurrentChoice ): # if answer in the same choice as previously
                    # then ask confirmation
                    aState[1] = self.rConfirmationThreshold - 0.01
                    thread.start_new_thread( self.ledsUnderstood, (True, False) )
                    self.reactionWordUnderstood( aState )
                else:
                    # else not understood
                    if( self.bInConfirmation ):
                        thread.start_new_thread( self.ledsUnderstood, (True, False) )
                    else:
                        self.sPreviousAnswer = aState[0]
                        thread.start_new_thread( self.ledsNotUnderstood, () )
                    self.reactionNothingUnderstood()
        else:
            if( self.bInConfirmation ):
                thread.start_new_thread( self.ledsUnderstood, (True, False) )
            else:
                thread.start_new_thread( self.ledsNotUnderstood, () )
            self.reactionNothingUnderstood()
        if( pMessage == "" ):
            self.sRecoInterruption = "wordRecognised"
        else:
            self.sRecoInterruption = pMessage

    def onSpeechDetected(self, pDataName, pValue, pMessage):
        "Handler for when something has been heard by the speech recognition system."
        aState = pValue
        if( aState == 1):
            if( self.bRecoIsWaitingForVoice ):
                # make eyes leds switch from an animation to an other
                self.bRecoIsHearingOrAnalysing = True
                self.bRecoIsWaitingForVoice = False
                try:
                    self.timeToReply(time.time() - self.beginTime)
                except:
                    pass

    def reactionWordUnderstood(self, word):
        "Reaction depending on the word recognised (help, repeat, word in choices, etc...) and its recognition confidence."
        if( self.bInConfirmation ):
            self.bInConfirmation = False
            if( word[0] in self.asNegativeWords ):
                # update number of failures
                self.nCountFailure += 1
                if( self.sPreviousAnswer in self.asHelpWords ):
                    if( self.nCountFailure >= self.nMaxCountFailure ): # if maximum number of failures
                        # skip the question
                        self.goOut( self.asExitWords[0], "notUnderstood" )
                else:
                    self.helpAfterFailure()
            else:
                if( (self.sPreviousAnswer in self.asHelpWords) or (word[0] in self.asHelpWords) ):
                    self.helpWhenAsked()
                elif( self.sPreviousAnswer in self.asRepeatWords or (word[0] in self.asRepeatWords) ):
                    self.repeatWhenNoQuestion()
                    # repeat the question
                else:
                    self.goOut( self.sPreviousAnswer, "wordRecognised" )
                self.sPreviousAnswer = ""
        else:
            self.sPreviousAnswer = word[0]
            if( word[1] >= self.rConfirmationThreshold ):
                if( self.rConfirmationThreshold <= self.arConfirmationThreshold[1] - 0.02 ):
                    self.rConfirmationThreshold += 0.02
                else:
                    self.rConfirmationThreshold = self.arConfirmationThreshold[1]
                if( self.sPreviousAnswer in self.asHelpWords ):
                    self.helpWhenAsked()
                elif( self.sPreviousAnswer in self.asRepeatWords ):
                    self.repeatWhenNoQuestion()
                    # repeat the question
                else:
                    self.goOut( self.sPreviousAnswer, "wordRecognised" )
                self.sPreviousAnswer = ""
            else:
                if( self.rConfirmationThreshold >= self.arConfirmationThreshold[0] + 0.05 ):
                    self.rConfirmationThreshold -= 0.05
                else:
                    self.rConfirmationThreshold = self.arConfirmationThreshold[0]
                self.bInConfirmation = True

    def reactionNothingUnderstood(self):
        "Reaction when nothing has been understood or without an enough confidence."
        if( self.bInConfirmation ):
            # if the robot did not understand, we assume that the user agree
            self.bInConfirmation = False
            if( self.sPreviousAnswer in self.asHelpWords ): # if help asked
                self.helpWhenAsked()
            elif( self.sPreviousAnswer in self.asRepeatWords ): # if repeat asked
                self.repeatWhenNoQuestion()
                # repeat the question
            else: # if not repeat nor help asked
                self.goOut( self.sPreviousAnswer, "wordRecognised" )
        else:
            # update number of failures
            self.nCountFailure += 1
            if( self.nCountFailure <= 1 ): # if first failure
                sentence = self.aAllSentences[self.tts.getLanguage()]["notUnderstood"][0]
            else: # if second failure or more
                sentenceNotUnderstoodAnims = self.aAllSentences[self.tts.getLanguage()]["notUnderstoodAnims"]
                index = random.randint( 0, len( sentenceNotUnderstoodAnims ) - 1 )
                sentence = sentenceNotUnderstoodAnims[index]
                if( self.nFrameNumber != self.aFrameNumbers["notUnderstood"] + 10*index ):
                    self.nFrameNumber = self.aFrameNumbers["notUnderstood"] + 10*index
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
            self.helpAfterFailure( sentence )

# HELP ------------------------------------------------------------------------------------------------------

    def enumerateChoices(self, bIntroToSay):
        "Enumerate choices (only the first word of each choice is taken into account)."
        sentenceHelpEnumChoices = self.aAllSentences[self.tts.getLanguage()]["helpEnumChoices"]
        sentenceHelpEnumMarks = self.aAllSentences[self.tts.getLanguage()]["enumMarks"]
        enumWords = ""
        maxNbEnumChoices = 3
        indexes = []
        for i in range( min(maxNbEnumChoices, len( self.aChoices ) - len( self.aDefaultChoices )) ):
            if( len( self.aChoices ) - len( self.aDefaultChoices ) <= maxNbEnumChoices ):
                index = len( self.aDefaultChoices ) + i
            else:
                index = random.randint( len( self.aDefaultChoices ), len( self.aChoices ) - 1 )
                while( index in indexes ):
                    index = random.randint( len( self.aDefaultChoices ), len( self.aChoices ) - 1 )
            indexes.append( index )
            if( len( indexes ) != 1 ): # if it is not the first choice
                if( len( indexes ) != min(maxNbEnumChoices, len( self.aChoices ) - len( self.aDefaultChoices )) ): # if it is not the last choice
                    enumWords += sentenceHelpEnumMarks[0]
                else:
                    enumWords += sentenceHelpEnumMarks[1]
            enumWords += self.aChoices[index][0]
        sentenceTemplate = sentenceHelpEnumChoices[2]
        if( len( self.aChoices ) - len( self.aDefaultChoices ) <= maxNbEnumChoices ): # if there are 3 or less choices
            sentenceTemplate = sentenceHelpEnumChoices[1]
        if( not bIntroToSay ):
            sentenceTemplate = sentenceHelpEnumChoices[3]
        if( len( self.aChoices ) - len( self.aDefaultChoices ) == 0 ): # if there is no choice
            sentence = sentenceHelpEnumChoices[0]
        else:
            sentence = sentenceTemplate % enumWords
        return sentence

    def enumerateDefaultChoices(self, bIntroToSay):
        "Enumerate default choices (only the first word of each choice is taken into account)."
        sentenceHelpEnumChoices = self.aAllSentences[self.tts.getLanguage()]["helpEnumChoices"]
        sentenceHelpEnumDefault = self.aAllSentences[self.tts.getLanguage()]["helpEnumDefault"]
        sentenceHelpEnumMarks = self.aAllSentences[self.tts.getLanguage()]["enumMarks"]
        enumWords = ""
        indexes = []
        for i in range( len( self.aDefaultChoices ) ):
            indexes.append( i )
            if( len( indexes ) != 1 ): # if it is not the first choice
                if( len( indexes ) != len( self.aDefaultChoices ) ): # if it is not the last choice
                    enumWords += sentenceHelpEnumMarks[0]
                else:
                    enumWords += sentenceHelpEnumMarks[1]
            enumWords += self.aDefaultChoices[i][0]
        sentenceTemplate = sentenceHelpEnumDefault[0]
        if( not bIntroToSay ):
            sentenceTemplate = sentenceHelpEnumChoices[3]
        if( len( self.aDefaultChoices ) == 0 ): # if there is no default choice
            sentence = ""
        else:
            sentence = sentenceTemplate % enumWords
        return sentence

    def explanationTactileSensor(self):
        "Explain the possible interaction with the tactile sensor."
        sentenceHelpTactile = self.aAllSentences[self.tts.getLanguage()]["helpTactile"]
        if( self.bInTactileSensorMenu ):
            sentence = sentenceHelpTactile[1]
        else:
            sentence = sentenceHelpTactile[0]
        return sentence

    def helpWhenAsked(self, sentence = ""):
        "Help when the user asked it: enumerate choices, enumerate default choices and explain tactile sensor possible interaction."
        if( not self.bInTactileSensorMenu ):
            # enumeration of choices
            sentence += self.enumerateChoices( True ) # True to ask that the introduction is played
            # enumeration of default choices
            sentence += self.enumerateDefaultChoices( True ) # True to ask that the introduction is played
        # explanation about alternative modality (tactil sensor, arm motion)
        sentence += self.explanationTactileSensor()
        # launch TTS
        idTTS = -1
        if( sentence != "" ):
            if( self.bInTactileSensorMenu ):
                idTTS = self.tts.post.say( sentence + "\\Pau=300\\" )
            else:
                idTTS = self.tts.post.say( sentence )
            self.aIdsTTS.append( idTTS )
            self.logger.debug( "Robot says: " + str(sentence) )
            # launch TTS movement animation
            if( self.bInTactileSensorMenu ):
                if( self.nFrameNumber != self.aFrameNumbers["helpTactileSensor"] ):
                    self.nFrameNumber = self.aFrameNumbers["helpTactileSensor"]
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
            else:
                if( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ):
                    self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
        # wait for the end of the TTS
        if( idTTS != -1 ):
            try:
                self.tts.wait( idTTS, 0 )
            except:
                self.logger.debug( "Warning: Could not wait the TTS." )
        # repeat the question

    def helpAfterFailure(self, sentence = ""):
        "Help when the speech recognition failed (nothing understood or incorrect answer understood)."
        if( self.nCountFailure < self.nMaxCountFailure ): # if reasonable number of failures
            if( self.bActivateHelpWhenFailure ):
                if( self.nCountFailure in [1, 2] ): # if first or second failure
                    # enumeration of choices, or default words if there is no choice
                    if( len( self.aChoices ) - len( self.aDefaultChoices ) > 0 ): # if there is at least one choice
                        sentence += self.enumerateChoices( self.nCountFailure == 1 ) # the introduction is played if it is the first failure
                    else:
                        sentence += self.enumerateDefaultChoices( self.nCountFailure == 1 ) # the introduction is played if it is the first failure
                    if( self.nCountFailure == 2 ): # if second failure
                        # explanation about alternative modality (tactil sensor, arm motion)
                        sentence += self.explanationTactileSensor()
                # launch TTS
                idTTS = -1
                if( sentence != "" ):
                    idTTS = self.tts.post.say( sentence )
                    self.aIdsTTS.append( idTTS )
                    self.logger.debug( "Robot says: " + str(sentence) )
                    # launch TTS movement animation
                    listPossibleFrames = range( len( self.aAllSentences[self.tts.getLanguage()]["notUnderstoodAnims"] ) )
                    for i in range(len(listPossibleFrames)):
                        listPossibleFrames[i] = listPossibleFrames[i] * 10 + self.aFrameNumbers["notUnderstood"]
                    if( ( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ) and not ( self.nFrameNumber in listPossibleFrames ) ):
                        try:
                            self.getTimeline().goTo(self.aFrameNumbers["bodyTalk"])
                        except: # if NAOqi < 1.14
                            try:
                                self.gotoAndStop(self.aFrameNumbers["bodyTalk"])
                            except:
                                pass
                    self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                # wait for the end of the TTS
                if( idTTS != -1 ):
                    try:
                        self.tts.wait( idTTS, 0 )
                    except:
                        self.logger.debug( "Warning: Could not wait the TTS." )
            # repeat the question
        else: # if maximum number of failures
            # skip the question
            self.goOut( self.asExitWords[0], "notUnderstood" )

# LEDS ---------------------------------------------------------------------------------------------------

    def setLeds(self, eyesLight, earsLight, brainLight):
        "Set all LEDS (eyes, ears and brain lights)."
        rDuration = 1
        if( self.bActivateEyesLight ):
            # set eyes leds
            self.leds.post.fadeRGB( "FaceLeds", eyesLight, rDuration )
        if( self.bActivateEarsLight ):
            # set ears leds
            self.leds.fadeRGB( "EarLeds", earsLight, rDuration )
        if( self.bActivateBrainLight ):
            # set brain leds light
            self.setLedsBrain( brainLight, 500 )

    def ledsUnderstood(self, bFlashEars, bFlashBrain):
        "Sequence of LEDS for eyes, ears and brain when the robot understood what it heard."
        self.bBrainAnimPaused = True
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x00FF00, rDuration )
        if( self.bActivateEarsLight ):
            if( bFlashEars ):
                self.leds.fadeRGB( "EarLeds", 0x00FF00, rDuration )
        if( self.bActivateBrainLight ):
            if( bFlashBrain ):
                self.setLedsBrain( 0.5, int(rDuration * 1000) )
        time.sleep( 0.3 )
        rDuration = 0.2
        if( self.bActivateEyesLight ):
            if( self.bInTactileSensorMenu ):
                self.leds.fadeRGB( "FaceLeds", 0xFFFFFF, rDuration )
            else:
                self.leds.fadeRGB( "FaceLeds", 0x000000, rDuration )
        if( self.bActivateEarsLight ):
            if( bFlashEars ):
                self.leds.fadeRGB( "EarLeds", 0x000000, rDuration )
        if( self.bActivateBrainLight ):
            if( bFlashBrain ):
                self.setLedsBrain( 0., int(rDuration * 1000) )
        time.sleep( 0.1 )
        if( not self.bInTactileSensorMenu ):
            self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        time.sleep( 0.1 )
        self.bBrainAnimPaused = False

    def ledsNotUnderstood(self):
        "Sequence of LEDS for eyes and ears when the robot did not understand what it heard."
        self.bBrainAnimPaused = True
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFF0000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0xFF0000, rDuration )
        time.sleep( 0.05 )
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x000000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0x000000, rDuration )
        time.sleep( 0.05 )
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFF0000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0xFF0000, rDuration )
        time.sleep( 0.05 )
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x000000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0x000000, rDuration )
        time.sleep( 0.3 )
        self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        self.bBrainAnimPaused = False

    def ledsNegative(self):
        "Sequence of LEDS for eyes and ears when the robot understood 'no'."
        self.bBrainAnimPaused = True
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFF0000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0xFF0000, rDuration )
        time.sleep( 0.3 )
        rDuration = 0.2
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x000000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0x000000, rDuration )
        time.sleep( 0.1 )
        self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        time.sleep( 0.1 )
        self.bBrainAnimPaused = False

    def loopLedsReco(self):
        "LEDS (eyes and ears) process during the speech recognition."
        self.beginTime = time.time()
        if( self.bInConfirmation ):
            timerReco = self.beginTime + self.nTimeoutRecoConfirmation
        else:
            timerReco = self.beginTime + self.nTimeoutReco
        self.bHasAlreadyHearingEyes = False
        nEarLedsNextIndex = 0
        nEyesLed = -1
        while( self.bRecoIsWaitingForVoice or self.bRecoIsHearingOrAnalysing ):
            if( self.bMustStop ):
                try:
                    self.timeToReply(time.time() - self.beginTime)
                except:
                    pass
                break
            if( self.bRecoIsWaitingForVoice ):
                if( timerReco < time.time() ):
                    try:
                        self.timeToReply(timerReco - self.beginTime)
                    except:
                        pass
                    self.sRecoInterruption = "timeout"
                    break
            nEarLedsNextIndex = self.ledsEarsTurnOneStep( nEarLedsNextIndex )
            nEyesLed += 1
            self.ledsEyesTurnOneStep( 0x0055FF, nEyesLed%8 )
            time.sleep( 0.2 )

    def ledsEarsTurnOneStep(self, nEarLedsNextIndex):
        "One step of ears LEDS sequence (turn) when the robot is in speech recognition."
        if( self.bActivateEarsLight ):
            nNbrLedByEars = 10
            rTime = 0.7
            strTemplate = "Ears/Led/%s/%dDeg/Actuator/Value"
            nAngle = (360/nNbrLedByEars) * nEarLedsNextIndex
            # update index before sending movement in case of a fast/concurrent call of the function
            nEarLedsNextIndex -= 1 # more beautiful to turn in this way
            if( nEarLedsNextIndex < 0 ):
                nEarLedsNextIndex = nNbrLedByEars-1
            self.leds.post.fade( strTemplate % ( "Left", nAngle ), 1.0, rTime )
            self.leds.post.fade( strTemplate % ( "Right", nAngle ), 1.0, rTime )
            self.leds.post.fade( strTemplate % ( "Left", nAngle ), 0.0, rTime*1.2 )
            self.leds.post.fade( strTemplate % ( "Right", nAngle ), 0.0, rTime*1.2 )
        return nEarLedsNextIndex

    def ledsEyesTurnOneStep(self, nColor, nLed):
        "One step of eyes LEDS sequence (turn) when the robot is in speech recognition."
        if( self.bActivateEyesLight ):
            rTime = 0.7
            if( self.bRecoIsHearingOrAnalysing ):
                if( not self.bHasAlreadyHearingEyes ):
                    self.leds.fadeRGB( "FaceLeds", 0xF4FF22, 0.1 )
                    # start headcheck animation
                    if( self.nFrameNumber != self.aFrameNumbers["headCheck"] ):
                        self.nFrameNumber = self.aFrameNumbers["headCheck"]
                        try:
                            self.getTimeline().goTo(self.nFrameNumber)
                        except: # if NAOqi < 1.14
                            try:
                                self.gotoAndStop(self.nFrameNumber)
                            except:
                                pass
                    self.bHasAlreadyHearingEyes = True
            elif( self.bRecoIsWaitingForVoice ):
                self.leds.post.fadeRGB( "FaceLed%d" % (nLed) , nColor, rTime )
                self.leds.post.fadeRGB( "FaceLed%d" % (nLed) , 0x000000, rTime*1.25 )

    def ledsChangeOnTactile(self):
        self.bBrainAnimPaused = True
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x0055FF, rDuration )
        self.setLedsBrain( 0.5, int(rDuration * 1000) )
        time.sleep( 0.3 )
        rDuration = 0.2
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFFFFFF, rDuration )
        self.setLedsBrain( 0., int(rDuration * 1000) )
        time.sleep( 0.2 )
        self.bBrainAnimPaused = False

    def loopLedsBrainTurn(self):
        self.setLeds( 0xFFFFFF, 0xFFFFFF, 0. )
        rIntensity = 0.5
        nTime = 50
        bAlreadyPaused = False
        while( self.bInTactileSensorMenu ):
            if( not self.bBrainAnimPaused ):
                if( self.nFront == 1 or self.nMiddle == 1 or self.nRear == 1 ):
                    if( not bAlreadyPaused ):
                        bAlreadyPaused = True
                        self.setLedsBrain( 0., 50 )
                else:
                    bAlreadyPaused = False
                    if( self.bActivateBrainLight ):
                        for i in range( 12 ):
                            if( not self.bBrainAnimPaused and self.dcm != None):
                                riseTime = self.dcm.getTime(nTime)
                                strDeviceName = self.getBrainLedName(i)
                                self.dcm.set( [ strDeviceName, "Merge",  [[ rIntensity, riseTime ]] ] )
                                time.sleep( nTime/1000. )
                                if( not self.bBrainAnimPaused ):
                                    self.dcm.set( [ strDeviceName, "Merge",  [[ 0.0, riseTime + int(nTime)/4 ]] ] )
            time.sleep( nTime/1000. )
        self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )

    def loopLedsBrainTwinkle(self):
        rIntensity = 0.5
        bOnStep = True
        bAlreadyPaused = False
        while( not self.bInTactileSensorMenu and self.bIsRunning ):
            if( not self.bBrainAnimPaused ):
                if( self.nFront == 1 or self.nMiddle == 1 or self.nRear == 1 ):
                    if( not bAlreadyPaused ):
                        bAlreadyPaused = True
                        self.setLedsBrain( 0., 50 )
                else:
                    bAlreadyPaused = False
                    if( bOnStep ):
                        self.setLedsBrain( rIntensity, 700 )
                        bOnStep = False
                    else:
                        self.setLedsBrain( 0.0, 700 )
                        bOnStep = True
            time.sleep( 1 )

    def setLedsBrain(self, rIntensity, rTimeMs):
        "One step of brain LEDS sequence (twinkle) when the robot is in speech recognition."
        if( self.bActivateBrainLight and self.dcm != None):
            riseTime = self.dcm.getTime( rTimeMs )
            for i in range( 12 ):
                strDeviceName = self.getBrainLedName(i)
                self.dcm.set( [ strDeviceName, "Merge",  [[ rIntensity, riseTime ]] ] )

# TACTILE SENSOR MENU -------------------------------------------------------------------------------------

    def onAlternativeModalityAction(self, p):
        "Process actions from alternative modalities (sequence from the tactile sensor, simple click on the torso button...)."
        if( not self.bIsRunning ): # if the box is not running
            return # then go out without doing a thing
        if( not self.bInTactileSensorMenu ): # if we are not in the tactile sensor menu (so if we are in the question-recognition-reaction loop)
            if( p in ["TapFront", "TapMiddle", "TapRear", "LongFront", "LongMiddle", "LongRear"] ):
                bTTSRunning = False # to know if TTS is running
                for idTTS in self.aIdsTTS:
                    if( self.tts.isRunning( idTTS )):
                        bTTSRunning = True
                if( bTTSRunning ): # if TTS is running
                    # skip the TTS
                    self.skipTTS()
                else: # if TTS was not running (so if in recognition)
                    # prepare to start the tactile sensor menu
                    self.bInTactileSensorMenu = True
                    # and stop the question-recognition-reaction loop
                    self.goOutOfQuestionRecoReaction()
                    self.sRecoInterruption = "onTactileSensor"
                    # start the tactile sensor menu
                    self.sayCurrentChoice()
                    # start counting timeout
                    self.rTimeWhenActionMadeInTactileMenu = time.time()
                    thread.start_new_thread( self.loopCheckTimeoutInTactileMenu, (self.rTimeWhenActionMadeInTactileMenu,) )
            elif( p in ["Tap", "CalmDown"] ):
                # skip the TTS
                self.skipTTS()
                # then stop everything and cancel the question
                self.goOut( self.asExitWords[0], "onTactileSensor" )
                self.sRecoInterruption = "onTactileSensor"
                self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        else: # if we are in the tactile sensor menu
            self.rTimeWhenActionMadeInTactileMenu = -1.
            if( p in ["TapFront"] ):
                bTTSRunning = False # to know if TTS is running
                for idTTS in self.aIdsTTS:
                    if( self.tts.isRunning( idTTS ) ):
                        bTTSRunning = True
                if( self.bIsSayingChoice or not bTTSRunning ): # else just skip the TTS (in the sayCurrentChoice function)
                    # change choice
                    self.nIndexChoice += 1
                    if( self.nIndexChoice >= len( self.aChoices ) ):
                        self.nIndexChoice = 0
                # say the choice in the tactile sensor menu
                self.sayCurrentChoice()
                self.timeoutManagingInTactileMenu()
            elif( p in ["TapRear"] ):
                bTTSRunning = False # to know if TTS is running
                for idTTS in self.aIdsTTS:
                    if( self.tts.isRunning( idTTS )):
                        bTTSRunning = True
                if( self.bIsSayingChoice or not bTTSRunning ): # else just skip the TTS (in the sayCurrentChoice function)
                    # change choice
                    self.nIndexChoice -= 1
                    if( self.nIndexChoice < 0 ):
                        self.nIndexChoice = len( self.aChoices ) - 1
                # say the choice in the tactile sensor menu
                self.sayCurrentChoice()
                self.timeoutManagingInTactileMenu()
            elif( p in ["TapMiddle", "LongMiddle"] ):
                self.rTimeWhenActionMadeInTactileMenu = time.time()
                rTimeForThisAction = self.rTimeWhenActionMadeInTactileMenu
                bWasSayingChoice = self.bIsSayingChoice
                bTTSRunning = False # to know if TTS is running
                for idTTS in self.aIdsTTS:
                    if( self.tts.isRunning( idTTS )):
                        bTTSRunning = True
                # skip the TTS if it is running
                self.skipTTS()
                if( bWasSayingChoice or not bTTSRunning ):
                    # validate choice
                    thread.start_new_thread( self.ledsUnderstood, (False, True) )
                    if( self.aChoices[self.nIndexChoice][0] == self.asRepeatWords[0] ):
                        self.repeatWhenNoQuestion()
                        # launch TTS
                        idTTS = -1
                        if( self.sQuestion != ""):
                            idTTS = self.tts.post.say( self.sQuestion + "\\Pau=300\\" )
                            self.aIdsTTS.append( idTTS )
                            self.logger.debug( "Robot says: " + str(self.sQuestion) )
                        # wait for the end of the TTS
                        if( idTTS != -1 ):
                            try:
                                self.tts.wait( idTTS, 0 )
                            except:
                                self.logger.debug( "Warning: Could not wait the TTS." )
                    else:
                        self.reactionWordUnderstood( [ self.aChoices[self.nIndexChoice][0], 1.0 ] )
                if( self.bIsRunning and rTimeForThisAction == self.rTimeWhenActionMadeInTactileMenu ): #$$$
                    self.rTimeWhenActionMadeInTactileMenu = -1.
                    # say the choice in the tactile sensor menu
                    self.sayCurrentChoice()
                    self.timeoutManagingInTactileMenu()
            elif( p == "LongFront" ):
                if( not self.bPressed ):
                    self.bPressed = True
                    bLastElementSaid = False
                    while( self.bPressed ):
                        if( self.nFront == 0 ):
                            self.bPressed = False
                            break
                        bTTSRunning = False # to know if TTS is running
                        for idTTS in self.aIdsTTS:
                            if( self.tts.isRunning( idTTS )):
                                bTTSRunning = True
                        if( self.bIsSayingChoice or not bTTSRunning ):
                            # change choice
                            self.nIndexChoice += 1
                            if( self.nIndexChoice >= len( self.aChoices ) - 1 ):
                                self.nIndexChoice = len( self.aChoices ) - 1
                                if( not bLastElementSaid ):
                                    bLastElementSaid = True
                                    # say the choice in the tactile sensor menu
                                    thread.start_new_thread( self.sayCurrentChoice, () )
                            else:
                                # say the choice in the tactile sensor menu
                                thread.start_new_thread( self.sayCurrentChoice, () )
                        else:
                            if( self.nIndexChoice == len( self.aChoices ) - 1 ):
                                bLastElementSaid = True
                            # say the choice in the tactile sensor menu
                            thread.start_new_thread( self.sayCurrentChoice, () )
                        for i in range(8):
                            if( self.nFront == 0 ):
                                self.bPressed = False
                                break
                            time.sleep(0.1)
                    for idTTS in self.aIdsTTS:
                        if( self.tts.isRunning( idTTS ) ):
                            try:
                                self.tts.wait( idTTS, 0 )
                            except:
                                self.logger.debug( "Warning: Could not wait the TTS." )
                    self.timeoutManagingInTactileMenu()
            elif( p == "LongRear" ):
                if( not self.bPressed ):
                    self.bPressed = True
                    bFirstElementSaid = False
                    while( self.bPressed ):
                        if( self.nRear == 0 ):
                            self.bPressed = False
                            break
                        bTTSRunning = False # to know if TTS is running
                        for idTTS in self.aIdsTTS:
                            if( self.tts.isRunning( idTTS )):
                                bTTSRunning = True
                        if( self.bIsSayingChoice or not bTTSRunning ):
                            # change choice
                            self.nIndexChoice -= 1
                            if( self.nIndexChoice <= 0 ):
                                self.nIndexChoice = 0
                                if( not bFirstElementSaid ):
                                    bFirstElementSaid = True
                                    # say the choice in the tactile sensor menu
                                    thread.start_new_thread( self.sayCurrentChoice, () )
                            else:
                                # say the choice in the tactile sensor menu
                                thread.start_new_thread( self.sayCurrentChoice, () )
                        else:
                            if( self.nIndexChoice == 0 ):
                                bFirstElementSaid = True
                            # say the choice in the tactile sensor menu
                            thread.start_new_thread( self.sayCurrentChoice, () )
                        for i in range(8):
                            if( self.nRear == 0 ):
                                self.bPressed = False
                                break
                            time.sleep(0.1)
                    for idTTS in self.aIdsTTS:
                        if( self.tts.isRunning( idTTS ) ):
                            try:
                                self.tts.wait( idTTS, 0 )
                            except:
                                self.logger.debug( "Warning: Could not wait the TTS." )
                    self.timeoutManagingInTactileMenu()
            elif( p in ["Tap", "CalmDown"] ):
                # then stop everything and cancel the question
                self.goOut( self.asExitWords[0], "onTactileSensor" )

    def sayCurrentChoice(self):
        "In the tactile sensor menu, make the robot say the current selected choice"
        self.bIsSayingChoice = True
        rTimeCurrent = time.time()
        self.rTimeLastChoiceSaid = rTimeCurrent
        # stop previous TTS
        self.skipTTS()
        # launch TTS
        idTTS = -1
        if( self.aChoices[ self.nIndexChoice ][0] != "" ):
            if( self.nFrameNumber != self.aFrameNumbers["headDown"] ):
                self.nFrameNumber = self.aFrameNumbers["headDown"]
                try:
                    self.getTimeline().goTo(self.nFrameNumber)
                except: # if NAOqi < 1.14
                    try:
                        self.gotoAndStop(self.nFrameNumber)
                    except:
                        pass
            sentence = self.aChoices[ self.nIndexChoice ][0] + "?"
            idTTS = self.tts.post.say( sentence )
            self.aIdsTTS.append( idTTS )
            self.logger.debug( "Robot says: " + str(sentence) )
            # launch flash leds
            thread.start_new_thread( self.ledsChangeOnTactile, () )
        if( idTTS != -1 ):
            try:
                self.tts.wait( idTTS, 0 )
            except:
                self.logger.debug( "Warning: Could not wait the TTS." )
        if( self.rTimeLastChoiceSaid == rTimeCurrent ):
            self.rTimeLastChoiceSaid = -1.
            self.bIsSayingChoice = False

    def timeoutManagingInTactileMenu(self):
        # check if there has been an other action with tts made while this one was processed
        bTTSRunning = False # to know if TTS is running
        for idTTS in self.aIdsTTS:
            if( self.tts.isRunning( idTTS )):
                bTTSRunning = True
        if( not bTTSRunning ):
            # start counting timeout
            self.rTimeWhenActionMadeInTactileMenu = time.time()
            thread.start_new_thread( self.loopCheckTimeoutInTactileMenu, (self.rTimeWhenActionMadeInTactileMenu,) )

    def loopCheckTimeoutInTactileMenu(self, rTimeForThisAction):
        nTimeout = time.time() + self.nTimeoutTactile
        if( self.rTimeWhenActionMadeInTactileMenu == rTimeForThisAction ):
            while( time.time() < nTimeout and self.rTimeWhenActionMadeInTactileMenu == rTimeForThisAction and self.bIsRunning ):
                time.sleep( 0.1 )
            if( self.rTimeWhenActionMadeInTactileMenu != rTimeForThisAction ):
                self.nCountNoReply = 0
            elif( self.bIsRunning ):
                self.rTimeWhenActionMadeInTactileMenu = -1.
                self.nCountNoReply += 1
                if( self.nCountNoReply >= self.nMaxCountNoReply ):
                    self.goOut( self.asExitWords[0], "timeout" )
                else:
                    bTTSRunning = False # to know if TTS is running
                    for idTTS in self.aIdsTTS:
                        if( self.tts.isRunning( idTTS )):
                            bTTSRunning = True
                    if( not bTTSRunning ):
                        # say the choice in the tactile sensor menu
                        self.sayCurrentChoice()
                        # start counting timeout
                        self.rTimeWhenActionMadeInTactileMenu = time.time()
                        thread.start_new_thread( self.loopCheckTimeoutInTactileMenu, (self.rTimeWhenActionMadeInTactileMenu,) )

# TACTILE SENSOR HANDLER -------------------------------------------------------------------------------

    def initSeqDetected(self):
        "Initialize the sequence handler."
        self.bSeqStarted = False
        self.aDetectedSeqs = []
        self.aDetectedSeqs.extend(self.aSeqs)
        for seq in self.aDetectedSeqs:
            seq["index"] = 0
            seq["previousStepTime"] = 0

    def convertToArrayOfPossibleStates(self, states):
        "Check if the states described in the sequences using a string are in the right syntax, and then convert them to an array of the possible states."
        aStates = []
        aStates3 = [[1, 1, 1]]
        aStates2 = [[0, 1, 1], [1, 0, 1], [1, 1, 0]]
        aStates1 = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]
        aStates0 = [[0, 0, 0]]
        try:
            if( int(states) == states ): # if states is an integer
                states = str(states)
        except:
            pass
        if( self.isString(states) ):
            if( not states in ["*", "0+", "0", "0-", "1+", "1", "1-", "2+", "2", "2-", "3+", "3", "3-", "F+", "F", "F-", "M+", "M", "M-", "R+", "R", "R-"] ):
                raise Exception( "Error in sequences states description syntax: description expected in " + str(["*", "0+", "0", "0-", "1+", "1", "1-", "2+", "2", "2-", "3+", "3", "3-", "F+", "F", "F-", "M+", "M", "M-", "R+", "R", "R-"]) + " but " + str(p) + " found with this type: " + str(type(p)) )
            if( states in ["*", "0+", "1+", "2+", "3+", "3", "3-", "F+", "M+", "R+"] ):
                aStates.extend(aStates3)
            if( states in ["*", "0+", "1+", "2+", "2", "2-", "3-"] ):
                aStates.extend(aStates2)
            if( states in ["*", "0+", "1+", "1", "1-", "2-", "3-"] ):
                aStates.extend(aStates1)
            if( states in ["*", "0+", "0", "0-", "1-", "2-", "3-", "F-", "M-", "R-"] ):
                aStates.extend(aStates0)
            if( states in ["F", "F+", "F-"] ):
                aStates.append([1, 0, 0])
            if( states in ["M", "M+", "M-"] ):
                aStates.append([0, 1, 0])
            if( states in ["R", "R+", "R-"] ):
                aStates.append([0, 0, 1])
            if( states in ["F+", "M+"] ):
                aStates.append([1, 1, 0])
            if( states in ["R+", "M+"] ):
                aStates.append([0, 1, 1])
            if( states in ["F+", "R+"] ):
                aStates.append([1, 0, 1])
        elif( self.isArray(states) ):
            if( self.isArray(states[0]) ):
                aStates = states
            elif( int(states[0]) == states[0] ):
                aStates = [states]
            else:
                raise Exception( "Error in sequences states description syntax: description expected in " + str(["*", "0+", "0", "0-", "1+", "1", "1-", "2+", "2", "2-", "3+", "3", "3-", "F+", "F", "F-", "M+", "M", "M-", "R+", "R", "R-"]) + " but " + str(p) + " found with this type: " + str(type(p)) )
        else:
            raise Exception( "Error in sequences states description syntax:\nstring, array or int expected but " + str(type(p)) + " found" )
        return aStates

    def checkIfSeqsCorrespondingLeft(self, param):
        "If the sequence handler is done (there is no sequence detected left or the first in the list corresponds), then reinitialize the sequence handler, and give the corresponding sequence if there is one."
        if( self.aDetectedSeqs == [] ):
            # then no sequence corresponding in the list
            self.initSeqDetected()
        else:
            if( self.aDetectedSeqs[0]["index"] == -1 ): # if first sequence in left ones corresponds
                # then it is this sequence which is played
                thread.start_new_thread( self.onAlternativeModalityAction, (self.aDetectedSeqs[0]["name"],) )
                self.initSeqDetected()
        self.mutexCheckIfSeqsCorrespondingLeft.unlock()

    def loopCheckTimeoutMax(self, nTimeoutMax, seq, currentState, currentTime):
        "When timeout ellapsed, check the sequence status and process it."
        nPreviousIndex = seq["index"]
        time.sleep(nTimeoutMax + 0.1)
        aSeqsTemp = []
        aSeqsTemp.extend( self.aDetectedSeqs )
        currentState = [self.nFront, self.nMiddle, self.nRear]
        currentTime = time.time()
        if( nPreviousIndex == seq["index"] and not self.mutexProcessCurrentState.test() and not (1 in currentState) ): # if no change in the sequence step but timeout ellapsed and sequence handler is not processing (so if there is no action from the user and the sequence is still at the same point)
            if( seq in aSeqsTemp and seq["index"] != -1 ): # but if sequence is still in the possible ones and not completed
                if( currentState in seq["statesAndTimeout"][seq["index"]] ): # last check if the current state corresponds to the next one
                    # then we go to the next step
                    seq["previousStepTime"] = currentTime
                    seq["index"] += 2
                    if( seq["index"] > len( seq["statesAndTimeout"] ) ): # if there is no more step
                        seq["index"] = -1 # then the sequence is completed
                    else: # if there is at least one step left
                        nTimeoutMin = 0
                        nTimeoutMax = 5
                        if( self.isArray(seq["statesAndTimeout"][seq["index"]-1]) ):
                            if( seq["statesAndTimeout"][seq["index"]-1][0] < 0 ):
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][0]
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][1]
                            else:
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][0]
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][1]
                        else:
                            if( seq["statesAndTimeout"][seq["index"]-1] < 0 ):
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1]
                            else:
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1]
                        thread.start_new_thread( self.loopCheckTimeoutMax, (nTimeoutMax, seq, currentState, currentTime) )
                else:
                    # then remove the sequence from the possible ones
                    aSeqsTemp.remove(seq)
                    self.aDetectedSeqs = aSeqsTemp
                self.mutexCheckIfSeqsCorrespondingLeft.lock( self.checkIfSeqsCorrespondingLeft, None )

    def loopCheckTimeoutMin(self, nTimeoutMin, seq):
        "Wait that the minimum timeout ellapse to check if the new tactile sensor state corresponds to the expected one for this sequence."
        if( nTimeoutMin != 0 ):
            nPreviousIndex = seq["index"]
            time.sleep(nTimeoutMin - time.time() + seq["previousStepTime"])
            currentTime = time.time()
            currentState = [self.nFront, self.nMiddle, self.nRear]
            self.mutexProcessCurrentState.lock( self.processCurrentState, [0, currentState, currentTime] )

    def updateDetectedSeqs(self, seq, aSeqsTemp, currentState, currentTime):
        "Update a detected sequence."
        if( seq["index"] > 0 ): # if not the first step
            nTimeoutMin = 0
            nTimeoutMax = 5
            if( self.isArray(seq["statesAndTimeout"][seq["index"]-1]) ):
                if( seq["statesAndTimeout"][seq["index"]-1][0] < 0 ):
                    nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][0]
                    nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][1]
                else:
                    nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][0]
                    nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][1]
            else:
                if( seq["statesAndTimeout"][seq["index"]-1] < 0 ):
                    nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1]
                else:
                    nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1]
            if( currentTime > nTimeoutMax + seq["previousStepTime"] ): # if timeout of this step ellapsed
                aSeqsTemp.remove(seq) # then it is not this sequence which is played
            elif( not (currentState in seq["statesAndTimeout"][seq["index"]]) ): # if the current state does not correspond to one of the described ones but the timeout of this step did not ellaspe
                # then we check that this state could be an intermediate one
                aIntermediateStates = [[], [], []]
                for i in range( len( currentState ) ):
                    for j in range( len( seq["statesAndTimeout"][seq["index"]] ) ):
                        aIntermediateStates[i].append( seq["statesAndTimeout"][seq["index"]][j][i] )
                    for j in range( len( seq["statesAndTimeout"][seq["index"]-2] ) ):
                        aIntermediateStates[i].append( seq["statesAndTimeout"][seq["index"]-2][j][i] )
                bIsIntermediate = True
                for i in range( len( currentState ) ):
                    bIsIntermediate = bIsIntermediate and ( currentState[i] in aIntermediateStates[i] )
                if( not bIsIntermediate ):
                    aSeqsTemp.remove(seq) # then it is not this sequence which is played
            else: # if the current state correspond to one of the described ones
                if( currentTime > nTimeoutMin + seq["previousStepTime"] ): # if the minimum time to wait the next step is ellapsed
                    # then we go to the next step
                    seq["previousStepTime"] = currentTime
                    seq["index"] += 2
                    if( seq["index"] > len( seq["statesAndTimeout"] ) ): # if there is no more step
                        seq["index"] = -1 # then the sequence is completed
                    else: # if there is at least one step left
                        # start clock to timeout
                        nTimeoutMin = 0
                        nTimeoutMax = 5
                        if( self.isArray(seq["statesAndTimeout"][seq["index"]-1]) ):
                            if( seq["statesAndTimeout"][seq["index"]-1][0] < 0 ):
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][0]
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][1]
                            else:
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][0]
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][1]
                        else:
                            if( seq["statesAndTimeout"][seq["index"]-1] < 0 ):
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1]
                            else:
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1]
                        thread.start_new_thread( self.loopCheckTimeoutMin, (nTimeoutMin, seq) )
                        thread.start_new_thread( self.loopCheckTimeoutMax, (nTimeoutMax, seq, currentState, currentTime) )
                else: # if the minimum time to wait the next step is not ellapsed
                    # then we are going to wait until it is to check then
                    thread.start_new_thread( self.loopCheckTimeoutMin, (nTimeoutMin, seq) )
        elif( seq["index"] == 0 ): # for the first step
            if( currentState in seq["statesAndTimeout"][seq["index"]] ): # if the current state correspond to one of the described ones
                # then we go to the next step
                seq["previousStepTime"] = currentTime
                seq["index"] += 2
                if( seq["index"] > len( seq["statesAndTimeout"] ) ): # if there is no more step
                    seq["index"] = -1 # then the sequence is completed
                else: # if there is at least one step left
                    # start clock to timeout
                    nTimeoutMin = 0
                    nTimeoutMax = 5
                    if( self.isArray(seq["statesAndTimeout"][seq["index"]-1]) ):
                        if( seq["statesAndTimeout"][seq["index"]-1][0] < 0 ):
                            nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][0]
                            nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][1]
                        else:
                            nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][0]
                            nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][1]
                    else:
                        if( seq["statesAndTimeout"][seq["index"]-1] < 0 ):
                            nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1]
                        else:
                            nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1]
                    thread.start_new_thread( self.loopCheckTimeoutMin, (nTimeoutMin, seq) )
                    thread.start_new_thread( self.loopCheckTimeoutMax, (nTimeoutMax, seq, currentState, currentTime) )
            else: # if the current state does not correspond to the first described
                aSeqsTemp.remove(seq) # then it is not this sequence which has just been started

    def updateSeqsHandler(self, currentState, currentTime):
        "Update list of detected sequences."
        aSeqsTemp = []
        aSeqsTemp.extend( self.aDetectedSeqs )
        for seq in self.aDetectedSeqs:
            self.updateDetectedSeqs( seq, aSeqsTemp, currentState, currentTime )
        self.aDetectedSeqs = aSeqsTemp
        self.mutexCheckIfSeqsCorrespondingLeft.lock( self.checkIfSeqsCorrespondingLeft, None )

    def processCurrentState(self, param):
        "Process the current tactile sensor state."
        pValue = param[0]
        currentState = param[1]
        currentTime = param[2]
        if( pValue == 1 and not self.bSeqStarted ):
            self.bSeqStarted = True
            for seq in self.aDetectedSeqs:
                seq["previousStepTime"] = currentTime
        # update sequences handler
        if( self.bSeqStarted ):
            self.updateSeqsHandler(currentState, currentTime)
        self.mutexProcessCurrentState.unlock()

    def onFrontTactilTouched(self, param):
        "Handle an action (touch or release) on the front tactile sensor."
        self.logger.debug( "Change detected on the front tactile sensor: " + str(param[0]) )
        pValue = param[0]
        currentTime = param[1]
        currentState = [pValue, self.nMiddle, self.nRear]
        self.nFront = pValue
        self.mutexProcessCurrentState.lock( self.processCurrentState, [pValue, currentState, currentTime] )
        self.mutexTactilTouched.unlock()

    def onMiddleTactilTouched(self, param):
        "Handle an action (touch or release) on the middle tactile sensor."
        self.logger.debug( "Change detected on the middle tactile sensor: " + str(param[0]) )
        pValue = param[0]
        currentTime = param[1]
        currentState = [self.nFront, pValue, self.nRear]
        self.nMiddle = pValue
        self.mutexProcessCurrentState.lock( self.processCurrentState, [pValue, currentState, currentTime] )
        self.mutexTactilTouched.unlock()

    def onRearTactilTouched(self, param):
        "Handle an action (touch or release) on the rear tactile sensor."
        self.logger.debug( "Change detected on the rear tactile sensor: " + str(param[0]) )
        pValue = param[0]
        currentTime = param[1]
        currentState = [self.nFront, self.nMiddle, pValue]
        self.nRear = pValue
        self.mutexProcessCurrentState.lock( self.processCurrentState, [pValue, currentState, currentTime] )
        self.mutexTactilTouched.unlock()

    def onTactilTouched(self, pDataName, pValue, pMessage):
        "Handle an action (touch or release) on the tactile sensor."
        self.mutexTactilTouched.lock( getattr( self, "on" + pDataName ), [pValue, time.time()] )

# OUTPUTS ACTIVATION --------------------------------------------------------------------------------------

    def goOut(self, outputName, cancelReason = ""):
        "Activate the right output (a choice output or the other output)."
        try:
            self.memory.unsubscribeToEvent( "FrontTactilTouched", self.getName() )
            self.memory.unsubscribeToEvent( "MiddleTactilTouched", self.getName() )
            self.memory.unsubscribeToEvent( "RearTactilTouched", self.getName() )
        except:
            pass

        self.bGoOut = True
        self.bInTactileSensorMenu = False
        if( outputName in self.asExitWords ):
            try:
                self.other( cancelReason )
                self.logger.debug( "Output 'other' stimulated because cancel asked: " + str(cancelReason) + "." )
            except:
                try:
                    self.onStopped( cancelReason )
                    self.logger.debug( "Output 'onStopped' stimulated because cancel asked: " + str(cancelReason) + "." )
                except:
                    try:
                        self.onStopped()
                        self.logger.debug( "Output 'onStopped' stimulated because cancel asked." )
                    except:
                        choregraphe = ALProxy( "ALChoregraphe" )
                        choregraphe.onPythonError( self.getName(), "goOut", "Invalid output: the main output name needs to be 'other', and it needs to be dynamic (because it can be either a string, or an integer)." )
        else:
            nOutput = -1
            for i in range( len (self.aChoices) - len (self.aDefaultChoices) ):
                if( nOutput == -1 ):
                    if( outputName in self.aChoices[i+len( self.aDefaultChoices )] ):
                        nOutput = i
            if( nOutput != -1):
                if( self.bExternChoices ):
                    if( self.bRepeatValidatedChoice ):
                        self.skipTTS()
                        self.tts.say( outputName )
                        self.logger.debug( "Robot says: " + str(outputName) )
                    try:
                        self.other( self.aChoiceIndexes[nOutput] )
                        self.logger.debug( "Output 'other' stimulated with: " + str(self.aChoiceIndexes[nOutput]) + " (corresponding to the choice '" + str(self.aChoices[nOutput+len( self.aDefaultChoices )][0]) + "')." )
                    except:
                        try:
                            self.onStopped( self.aChoiceIndexes[nOutput] )
                            self.logger.debug( "Output 'onStopped' stimulated with: " + str(self.aChoiceIndexes[nOutput]) + " (corresponding to the choice '" + str(self.aChoices[nOutput+len( self.aDefaultChoices )][0]) + "')." )
                        except:
                            choregraphe = ALProxy( "ALChoregraphe" )
                            choregraphe.onPythonError( self.getName(), "goOut", "Invalid type of output: using the input 'choicesList', the main output needs to be dynamic (because it can be either a string, or an integer)." )
                else:
                    if( self.bRepeatValidatedChoice ):
                        self.skipTTS()
                        self.tts.say( outputName )
                        self.logger.debug( "Robot says: " + str(outputName) )
                    try:
                        func = getattr( self, "output_" + str(self.aChoiceIndexes[nOutput]+1) ) #+1 because the first one is output_1 corresponding to the element 0 in the list.
                        func(outputName)
                        self.logger.debug( "Output 'output_" + str(self.aChoiceIndexes[nOutput]+1) + "' stimulated with: " + str(outputName) + "." )
                    except:
                        choregraphe = ALProxy( "ALChoregraphe" )
                        choregraphe.onPythonError( self.getName(), "goOut", "Invalid output: the output 'output_" + str(self.aChoiceIndexes[nOutput]+1) + "' was expected to be stimulated with: " + str(outputName) + " but could not." )
        self.onUnload()
        # come back to an initial position and stop movement animation
        if( self.nFrameNumber != self.aFrameNumbers["end"] ):
            self.nFrameNumber = self.aFrameNumbers["end"]
            try:
                self.getTimeline().goTo(self.nFrameNumber)
            except: # if NAOqi < 1.14
                try:
                    self.gotoAndStop(self.nFrameNumber)
                except:
                    pass

# UNLOAD --------------------------------------------------------------------------------------------------

    def goOutOfQuestionRecoReaction(self):
        "Set some variables to go out of the question-recognition-reaction loop and reinitialize other variables which are going to be used again only on the next start of this box."
        self.bGoOut = True
        self.bMustStop = True
        self.nCountFailure = 0
        self.nCountNoReply = 0
        self.bInConfirmation = False
        self.bVocabularyLoaded = False
        self.skipTTS()
        for idTTS in self.aIdsTTS:
            try:
                self.aIdsTTS.remove( idTTS )
            except:
                self.logger.debug( "Warning: The task ID corresponding to the Text-To-Speech could not have been removed from the ID tasks list." )
        try:
            self.memory.unsubscribeToEvent( "WordRecognized", self.getName() )
            self.bRecoIsWaitingForVoice = False
            self.bRecoIsHearingOrAnalysing = False
            self.logger.debug( "Speech recognition stopped." )
            self.memory.unsubscribeToEvent( "SpeechDetected", self.getName() )
        except:
            pass

    def onUnload(self):
        "Reinitialize variables to default state."
        self.goOutOfQuestionRecoReaction()
        self.bExternChoices = False
        self.bInTactileSensorMenu = False
        try:
            self.memory.unsubscribeToEvent( "FrontTactilTouched", self.getName() )
            self.memory.unsubscribeToEvent( "MiddleTactilTouched", self.getName() )
            self.memory.unsubscribeToEvent( "RearTactilTouched", self.getName() )
        except:
            pass
        self.bIsRunning = False]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <keyword>نعم</keyword>
                                                        <keyword>لا</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </arabic>
                                                    <brazilian>
                                                        <keyword>sim</keyword>
                                                        <keyword>não</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </brazilian>
                                                    <chinese>
                                                        <keyword>是</keyword>
                                                        <keyword>不是</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </chinese>
                                                    <czech>
                                                        <keyword>ano</keyword>
                                                        <keyword>ne</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </czech>
                                                    <danish>
                                                        <keyword>ja</keyword>
                                                        <keyword>nej</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </danish>
                                                    <dutch>
                                                        <keyword>ja</keyword>
                                                        <keyword>nee</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </dutch>
                                                    <english>
                                                        <keyword></keyword>
                                                        <keyword>Yes</keyword>
                                                        <keyword>No</keyword>
                                                        <keyword></keyword>
                                                    </english>
                                                    <finnish>
                                                        <keyword>kyllä</keyword>
                                                        <keyword>ei</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </finnish>
                                                    <french>
                                                        <keyword>oui</keyword>
                                                        <keyword>non</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </french>
                                                    <german>
                                                        <keyword>ja</keyword>
                                                        <keyword>nein</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </german>
                                                    <greek>
                                                        <keyword>ναί</keyword>
                                                        <keyword>κανένα</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </greek>
                                                    <italian>
                                                        <keyword>sì</keyword>
                                                        <keyword>no</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </italian>
                                                    <japanese>
                                                        <keyword>はい</keyword>
                                                        <keyword>いいえ</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </japanese>
                                                    <korean>
                                                        <keyword>예</keyword>
                                                        <keyword>아니</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </korean>
                                                    <norwegian>
                                                        <keyword>ja</keyword>
                                                        <keyword>Nei</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </norwegian>
                                                    <polish>
                                                        <keyword>tak</keyword>
                                                        <keyword>nie</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </polish>
                                                    <portuguese>
                                                        <keyword>sim</keyword>
                                                        <keyword>não</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </portuguese>
                                                    <russian>
                                                        <keyword>да</keyword>
                                                        <keyword>нет</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </russian>
                                                    <spanish>
                                                        <keyword>si</keyword>
                                                        <keyword>no</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </spanish>
                                                    <swedish>
                                                        <keyword>ja</keyword>
                                                        <keyword>ingen</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </swedish>
                                                    <turkish>
                                                        <keyword>evet</keyword>
                                                        <keyword>hayır</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </turkish>
                                                    <language>english</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="0" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is&#x0A;received on this input. The signal can be&#x0A;either a string so that the robot asks a&#x0A;question before the recognition of a&#x0A;choice, or a bang so that the speech&#x0A;recognition starts immediately without any&#x0A;question." id="2" />
                                                <Input name="choicesList" type="0" type_size="1" nature="1" inner="0" tooltip="To have extern choices list (for example,&#x0A;depending on extern variables).&#x0A;!! Warning !! : Must be set before each&#x0A;time the box is started (with onStart&#x0A;input). Otherwise, the choices displayed&#x0A;on the box will be selected." id="3" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip='Box behavior stops when a signal is&#x0A;received on this input, the &apos;other&apos; output is&#x0A;stimulated by &quot;onStop&quot;.' id="4" />
                                                <Output name="other" type="0" type_size="1" nature="1" inner="0" tooltip='When the user skipped the question, this output gives how it has been&#x0A;skipped. Gives also the number of the choice chosen in case of external&#x0A;choices.&#x0A;This output can be:&#x0A;- &quot;timeout&quot; if the user has not replied.&#x0A;- &quot;notUnderstood&quot; if the interaction with the speech recognition failed.&#x0A;- &quot;onStop&quot; if the onStop input has been activated.&#x0A;- &quot;wordRecognised&quot; if the exit command has been understood.&#x0A;- &quot;onTactileSensor&quot; if the user has tapped the tactile sensor of the robot.&#x0A;- an integer being the number of the external choice in the input list.' id="5" />
                                                <Output name="output_1" type="0" type_size="1" nature="2" inner="0" tooltip="This IO has been automatically added by box. Read box tooltip for more information." id="6" />
                                                <Output name="output_2" type="0" type_size="1" nature="2" inner="0" tooltip="This IO has been automatically added by box. Read box tooltip for more information." id="7" />
                                                <Output name="output_3" type="0" type_size="1" nature="2" inner="0" tooltip="This IO has been automatically added by box. Read box tooltip for more information." id="8" />
                                                <Parameter name="Minimum threshold to understand" inherits_from_parent="0" content_type="2" value="0.2" default_value="0.2" min="0" max="1" tooltip="Minimum threshold to get in order to be understood by the robot." id="9" />
                                                <Parameter name="Minimum threshold to be sure" inherits_from_parent="0" content_type="2" value="0.3" default_value="0.3" min="0" max="1" tooltip="Minimum threshold to get so that the robot would be sure about the user&apos;s&#x0A;answer. Below this threshold, the robot asks a confirmation about what has been&#x0A;understood." id="10" />
                                                <Parameter name="Speech recognition timeout when confirmation" inherits_from_parent="0" content_type="1" value="6" default_value="6" min="1" max="20" tooltip="When the robot asks if what he understood is correct, after this time, if there has been&#x0A;nothing heard, the speech recognition is stopped and the answer understood is&#x0A;considered as correct." id="11" />
                                                <Parameter name="Speech recognition timeout" inherits_from_parent="0" content_type="1" value="6" default_value="6" min="1" max="20" tooltip="After this time, if there has been nothing heard, the speech recognition is stopped&#x0A;and the question is repeated or is skipped." id="12" />
                                                <Parameter name="Maximum number of repetition when no reply" inherits_from_parent="0" content_type="1" value="3" default_value="3" min="1" max="20" tooltip='After this number of times when the user did not reply, the question is skipped, and&#x0A;the output other is stimulated with &quot;timeout&quot;.' id="13" />
                                                <Parameter name="Repeat validated choice" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="If this option is activated, the robot repeats the validated choice when it exits the box." id="14" />
                                                <Parameter name="Activate ears light" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="Activate ears light animation (turn, flash, etc...)." id="15" />
                                                <Parameter name="Activate eyes light" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="Activate eyes light animation (turn, flash, etc...)." id="16" />
                                                <Parameter name="Activate brain light" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="Activate brain light animation (turn, flash, etc...)." id="17" />
                                                <Parameter name="Tactile sensor menu timeout" inherits_from_parent="0" content_type="1" value="10" default_value="10" min="1" max="20" tooltip="After this time, if there has been no action made on the tactile sensor or the torso&#x0A;button, the choice currently selected is repeated or the question is skipped." id="18" />
                                                <Parameter name="Maximum number of repetition when failure" inherits_from_parent="0" content_type="1" value="5" default_value="5" min="1" max="20" tooltip='After this number of times when the robot did not understand the user, the question&#x0A;is skipped, and the output other is stimulated with &quot;notUnderstood&quot;.' id="19" />
                                                <Parameter name="Activate help when failure" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="When this parameter is activated, when the robot did not understand the user, he&#x0A;says some help enumerating available choices and attracting attention on the&#x0A;other available modalities (head tactile sensor)." id="20" />
                                                <Parameter name="Activate help command" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip='Enable the help command. So you can say &quot;help&quot; during the speech recognition&#x0A;and the robot will tell you more information.&#x0A;You will still be able to ask help by clicking the torso button.' id="21" />
                                                <Parameter name="Activate repeat command" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip='Activate the repeat command. So you can say &quot;repeat&quot; during the speech&#x0A;recognition and the robot will repeat the question.' id="22" />
                                                <Parameter name="Activate exit command" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip='Enable the exit command. So you can say &quot;exit&quot; during the speech recognition&#x0A;and the box will be stopped and the &apos;other&apos; output will be stimulated with&#x0A;&quot;wordRecognised&quot;.&#x0A;You will still be able to exit the box with&#x0A;the tactile sensor.' id="23" />
                                                <Parameter name="Sentences file" inherits_from_parent="0" content_type="4" value="/Aldebaran/choice_sentences_light.xml" default_value="/Aldebaran/choice_sentences_light.xml" tooltip="File containing all necessary sentences in each supported language." id="24" />
                                            </Box>
                                            <Box name="Localized Text" id="5" localization="8" tooltip="Send on the output the text associated with the robot&apos;s current voice language.&#x0A;You can display and edit the text associated with any language by&#x0A;selecting the language in the combobox.&#x0A;&#x0A;!!Warning!! The text sent on the output is NOT the displayed one but the one&#x0A;associated with the robot&apos;s current voice language." plugin="localizationbox_plugin" x="59" y="54">
                                                <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		try: # disable autoBind
			GeneratedClass.__init__(self, False)
		except TypeError: # if NAOqi < 1.14
			GeneratedClass.__init__( self )

		self.tts = ALProxy("ALTextToSpeech")
		self.sentences = {
			"Arabic" : "  ",
			"Czech" : " Máš rád čokoládu? ",
			"Danish" : " Kan du lide chokolade? ",
			"German" : " Mögen Sie Schokolade? ",
			"Greek" : "  ",
			"English" : " Is your appointment at ten fifteen am ",
			"Spanish" : " ¿Te gusta el chocolate? ",
			"Finnish" : " Pidätkö suklaasta? ",
			"French" : " Aimes-tu le chocolat ? ",
			"Italian" : " Ti piace il cioccolato? ",
			"Japanese" : " チョコレートが好きですか ",
			"Korean" : " 당신은 초콜렛을 좋아합니까? ",
			"Dutch" : " Hou je van chocolade? ",
			"Norwegian" : "  ",
			"Polish" : " Lubisz czekoladę? ",
			"Brazilian" : " Você gosta de chocolate? ",
			"Portuguese" : " Gostas de chocolate? ",
			"Russian" : " Вы любите шоколад? ",
			"Swedish" : " Gillar du choklad? ",
			"Turkish" : " Çikolata sever misin? ",
			"Chinese" : "  "
		}

	def onInput_onStart(self):
		sDefaultLang = self.tts.getLanguage()
		self.onStopped(self.sentences[sDefaultLang])]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <![CDATA[]]>
</arabic>
                                                    <czech>
                                                        <![CDATA[Máš rád čokoládu?]]>
</czech>
                                                    <danish>
                                                        <![CDATA[Kan du lide chokolade?]]>
</danish>
                                                    <german>
                                                        <![CDATA[Mögen Sie Schokolade?]]>
</german>
                                                    <greek>
                                                        <![CDATA[]]>
</greek>
                                                    <english>
                                                        <![CDATA[Is your appointment at ten fifteen am]]>
</english>
                                                    <spanish>
                                                        <![CDATA[¿Te gusta el chocolate?]]>
</spanish>
                                                    <finnish>
                                                        <![CDATA[Pidätkö suklaasta?]]>
</finnish>
                                                    <french>
                                                        <![CDATA[Aimes-tu le chocolat ?]]>
</french>
                                                    <italian>
                                                        <![CDATA[Ti piace il cioccolato?]]>
</italian>
                                                    <japanese>
                                                        <![CDATA[チョコレートが好きですか]]>
</japanese>
                                                    <korean>
                                                        <![CDATA[당신은 초콜렛을 좋아합니까?]]>
</korean>
                                                    <dutch>
                                                        <![CDATA[Hou je van chocolade?]]>
</dutch>
                                                    <norwegian>
                                                        <![CDATA[]]>
</norwegian>
                                                    <polish>
                                                        <![CDATA[Lubisz czekoladę?]]>
</polish>
                                                    <brazilian>
                                                        <![CDATA[Você gosta de chocolate?]]>
</brazilian>
                                                    <portuguese>
                                                        <![CDATA[Gostas de chocolate?]]>
</portuguese>
                                                    <russian>
                                                        <![CDATA[Вы любите шоколад?]]>
</russian>
                                                    <swedish>
                                                        <![CDATA[Gillar du choklad?]]>
</swedish>
                                                    <turkish>
                                                        <![CDATA[Çikolata sever misin?]]>
</turkish>
                                                    <chinese>
                                                        <![CDATA[]]>
</chinese>
                                                    <language>5</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Data is sent on the output when this input is stimulated." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Data sent when asked." id="3" />
                                            </Box>
                                            <Link inputowner="1" indexofinput="2" outputowner="5" indexofoutput="3" />
                                            <Link inputowner="5" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="0" indexofinput="4" outputowner="1" indexofoutput="5" />
                                            <Link inputowner="0" indexofinput="5" outputowner="1" indexofoutput="6" />
                                            <Link inputowner="0" indexofinput="5" outputowner="1" indexofoutput="7" />
                                            <Link inputowner="0" indexofinput="6" outputowner="1" indexofoutput="8" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Speech" type="Lock" timeout="0" />
                            <Resource name="Speech recognition" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Follow Nao to appointment  (1)" id="7" localization="8" tooltip="Nao asks user to follow them to appointment " x="113" y="1204">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean." id="6" />
                            <Parameter name="Body language mode" inherits_from_parent="0" content_type="3" value="contextual" default_value="contextual" custom_choice="0" tooltip="Change the body language mode during the speech.&#x0A;disabled: The robot will only play the animations given by the user. ex: ^start(...) or ^tag(...)&#x0A;random: During time the robot has no animation to play, he will launch random neutral animations.&#x0A;contextual: During time the robot has no animation to play, he will try to launch a new one accordingly to the saying text. Every time the robot can&apos;t find a contextual animation he will launch a random neutral animation." id="7">
                                <Choice value="disabled" />
                                <Choice value="random" />
                                <Choice value="contextual" />
                            </Parameter>
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Animated Say Text" id="2" localization="8" tooltip="Say the text received on its input and move during its speech." x="422" y="93">
                                                <bitmap>media/images/box/interaction/say.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.animSpeech = ALProxy('ALAnimatedSpeech')

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.animSpeech.stop(id)
            except:
                pass

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            configuration =\
            {"bodyLanguageMode":self.getParameter("Body language mode")}
            id = self.animSpeech.post.say(str(sentence), configuration)
            self.ids.append(id)
            self.animSpeech.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                                                <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                                                <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                                                <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                                                <Parameter name="Body language mode" inherits_from_parent="1" content_type="3" value="contextual" default_value="contextual" custom_choice="0" tooltip="Change the body language mode during the speech.&#x0A;disabled: The robot will only play the animations given by the user. ex: ^start(...) or ^tag(...)&#x0A;random: During time the robot has no animation to play, he will launch random neutral animations.&#x0A;contextual: During time the robot has no animation to play, he will try to launch a new one accordingly to the saying text. Every time the robot can&apos;t find a contextual animation he will launch a random neutral animation." id="7">
                                                    <Choice value="disabled" />
                                                    <Choice value="random" />
                                                    <Choice value="contextual" />
                                                </Parameter>
                                            </Box>
                                            <Box name="Localized Text" id="5" localization="8" tooltip="Send on the output the text associated with the robot&apos;s current voice language.&#x0A;You can display and edit the text associated with any language by&#x0A;selecting the language in the combobox.&#x0A;&#x0A;!!Warning!! The text sent on the output is NOT the displayed one but the one&#x0A;associated with the robot&apos;s current voice language." plugin="localizationbox_plugin" x="114" y="68">
                                                <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		try: # disable autoBind
			GeneratedClass.__init__(self, False)
		except TypeError: # if NAOqi < 1.14
			GeneratedClass.__init__( self )

		self.tts = ALProxy("ALTextToSpeech")
		self.sentences = {
			"Arabic" : "  ",
			"Czech" : " ^start(animations/Stand/Gestures/Hey_1) Ahoj ^wait(animations/Stand/Gestures/Hey_1) ",
			"Danish" : " ^start(animations/Stand/Gestures/Hey_1) Hej ^wait(animations/Stand/Gestures/Hey_1) ",
			"German" : " ^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1) ",
			"Greek" : "  ",
			"English" : " Dilynwch fi i\'ch apwyntiad ",
			"Spanish" : " ^start(animations/Stand/Gestures/Hey_1) Hola ^wait(animations/Stand/Gestures/Hey_1) ",
			"Finnish" : " ^start(animations/Stand/Gestures/Hey_1) Hei ^wait(animations/Stand/Gestures/Hey_1) ",
			"French" : " ^start(animations/Stand/Gestures/Hey_1) Bonjour ^wait(animations/Stand/Gestures/Hey_1) ",
			"Italian" : " ^start(animations/Stand/Gestures/Hey_1) Ciao ^wait(animations/Stand/Gestures/Hey_1) ",
			"Japanese" : " ^start(animations/Stand/Gestures/Hey_1) こんにちは ^wait(animations/Stand/Gestures/Hey_1) ",
			"Korean" : " ^start(animations/Stand/Gestures/Hey_1) 안녕하세요 ^wait(animations/Stand/Gestures/Hey_1) ",
			"Dutch" : " ^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1) ",
			"Norwegian" : "  ",
			"Polish" : " ^start(animations/Stand/Gestures/Hey_1) Cześć ^wait(animations/Stand/Gestures/Hey_1) ",
			"Brazilian" : " ^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1) ",
			"Portuguese" : " ^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1) ",
			"Russian" : " ^start(animations/Stand/Gestures/Hey_1) Привет ^wait(animations/Stand/Gestures/Hey_1) ",
			"Swedish" : " ^start(animations/Stand/Gestures/Hey_1) Hallå ^wait(animations/Stand/Gestures/Hey_1) ",
			"Turkish" : " ^start(animations/Stand/Gestures/Hey_1) Merhaba ^wait(animations/Stand/Gestures/Hey_1) ",
			"Chinese" : "  "
		}

	def onInput_onStart(self):
		sDefaultLang = self.tts.getLanguage()
		self.onStopped(self.sentences[sDefaultLang])]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <![CDATA[]]>
</arabic>
                                                    <czech>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Ahoj ^wait(animations/Stand/Gestures/Hey_1)]]>
</czech>
                                                    <danish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hej ^wait(animations/Stand/Gestures/Hey_1)]]>
</danish>
                                                    <german>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1)]]>
</german>
                                                    <greek>
                                                        <![CDATA[]]>
</greek>
                                                    <english>
                                                        <![CDATA[Dilynwch fi i'ch apwyntiad]]>
</english>
                                                    <spanish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hola ^wait(animations/Stand/Gestures/Hey_1)]]>
</spanish>
                                                    <finnish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hei ^wait(animations/Stand/Gestures/Hey_1)]]>
</finnish>
                                                    <french>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Bonjour ^wait(animations/Stand/Gestures/Hey_1)]]>
</french>
                                                    <italian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Ciao ^wait(animations/Stand/Gestures/Hey_1)]]>
</italian>
                                                    <japanese>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) こんにちは ^wait(animations/Stand/Gestures/Hey_1)]]>
</japanese>
                                                    <korean>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) 안녕하세요 ^wait(animations/Stand/Gestures/Hey_1)]]>
</korean>
                                                    <dutch>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1)]]>
</dutch>
                                                    <norwegian>
                                                        <![CDATA[]]>
</norwegian>
                                                    <polish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Cześć ^wait(animations/Stand/Gestures/Hey_1)]]>
</polish>
                                                    <brazilian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1)]]>
</brazilian>
                                                    <portuguese>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1)]]>
</portuguese>
                                                    <russian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Привет ^wait(animations/Stand/Gestures/Hey_1)]]>
</russian>
                                                    <swedish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallå ^wait(animations/Stand/Gestures/Hey_1)]]>
</swedish>
                                                    <turkish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Merhaba ^wait(animations/Stand/Gestures/Hey_1)]]>
</turkish>
                                                    <chinese>
                                                        <![CDATA[]]>
</chinese>
                                                    <language>5</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Data is sent on the output when this input is stimulated." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Data sent when asked." id="3" />
                                            </Box>
                                            <Link inputowner="0" indexofinput="4" outputowner="2" indexofoutput="4" />
                                            <Link inputowner="5" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="2" indexofinput="2" outputowner="5" indexofoutput="3" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Ask user to wait in the waiting room (1)" id="14" localization="8" tooltip="Ask user to take a seat in the waiting room." x="350" y="1211">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean." id="6" />
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Say Text" id="2" localization="8" tooltip="Say the text received on its input." x="422" y="65">
                                                <bitmap>media/images/box/interaction/say.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.tts = ALProxy('ALTextToSpeech')
        self.ttsStop = ALProxy('ALTextToSpeech', True) #Create another proxy as wait is blocking if audioout is remote

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            id = self.tts.post.say(str(sentence))
            self.ids.append(id)
            self.tts.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                                                <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                                                <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                                                <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                                            </Box>
                                            <Box name="Localized Text" id="5" localization="8" tooltip="Send on the output the text associated with the robot&apos;s current voice language.&#x0A;You can display and edit the text associated with any language by&#x0A;selecting the language in the combobox.&#x0A;&#x0A;!!Warning!! The text sent on the output is NOT the displayed one but the one&#x0A;associated with the robot&apos;s current voice language." plugin="localizationbox_plugin" x="114" y="68">
                                                <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		try: # disable autoBind
			GeneratedClass.__init__(self, False)
		except TypeError: # if NAOqi < 1.14
			GeneratedClass.__init__( self )

		self.tts = ALProxy("ALTextToSpeech")
		self.sentences = {
			"Arabic" : "  ",
			"Czech" : " Ahoj ",
			"Danish" : " Hej ",
			"German" : " Hallo ",
			"Greek" : "  ",
			"English" : " Eisteddwch yn yr ystafell aros os gwelwch yn dda ",
			"Spanish" : " Hola ",
			"Finnish" : " Hei ",
			"French" : " Bonjour ",
			"Italian" : " Ciao ",
			"Japanese" : " こんにちは ",
			"Korean" : " 안녕하세요 ",
			"Dutch" : " Hallo ",
			"Norwegian" : "  ",
			"Polish" : " Cześć ",
			"Brazilian" : " Olá ",
			"Portuguese" : " Olá ",
			"Russian" : " Привет ",
			"Swedish" : " Hallå ",
			"Turkish" : " Merhaba ",
			"Chinese" : "  "
		}

	def onInput_onStart(self):
		sDefaultLang = self.tts.getLanguage()
		self.onStopped(self.sentences[sDefaultLang])]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <![CDATA[]]>
</arabic>
                                                    <czech>
                                                        <![CDATA[Ahoj]]>
</czech>
                                                    <danish>
                                                        <![CDATA[Hej]]>
</danish>
                                                    <german>
                                                        <![CDATA[Hallo]]>
</german>
                                                    <greek>
                                                        <![CDATA[]]>
</greek>
                                                    <english>
                                                        <![CDATA[Eisteddwch yn yr ystafell aros os gwelwch yn dda]]>
</english>
                                                    <spanish>
                                                        <![CDATA[Hola]]>
</spanish>
                                                    <finnish>
                                                        <![CDATA[Hei]]>
</finnish>
                                                    <french>
                                                        <![CDATA[Bonjour]]>
</french>
                                                    <italian>
                                                        <![CDATA[Ciao]]>
</italian>
                                                    <japanese>
                                                        <![CDATA[こんにちは]]>
</japanese>
                                                    <korean>
                                                        <![CDATA[안녕하세요]]>
</korean>
                                                    <dutch>
                                                        <![CDATA[Hallo]]>
</dutch>
                                                    <norwegian>
                                                        <![CDATA[]]>
</norwegian>
                                                    <polish>
                                                        <![CDATA[Cześć]]>
</polish>
                                                    <brazilian>
                                                        <![CDATA[Olá]]>
</brazilian>
                                                    <portuguese>
                                                        <![CDATA[Olá]]>
</portuguese>
                                                    <russian>
                                                        <![CDATA[Привет]]>
</russian>
                                                    <swedish>
                                                        <![CDATA[Hallå]]>
</swedish>
                                                    <turkish>
                                                        <![CDATA[Merhaba]]>
</turkish>
                                                    <chinese>
                                                        <![CDATA[]]>
</chinese>
                                                    <language>5</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Data is sent on the output when this input is stimulated." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Data sent when asked." id="3" />
                                            </Box>
                                            <Link inputowner="0" indexofinput="4" outputowner="2" indexofoutput="4" />
                                            <Link inputowner="5" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="2" indexofinput="2" outputowner="5" indexofoutput="3" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Sit Down (1)" id="15" localization="8" tooltip="the robot tries to sit down from any position for a number of tries.&#x0A;&#x0A;Note: The number of tries can be set in parameters." x="474" y="1399">
                            <bitmap>media/images/box/movement/sit_ground.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Output name="success" type="1" type_size="1" nature="1" inner="0" tooltip="Stimulated when the robot succeed in sitting down." id="4" />
                            <Output name="failure" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when the robot failed to sit down after n tries.&#x0A;&#x0A;Note: The number of tries can be set in parameters." id="5" />
                            <Timeline enable="0">
                                <BehaviorLayer name="SitDownBehavior">
                                    <BehaviorKeyframe name="DetectRobotPose" index="1">
                                        <Diagram>
                                            <Box name="Goto Posture" id="7" localization="8" tooltip="The robot goes from its current postition to the asked posture." x="371" y="101">
                                                <bitmap>media/images/box/box-diagram.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.postureProxy = ALProxy("ALRobotPosture")
        pass

    def onUnload(self):
        self.postureProxy.stopMove()

    def onInput_onStart(self):
        result = self.postureProxy.goToPosture(self.getParameter("Name"), self.getParameter("Speed (%)")/100.)
        if(result):
            self.success()
        else:
            self.failure()
        pass

    def onInput_onStop(self):
        self.onUnload() #~ it is recommanded to call onUnload of this box in a onStop method, as the code written in onUnload is used to stop the box as well
        pass]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                                                <Output name="success" type="1" type_size="1" nature="1" inner="0" tooltip="Stimulated if the posture has been reached." id="4" />
                                                <Output name="failure" type="1" type_size="1" nature="1" inner="0" tooltip="Stimulated if the posture could not be reached." id="5" />
                                                <Parameter name="Name" inherits_from_parent="0" content_type="3" value="Sit" default_value="Sit" custom_choice="1" tooltip="Name of the posture to go to." id="6">
                                                    <Choice value="Crouch" />
                                                    <Choice value="LyingBack" />
                                                    <Choice value="LyingBelly" />
                                                    <Choice value="Sit" />
                                                    <Choice value="SitRelax" />
                                                    <Choice value="StandInit" />
                                                    <Choice value="Stand" />
                                                    <Choice value="StandZero" />
                                                </Parameter>
                                                <Parameter name="Speed (%)" inherits_from_parent="0" content_type="1" value="80" default_value="100" min="0" max="100" tooltip="Speed to go to the posture." id="7" />
                                                <Resource name="All motors" type="Lock" timeout="0" />
                                                <Resource name="Stiffness" type="Lock" timeout="0" />
                                            </Box>
                                            <Link inputowner="7" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="0" indexofinput="4" outputowner="7" indexofoutput="4" />
                                            <Link inputowner="0" indexofinput="5" outputowner="7" indexofoutput="5" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="All motors" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Choice (light) (3)" id="16" localization="8" tooltip="Launch speech recognition, and wait for one of a defined number of expected answers (written in the table of the box). the robot will prompt the speaker if he cannot understand and give suggestions as to available answers and other ways of selecting your choice. e.g. The tactile sensor on his head.&#x0A;&#x0A;Note that you must open this box to enter the question text and the available answers.&#x0A;&#x0A;This is a lighter version of Choice box from standard library which has no animation embedded.&#x0A;&#x0A;V1.1.0&#x0A;" x="377" y="939">
                            <bitmap>media/images/box/interaction/choice.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                            <Output name="answer" type="3" type_size="1" nature="1" inner="0" tooltip="Answer recognized." id="5" />
                            <Output name="output" type="3" type_size="1" nature="1" inner="0" tooltip="" id="6" />
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Choice" id="1" localization="8" tooltip="Launch the speech recognition waiting for a defined number of predicted answers (written in the table on the box). Available help&#x0A;from the robot which gives some possible answers and attracts attention on the other modalities to answer (head tactile sensor).&#x0A;&#x0A;You can edit a choice by left double-clicking on the line. You can add a choice by right clicking on a line and selecting &apos;Insert a&#x0A;row&apos;. You can delete a choice by right clicking on a line and selecting &apos;Remove a row&apos;. You can also write several alternative&#x0A;answers for the same choice by writing them on the line separated by the character &apos;/&apos;.&#x0A;Ex: apple pie / pie / apple&#x0A;Then if any of these answers (&apos;apple pie&apos;, &apos;pie&apos; or &apos;apple&apos;) are said, the corresponding output will be activated. Indeed, each output&#x0A;which name begins with &apos;output_&apos; correspond to the choice in the list placed just in front of the output.&#x0A;&#x0A;Moreover, you have advanced options appearing when you click on the blue cross. Then you can make the robot calculate the threshold&#x0A;average of choices with the 1/2/3 button. Actually, it will calculate recognition threshold of each alternative answer and put them from&#x0A;highest to smallest threshold. The threshold displayed in front of each choice then is the highest&apos;s." plugin="ui_choice_plugin" x="312" y="51">
                                                <bitmap>media/images/box/interaction/choice.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
# -*- coding: utf-8 -*-
# script of the Choice box v8.8
# @author Desktop Application team
# (c) 2011 Aldebaran Robotics

import os
import time
import random
import thread
import mutex
import xml.dom.minidom

class MyClass(GeneratedClass):
    def __init__(self):
        try: # disable autoBind
          GeneratedClass.__init__(self, False)
        except TypeError: # if NAOqi < 1.14
          GeneratedClass.__init__( self )

        # PROXIES INITIALIZATION
        self.tts = ALProxy("ALTextToSpeech")
        self.ttsStop = ALProxy("ALTextToSpeech", True) #Create another proxy as wait is blocking if audioout is remote
        self.memory = ALProxy("ALMemory")
        try:
            self.asr = ALProxy("ALSpeechRecognition")
            self.ad = ALProxy("ALAudioDevice")
            self.player = ALProxy("ALAudioPlayer")
            self.dcm = ALProxy( "DCM" )
        except:
            self.logger.warning("cannot find ALSpeechRecognition, choice box will run in simulation mode")
            self.asr = None
            self.ad = None
            self.player = None
            self.dcm = None

        self.leds = ALProxy( "ALLeds" )
        # VARIABLES INITIALIZATION
        self.aIdsTTS = []
        self.bSentencesInitialized = False
        self.bMustStop = False
        self.bIsRunning = False
        self.bGoOut = False
        self.nCountNoReply = 0
        self.nCountFailure = 0
        self.aFrameNumbers = {"end" : 1,
                              "headDown" : 10,
                              "bodyTalk" : 20,
                              "reco" : 30,
                              "headCheck" : 40,
                              "helpTactileSensor" : 50,
                              "notUnderstood" : 70}
        self.nFrameNumber = self.aFrameNumbers["end"]
        self.bInConfirmation = False
        self.bVocabularyLoaded = False
        self.bRecoIsHearingOrAnalysing = False
        self.bRecoIsWaitingForVoice = False
        self.bHasAlreadyHearingEyes = False
        self.bInTactileSensorMenu = False
        self.bExternChoices = False
        self.bBrainAnimPaused = False
        self.rTimeLastChoiceSaid = -1.
        self.bIsSayingChoice = False
        self.nIndexChoice = 0
        self.sRecoInterruption = "" # = "wordRecognised" or "timeout" or "onStop" or "onTactileSensor"
        self.sPreviousAnswer = ""
        self.rTimeWhenActionMadeInTactileMenu = -1.
        # variables used for the tactile sensor
        self.nFront = 0
        self.nMiddle = 0
        self.nRear = 0
        self.bSeqStarted = False
        self.bIsStoringParam = False
        self.bPressed = False
        self.mutexProcessCurrentState = mutex.mutex()
        self.mutexTactilTouched = mutex.mutex()
        self.mutexCheckIfSeqsCorrespondingLeft = mutex.mutex()
        self.bSeqStarted = False
        # assuming that every sequence is after [0, 0, 0]
        # and then start with one tactil sensor activated
        # timeout must be either a number (int or float) not equal to 0 or an array of two numbers not equal to 0, a negative one and a positive one
        # a negative timeout means a minimum time that has to ellapse before the next step
        # a positive timeout means a maximum time before the next step must show up
        self.aSeqs = [{"name" : "Tap", "statesAndTimeout" : [ "1+", 0.35, "2+", 0.45, "0" ]},
                      {"name" : "TapFront", "statesAndTimeout" : [ "F", 1, "0" ]},
                      {"name" : "LongFront", "statesAndTimeout" : [ "F", -1, "F" ]},
                      {"name" : "TapMiddle", "statesAndTimeout" : [ "M", 1, "0" ]},
                      {"name" : "LongMiddle", "statesAndTimeout" : [ "M", -1, "M" ]},
                      {"name" : "TapRear", "statesAndTimeout" : [ "R", 1, "0" ]},
                      {"name" : "LongRear", "statesAndTimeout" : [ "R", -1, "R" ]},
                      {"name" : "CalmDown", "statesAndTimeout" : [ "1+", 0.5, "2+", -1, "2+" ]}]
        # sequences initialization
        aSeqsTemp = []
        for seq in self.aSeqs:
            try: # ensure that the sequence has at least a name and states and timeout defined
                seq["name"]
                seq["statesAndTimeout"]
                aSeqsTemp.append(seq)
            except:
                pass
        self.aSeqs = aSeqsTemp
        for seq in self.aSeqs:
            states = range( len( seq["statesAndTimeout"][0:len(seq["statesAndTimeout"]):2] ) )
            i = 0
            for state in seq["statesAndTimeout"][0:len(seq["statesAndTimeout"]):2]:
                states[i] = self.convertToArrayOfPossibleStates(state)
                i += 1
            seq["statesAndTimeout"][0:len(seq["statesAndTimeout"]):2] = states
        self.aDetectedSeqs = []
        self.aDetectedSeqs.extend(self.aSeqs)
        # end - variables used for the tactile sensor
        self.aChoices = []
        self.aChoiceIndexes = []
        # parameters which can be changed from the parameters edition window
        self.sQuestion = ""
        self.nTimeoutReco = 6
        self.nTimeoutRecoConfirmation = 6
        self.nTimeoutTactile = 10
        self.nMaxCountNoReply = 3
        self.nMaxCountFailure = 5
        self.arUnderstoodThreshold = [0.0, 1.0] # range of self.rUnderstoodThreshold
        self.arConfirmationThreshold = [0.0, 1.0] # range of self.rConfirmationThreshold (must be higher than self.arUnderstoodThreshold)
        self.rUnderstoodThreshold = 0.2
        self.rConfirmationThreshold = 0.4
        self.bActivateEyesLight = True
        self.bActivateEarsLight = True
        self.bActivateBrainLight = True
        self.bActivateHelpWhenFailure = True
        self.bRepeatValidatedChoice = True
        self.bActivateDefaultChoiceHelp = True
        self.bActivateDefaultChoiceRepeat = True
        self.bActivateDefaultChoiceExit = True
        self.BIND_PYTHON(self.getName(), "onTactilTouched")
        self.BIND_PYTHON(self.getName(), "onWordRecognized")
        self.BIND_PYTHON(self.getName(), "onSpeechDetected")


# FUNCTIONS ===============================================================================================

    def onLoad(self):
        # initialize sentences for each language
        if( not self.bSentencesInitialized ):
            self.initializeSentences()
            self.bSentencesInitialized = True

# XML PARSER FOR SENTENCES INITIALIZATION
    def initializeSentences(self):
        "Initialize necessary sentences in each language."
        framemanager = ALProxy("ALFrameManager")
        filename = framemanager.getBehaviorPath(self.behaviorId) + self.tryGetParameter( "Sentences file", "/Aldebaran/choice_sentences.xml" )
        if not self.fileExists(filename):
            raise RuntimeError("File " + filename + " could not be found. Please update your Choice box with a newer one from Choregraphe")
        try:
            doc = self.getFileContents( filename )
            dom = xml.dom.minidom.parseString( doc )
        except Exception as e:
            raise Exception( "The " + filename + " file is not in the right format. Check the special characters and that the syntax is correct.\n" + str(e) )
        try:
            tag = "sentences"
            mainBlock = dom.getElementsByTagName( tag )[0]
            tag = "translation"
            aTranslations = mainBlock.getElementsByTagName( tag )
            self.aAllWords = {}
            self.aAllSentences = {}
            for sTranslation in aTranslations:
                sLanguage = sTranslation.getAttribute("language")
                tag = "speechReco"
                blockSpeechReco = sTranslation.getElementsByTagName( tag )[0]
                # variable used for the speech recognition
                self.aAllWords[sLanguage] = {}
                aKinds = ["negative",
                          "positive",
                          "help",
                          "exit",
                          "repeat"]
                for sKind in aKinds:
                    tag = sKind
                    blockWordsForThisKind = blockSpeechReco.getElementsByTagName( sKind )[0]
                    self.aAllWords[sLanguage][sKind] = blockWordsForThisKind.getAttribute( "text" ).encode("utf-8").split("/")
                # end - variable used for the speech recognition
                tag = "tts"
                blockTTS = sTranslation.getElementsByTagName( tag )[0]
                # variable used for the Text-To-Speech
                self.aAllSentences[sLanguage] = {}
                aKinds = ["confirmation",
                          "enumMarks",
                          "helpEnumChoices",
                          "helpEnumDefault",
                          "helpTactile",
                          "notUnderstood",
                          "noQuestion",
                          "notUnderstoodAnims"]
                for sKind in aKinds:
                    tag = sKind
                    blockSentencesForThisKind = blockTTS.getElementsByTagName( sKind )[0]
                    self.aAllSentences[sLanguage][sKind] = blockSentencesForThisKind.getAttribute( "text" ).encode("utf-8").split("/")
                # end - variable used for the Text-To-Speech
        except Exception as e:
            raise Exception( "The " + filename + " file is not in the right format. Check that the '" + tag + "' tag is defined and with the right format.\n" + str(e) )

        # choices
        # !!! don't remove any comments from this variable !!!
        # (they are here to make the plugin work)
        self.aListAllChoices = {"Arabic": ["نعم", "لا", "", ""], "Brazilian": ["sim", "não", "", ""], "Chinese": ["是", "不是", "", ""], "Czech": ["ano", "ne", "", ""], "Danish": ["ja", "nej", "", ""], "Dutch": ["ja", "nee", "", ""], "English": ["", "Le", "Na", ""], "Finnish": ["kyllä", "ei", "", ""], "French": ["oui", "non", "", ""], "German": ["ja", "nein", "", ""], "Greek": ["ναί", "κανένα", "", ""], "Italian": ["sì", "no", "", ""], "Japanese": ["はい", "いいえ", "", ""], "Korean": ["예", "아니", "", ""], "Norwegian": ["ja", "Nei", "", ""], "Polish": ["tak", "nie", "", ""], "Portuguese": ["sim", "não", "", ""], "Russian": ["да", "нет", "", ""], "Spanish": ["si", "no", "", ""], "Swedish": ["ja", "ingen", "", ""], "Turkish": ["evet", "hayır", "", ""]
                               }
        # end - choices

# INPUTS ACTIVATION PROCESSING ------------------------------------------------------------------------------
    def onInput_onStart(self, question=None):
        "Initialize variables and start box behaviour."
        self.logger.debug( "Input onStart stimulated." )
        if( self.bIsRunning): # to avoid starting the process twice
            return
        self.bIsRunning = True
        if(self.asr != None):
            self.asr.setVisualExpression( False )
        language = self.tts.getLanguage()
        if(self.asr != None):
            self.asr.setLanguage( language )
        try:
            self.aAllWords[language]
            self.aAllSentences[language]
        except:
            raise Exception( "The current language is not supported by this Choice box. It is probably deprecated. Try to use the one supplied in Choregraphe library instead." )
        self.asNegativeWords = self.aAllWords[language]["negative"]
        self.asPositiveWords = self.aAllWords[language]["positive"]
        self.asHelpWords = self.aAllWords[language]["help"]
        self.asExitWords = self.aAllWords[language]["exit"]
        self.asRepeatWords = self.aAllWords[language]["repeat"]
        self.bGoOut = False
        self.bVocabularyLoaded = False
        self.bRecoIsHearingOrAnalysing = False
        self.bRecoIsWaitingForVoice = False
        self.bHasAlreadyHearingEyes = False
        self.sRecoInterruption = ""
        self.sPreviousAnswer = ""
        self.bMustStop = False
        self.nCountNoReply = 0
        self.nCountFailure = 0
        self.nFrameNumber = self.aFrameNumbers["end"]
        self.beginTime = time.time()
        self.bInConfirmation = False
        self.bInTactileSensorMenu = False
        self.bBrainAnimPaused = False
        self.bPressed = False
        self.rTimeWhenActionMadeInTactileMenu = -1.
        self.nFront = 0
        self.nMiddle = 0
        self.nRear = 0
        self.bSeqStarted = False
        self.bIsStoringParam = False
        self.rUnderstoodThreshold = self.tryGetParameter( "Minimum threshold to understand", 0.2 )
        self.rConfirmationThreshold = self.tryGetParameter( "Minimum threshold to be sure", 0.4 )
        self.nTimeoutReco = self.tryGetParameter( "Speech recognition timeout", 6 )
        self.nTimeoutRecoConfirmation = self.tryGetParameter( "Speech recognition timeout when confirmation", 6 )
        self.nTimeoutTactile = self.tryGetParameter( "Tactile sensor menu timeout", 10 )
        self.nMaxCountNoReply = self.tryGetParameter( "Maximum number of repetition when no reply", 3 )
        self.nMaxCountFailure = self.tryGetParameter( "Maximum number of repetition when failure", 5 )
        self.bActivateEyesLight = self.tryGetParameter( "Activate eyes light", True )
        self.bActivateEarsLight = self.tryGetParameter( "Activate ears light", True )
        self.bActivateBrainLight = self.tryGetParameter( "Activate brain light", True )
        self.bActivateHelpWhenFailure = self.tryGetParameter( "Activate help when failure", True )
        self.bRepeatValidatedChoice = self.tryGetParameter( "Repeat validated choice", True )
        self.bActivateDefaultChoiceHelp = self.tryGetParameter( "Activate help command", True )
        self.bActivateDefaultChoiceRepeat = self.tryGetParameter( "Activate repeat command", True )
        self.bActivateDefaultChoiceExit = self.tryGetParameter( "Activate exit command", True )
        self.aDefaultChoices = []
        if (self.bActivateDefaultChoiceHelp):
            self.aDefaultChoices.append( self.asHelpWords )
        if (self.bActivateDefaultChoiceRepeat):
            self.aDefaultChoices.append( self.asRepeatWords )
        if (self.bActivateDefaultChoiceExit):
            self.aDefaultChoices.append( self.asExitWords )
        if( question == None ):
            question = ""
        self.initQuestionAndChoices( question )
        if( len( self.aChoices ) > len( self.aDefaultChoices ) ): # if there is at least one choice (not a default one)
            self.nIndexChoice = len( self.aDefaultChoices )
        else: # if there are only default words
            self.nIndexChoice = 0
        self.bGoOut = False
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFFFFFF, 0.1 )
        # initialize tactile sensor handler
        self.initSeqDetected()
        # subscribe to tactile sensors extractors (launch tactile sensor handler)
        self.memory.subscribeToEvent( "FrontTactilTouched", self.getName(), "onTactilTouched" )
        self.memory.subscribeToEvent( "MiddleTactilTouched", self.getName(), "onTactilTouched" )
        self.memory.subscribeToEvent( "RearTactilTouched", self.getName(), "onTactilTouched" )
        thread.start_new_thread( self.loopLedsBrainTwinkle, () )
        while( not self.bGoOut ):
            self.questionRecognitionReaction()
        if( self.bInTactileSensorMenu ):
            self.nCountNoReply = 0
            if( self.nFrameNumber != self.aFrameNumbers["headDown"] ):
                self.nFrameNumber = self.aFrameNumbers["headDown"]
                try:
                    self.getTimeline().goTo(self.nFrameNumber)
                except: # if NAOqi < 1.14
                    try:
                        self.gotoAndStop(self.nFrameNumber)
                    except:
                        pass
            self.loopLedsBrainTurn()
        else:
            self.bIsRunning = False

    def onInput_choicesList(self, p):
        "Set choices list."
        self.logger.debug( "Input choicesList stimulated." )
        if( not self.bIsRunning ):
            self.bExternChoices = True
            language = "English"
            if(self.asr != None):
                language =  self.asr.getLanguage()
            self.asNegativeWords = self.aAllWords[language]["negative"]
            self.asPositiveWords = self.aAllWords[language]["positive"]
            self.asHelpWords = self.aAllWords[language]["help"]
            self.asExitWords = self.aAllWords[language]["exit"]
            self.asRepeatWords = self.aAllWords[language]["repeat"]
            self.bActivateDefaultChoiceHelp = self.tryGetParameter( "Activate help command", True )
            self.bActivateDefaultChoiceRepeat = self.tryGetParameter( "Activate repeat command", True )
            self.bActivateDefaultChoiceExit = self.tryGetParameter( "Activate exit command", True )
            self.aDefaultChoices = []
            if (self.bActivateDefaultChoiceHelp):
                self.aDefaultChoices.append( self.asHelpWords )
            if (self.bActivateDefaultChoiceRepeat):
                self.aDefaultChoices.append( self.asRepeatWords )
            if (self.bActivateDefaultChoiceExit):
                self.aDefaultChoices.append( self.asExitWords )
            self.aChoices = []
            self.aChoiceIndexes = []
            self.aChoices.extend( self.aDefaultChoices )
            index = 0
            for choice in p:
                if( self.isString(choice) ):
                    choice = choice.strip(" \t,;.\n") # remove space or tabs at beginning or end of a choice
                    if( choice != "" ):
                        choice = [ choice ]
                    else:
                        choice = []
                elif( self.isArray(choice) ):
                    if( choice != [] ):
                        for i in range( len( choice ) ):
                            if( self.isString(choice[i]) ):
                                choice[i] = choice[i].strip(" \t,;.\n") # remove space or tabs at beginning or end of a choice
                                if( len( choice[i] ) < 1 ):
                                    del choice[i]
                                    i -= 1 # to parse the good one next loop
                            else:
                                raise Exception( "Error in choices input syntax:\nIt must be an array of choices and each choice can be either a string or an array of strings (several possibilities for one choice)\nEx: ['choice1',['choice2a','choice2b']]\nbut: " + str(p) + " found" )
                else:
                    raise Exception( "Error in choices input syntax:\nIt must be an array of choices and each choice can be either a string or an array of strings (several possibilities for one choice)\nEx: ['choice1',['choice2a','choice2b']]\nbut: " + str(p) + " found" )
                if( len( choice ) > 0 ):
                    for sWord in choice:
                        for aDefaultChoice in self.aDefaultChoices:
                            if( sWord in aDefaultChoice ):
                                raise Exception( "Error in input choices list: You chose a word which is already used for default choices:\n" + str(sWord) + " is used for the default choice: " + str(aDefaultChoice[0]) )
                    self.aChoices.append( choice )
                    self.aChoiceIndexes.append( index )
                index += 1

    def onInput_onStop(self):
        "Stop box behaviour."
        self.logger.debug( "Input onStop stimulated." )
        if( self.bIsRunning ):
            self.goOut( self.asExitWords[0], "onStop" )
            self.sRecoInterruption = "onStop"
        else:
            self.onUnload()

# GENERAL FUNCTIONS ------------------------------------------------------------------------------------------

    def isString(self, strVariable):
        try:
            if( type( strVariable ) == type( "some string" ) ):
                return True
        except:
            pass
        return False

    def isArray(self, aVariable):
        try:
            if( type( aVariable ) == type( ["some array"] ) ):
                return True
        except:
            pass
        return False

    def fileExists(self, strPathFilename ):
        try:
            file = open( strPathFilename, 'r' )
            if( file ):
                file.close()
                return True
        except (IOError, os.error), err:
            pass
        return False

    def getFileContents(self, sFilename ):
        "read a file and return it's contents, or '' if not found, empty, ..."
        try:
            fileContent = open( sFilename )
            aBuf = fileContent.read()
            fileContent.close()
        except:
            try:
                fileContent.close()
            except:
                pass
            return ""
        return aBuf

    def getBrainLedName(self, nNumLed):
        "Get the name of the DCM led device from its number"
        "0 => front left; 1 => next in clock wise; until 11"
        numLed = nNumLed%12
        if( numLed <= 1 ):
            return "Head/Led/Front/Right/%d/Actuator/Value" % (1-numLed)
        elif( numLed >= 10 ):
            return "Head/Led/Front/Left/%d/Actuator/Value" % (numLed-10)
        elif( numLed <= 2 ):
            return "Head/Led/Middle/Right/%d/Actuator/Value" % (2-numLed)
        elif( numLed >= 9 ):
            return "Head/Led/Middle/Left/%d/Actuator/Value" % (numLed-9)
        elif( numLed <= 5 ):
            return "Head/Led/Rear/Right/%d/Actuator/Value" % (numLed-3)
        else:
            return "Head/Led/Rear/Left/%d/Actuator/Value" % (8-numLed)

    def skipTTS(self):
        for idtts in self.aIdsTTS:
            try:
                self.ttsStop.stop(idtts)
            except:
                self.logger.debug( "Warning: The Text-To-Speech could not have been stopped." )

    def tryGetParameter(self, sParameterName, defaultValue):
        try:
            return self.getParameter( sParameterName )
        except:
            return defaultValue

# QUESTION AND CHOICES INITIALIZATION ----------------------------------------------------------------------

    def initQuestionAndChoices(self, p):
        "Initialize the question and the choices."
        # question processing
        if( self.isString(p) ):
            self.sQuestion = p
        else:
            raise Exception( "Error in question input syntax:\nQuestion text\nexpected for example, but:\n" + str(p[0]) + "\nfound" )
        # choices processing
        if( not self.bExternChoices ):
            self.aChoices = []
            self.aChoiceIndexes = []
            self.aChoices.extend( self.aDefaultChoices )
            index = 0
            listChoices = self.aListAllChoices[self.tts.getLanguage()]
            for choice in listChoices:
                aChoice = choice.split( "/" )
                if( aChoice != [] ):
                    for i in range( len( aChoice ) ):
                        aChoice[i] = aChoice[i].strip(" \t,;.\n") # remove space or tabs at beginning or end of a choice
                        if( len( aChoice[i] ) < 1 ):
                            del aChoice[i]
                            i -= 1 # to parse the good one next loop
                if( len( aChoice ) > 0 ):
                    # check if there is a word which is already used for the default choices
                    for sWord in aChoice:
                        for aDefaultChoice in self.aDefaultChoices:
                            if( sWord in aDefaultChoice ):
                                raise Exception( "Error in choices list: You chose a word which is already used for default choices:\n" + str(sWord) + " is used for the default choice: " + str(aDefaultChoice[0]) )
                    # append the choice to the list if everything worked well
                    self.aChoices.append( aChoice )
                    self.aChoiceIndexes.append( index )
                index += 1
        # check that there is at least one choice (a default one or not)
        if( len( self.aChoices ) < 1 ):
            raise Exception( "Error in choices list: It is empty. There is no default choice nor choice entered." )

# QUESTION-RECOGNITION-REACTION -----------------------------------------------------------------------------

    def questionRecognitionReaction(self):
        "Ask question, launch speech recognition and process answer."
        self.ttsQuestionAndRecoInit()
        if( not self.bMustStop ):
            # stop movement animation
            if( self.nFrameNumber != self.aFrameNumbers["reco"] ):
                self.nFrameNumber = self.aFrameNumbers["reco"]
                try:
                    self.getTimeline().goTo(self.nFrameNumber)
                except: # if NAOqi < 1.14
                    try:
                        self.gotoAndStop(self.nFrameNumber)
                    except:
                        pass
            # start speech recognition
            self.logger.debug( "Speech recognition started." )
            self.memory.subscribeToEvent( "WordRecognized", self.getName(), "onWordRecognized" )
            self.bRecoIsWaitingForVoice = True
            self.memory.subscribeToEvent( "SpeechDetected", self.getName(), "onSpeechDetected" )
        # leds during the recognition
        self.loopLedsReco()
        # process the reco loop break
        self.processRecoInterruption()

    def ttsQuestionAndRecoInit(self):
        "Ask question and initialize the speech recognition during the question to gain time in the interaction."
        if( not self.bInConfirmation ):
            # launch TTS
            idTTS = -1
            if( self.sQuestion != ""):
                idTTS = self.tts.post.say( self.sQuestion )
                self.aIdsTTS.append( idTTS )
                self.logger.debug( "Robot says: " + str(self.sQuestion) )
                # launch TTS movement animation
                if( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ):
                    self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
            # prepare speech recognition
            if(self.asr != None):
                self.asr.setLanguage( self.tts.getLanguage() )
            if( not self.bVocabularyLoaded ):
                aWordsRecognised = []
                for i in range( len( self.aChoices ) ):
                    if( self.aChoices[i] != [] ):
                        aWordsRecognised.extend( self.aChoices[i] )
                sWordsRecognised = "You can say: "
                if( len( aWordsRecognised ) > 1 ):
                    for i in range( len( aWordsRecognised ) - 1 ):
                        sWordsRecognised += "'" + aWordsRecognised[i] + "', "
                if( len( aWordsRecognised ) > 0 ):
                    sWordsRecognised += "'" + aWordsRecognised[len( aWordsRecognised ) - 1] + "'"
                sWordsRecognised += "."
                self.logger.debug( sWordsRecognised )
                if(self.asr != None):
                    self.asr.setVocabulary( aWordsRecognised, False )
                self.bVocabularyLoaded = True
        else:
            # launch TTS
            sentence = self.aAllSentences[self.tts.getLanguage()]["confirmation"][0]
            idTTS = -1
            sentenceToSay = sentence % self.sPreviousAnswer
            if( sentenceToSay != ""):
                idTTS = self.tts.post.say( sentenceToSay )
                self.aIdsTTS.append( idTTS )
                self.logger.debug( "Robot says: " + str(sentenceToSay) )
                # launch TTS movement animation
                if( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ):
                    self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
            # prepare speech recognition
            aWordsRecognised = []
            aWordsRecognised.extend( self.asNegativeWords )
            aWordsRecognised.extend( self.asPositiveWords )
            sWordsRecognised = "You can say: "
            if( len( aWordsRecognised ) > 1 ):
                for i in range( len( aWordsRecognised ) - 1 ):
                    sWordsRecognised += "'" + aWordsRecognised[i] + "', "
            if( len( aWordsRecognised ) > 0 ):
                sWordsRecognised += "'" + aWordsRecognised[len( aWordsRecognised ) - 1] + "'"
            sWordsRecognised += "."
            self.logger.debug( sWordsRecognised )
            if(self.asr != None):
                self.asr.setVocabulary( aWordsRecognised, False )
            self.bVocabularyLoaded = False
        # wait for the end of the TTS
        if( idTTS != -1 ):
            try:
                self.tts.wait( idTTS, 0 )
            except:
                self.logger.debug( "Warning: Could not wait the TTS." )

    def processRecoInterruption(self):
        "Process speech recognition interruption (timeout, action on tactile sensor, word said, etc...)"
        # wait for the end of the reaction (help, not understood, etc...)
        while( self.sRecoInterruption == "" ):
            time.sleep( 0.2 )
        self.logger.debug( "The speech recognition has been interrupted because of: " + str(self.sRecoInterruption) + "." )
        if( self.sRecoInterruption == "timeout" ): # if recognition interrupted by timeout
            try:
                # stop recognition
                self.memory.unsubscribeToEvent( "WordRecognized", self.getName() )
                self.bRecoIsWaitingForVoice = False
                self.bRecoIsHearingOrAnalysing = False
                self.logger.debug( "Speech recognition stopped." )
                self.memory.unsubscribeToEvent( "SpeechDetected", self.getName() )
            except:
                pass
            if( self.bInConfirmation ): # if it was a confirmation question
                # leds noticing that the robot confirm its guessing
                thread.start_new_thread( self.ledsUnderstood, (True, False) )
                # if nothing has been said, we assume that the user agree
                self.bInConfirmation = False
                if( self.sPreviousAnswer in self.asHelpWords ): # if help asked
                    self.helpWhenAsked()
                elif( self.sPreviousAnswer in self.asRepeatWords ): # if repeat asked
                    self.repeatWhenNoQuestion()
                    # repeat the question
                else: # if not repeat nor help asked
                    self.goOut( self.sPreviousAnswer, "wordRecognised" )
            else:
                # reinitialize leds
                self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
                self.nCountNoReply += 1
                if( self.nCountNoReply >= self.nMaxCountNoReply ):
                    self.goOut( self.asExitWords[0], "timeout" )
        else:
            self.nCountNoReply = 0
            if( self.sRecoInterruption in [ "onStop" ] ):
                self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        self.sRecoInterruption = ""

    def repeatWhenNoQuestion(self):
        "Robot's reaction when it is asked to repeat the question when there is no question."
        if( self.sQuestion == "" ):
            sentenceNoQuestion = self.aAllSentences[self.tts.getLanguage()]["noQuestion"][0]
            sentenceNoQuestion += self.enumerateChoices( True ) # True to ask that the introduction is played
            if( len( self.aChoices ) - len( self.aDefaultChoices ) == 0 ): # if there is no choice
                sentenceNoQuestion += self.enumerateDefaultChoices( True ) # True to ask that the introduction is played
            # launch TTS
            idTTS = -1
            if( sentenceNoQuestion != ""):
                if( self.bInTactileSensorMenu ):
                    idTTS = self.tts.post.say( sentenceNoQuestion + "\\Pau=300\\" )
                else:
                    idTTS = self.tts.post.say( sentenceNoQuestion )
                self.aIdsTTS.append( idTTS )
                self.logger.debug( "Robot says: " + str(sentenceNoQuestion) )
                if( not self.bInTactileSensorMenu ):
                    # launch TTS movement animation
                    if( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ):
                        self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                        try:
                            self.getTimeline().goTo(self.nFrameNumber)
                        except: # if NAOqi < 1.14
                            try:
                                self.gotoAndStop(self.nFrameNumber)
                            except:
                                pass
            # wait for the end of the TTS
            if( idTTS != -1 ):
                try:
                    self.tts.wait( idTTS, 0 )
                except:
                    self.logger.debug( "Warning: Could not wait the TTS." )

# RECO OUTPUT PROCESSING --------------------------------------------------------------------------------------

    def onWordRecognized(self, pDataName, pValue, pMessage):
        "Handler for when a word is recognised by the speech recognition system."
        aState = pValue
        self.logger.debug( "The word '" + str(aState[0]) + "' has been recognised with a threshold of " + str(aState[1]) + "." )
        # interrupt loops:
            # - stop reco
            # - stop leds
            # - stop asking the question on and on
        try:
            self.memory.unsubscribeToEvent( "WordRecognized", self.getName() )
            self.logger.debug( "Speech recognition stopped." )
            self.memory.unsubscribeToEvent( "SpeechDetected", self.getName() )
        except:
            pass
        self.bRecoIsHearingOrAnalysing = False
        self.bRecoIsWaitingForVoice = False
        if( aState[0] != "" ):
            if( aState[1] >= self.rUnderstoodThreshold ):
                if( self.rUnderstoodThreshold <= self.arUnderstoodThreshold[1] - 0.02 ):
                    self.rUnderstoodThreshold += 0.02
                else:
                    self.rUnderstoodThreshold = self.arUnderstoodThreshold[1]
                if( self.bInConfirmation ):
                    if( aState[0] in self.asNegativeWords ):
                        thread.start_new_thread( self.ledsNegative, () )
                    else:
                        thread.start_new_thread( self.ledsUnderstood, (True, False) )
                else:
                    thread.start_new_thread( self.ledsUnderstood, (True, False) )
                self.reactionWordUnderstood( aState )
            else:
                if( self.rUnderstoodThreshold >= self.arUnderstoodThreshold[0] + 0.05 ):
                    self.rUnderstoodThreshold -= 0.05
                else:
                    self.rUnderstoodThreshold = self.arUnderstoodThreshold[0]
                aCurrentChoice = ""
                for choice in self.aChoices:
                    if( aCurrentChoice == "" ):
                        if( aState[0] in choice ):
                            aCurrentChoice = choice
                if( self.sPreviousAnswer in aCurrentChoice ): # if answer in the same choice as previously
                    # then ask confirmation
                    aState[1] = self.rConfirmationThreshold - 0.01
                    thread.start_new_thread( self.ledsUnderstood, (True, False) )
                    self.reactionWordUnderstood( aState )
                else:
                    # else not understood
                    if( self.bInConfirmation ):
                        thread.start_new_thread( self.ledsUnderstood, (True, False) )
                    else:
                        self.sPreviousAnswer = aState[0]
                        thread.start_new_thread( self.ledsNotUnderstood, () )
                    self.reactionNothingUnderstood()
        else:
            if( self.bInConfirmation ):
                thread.start_new_thread( self.ledsUnderstood, (True, False) )
            else:
                thread.start_new_thread( self.ledsNotUnderstood, () )
            self.reactionNothingUnderstood()
        if( pMessage == "" ):
            self.sRecoInterruption = "wordRecognised"
        else:
            self.sRecoInterruption = pMessage

    def onSpeechDetected(self, pDataName, pValue, pMessage):
        "Handler for when something has been heard by the speech recognition system."
        aState = pValue
        if( aState == 1):
            if( self.bRecoIsWaitingForVoice ):
                # make eyes leds switch from an animation to an other
                self.bRecoIsHearingOrAnalysing = True
                self.bRecoIsWaitingForVoice = False
                try:
                    self.timeToReply(time.time() - self.beginTime)
                except:
                    pass

    def reactionWordUnderstood(self, word):
        "Reaction depending on the word recognised (help, repeat, word in choices, etc...) and its recognition confidence."
        if( self.bInConfirmation ):
            self.bInConfirmation = False
            if( word[0] in self.asNegativeWords ):
                # update number of failures
                self.nCountFailure += 1
                if( self.sPreviousAnswer in self.asHelpWords ):
                    if( self.nCountFailure >= self.nMaxCountFailure ): # if maximum number of failures
                        # skip the question
                        self.goOut( self.asExitWords[0], "notUnderstood" )
                else:
                    self.helpAfterFailure()
            else:
                if( (self.sPreviousAnswer in self.asHelpWords) or (word[0] in self.asHelpWords) ):
                    self.helpWhenAsked()
                elif( self.sPreviousAnswer in self.asRepeatWords or (word[0] in self.asRepeatWords) ):
                    self.repeatWhenNoQuestion()
                    # repeat the question
                else:
                    self.goOut( self.sPreviousAnswer, "wordRecognised" )
                self.sPreviousAnswer = ""
        else:
            self.sPreviousAnswer = word[0]
            if( word[1] >= self.rConfirmationThreshold ):
                if( self.rConfirmationThreshold <= self.arConfirmationThreshold[1] - 0.02 ):
                    self.rConfirmationThreshold += 0.02
                else:
                    self.rConfirmationThreshold = self.arConfirmationThreshold[1]
                if( self.sPreviousAnswer in self.asHelpWords ):
                    self.helpWhenAsked()
                elif( self.sPreviousAnswer in self.asRepeatWords ):
                    self.repeatWhenNoQuestion()
                    # repeat the question
                else:
                    self.goOut( self.sPreviousAnswer, "wordRecognised" )
                self.sPreviousAnswer = ""
            else:
                if( self.rConfirmationThreshold >= self.arConfirmationThreshold[0] + 0.05 ):
                    self.rConfirmationThreshold -= 0.05
                else:
                    self.rConfirmationThreshold = self.arConfirmationThreshold[0]
                self.bInConfirmation = True

    def reactionNothingUnderstood(self):
        "Reaction when nothing has been understood or without an enough confidence."
        if( self.bInConfirmation ):
            # if the robot did not understand, we assume that the user agree
            self.bInConfirmation = False
            if( self.sPreviousAnswer in self.asHelpWords ): # if help asked
                self.helpWhenAsked()
            elif( self.sPreviousAnswer in self.asRepeatWords ): # if repeat asked
                self.repeatWhenNoQuestion()
                # repeat the question
            else: # if not repeat nor help asked
                self.goOut( self.sPreviousAnswer, "wordRecognised" )
        else:
            # update number of failures
            self.nCountFailure += 1
            if( self.nCountFailure <= 1 ): # if first failure
                sentence = self.aAllSentences[self.tts.getLanguage()]["notUnderstood"][0]
            else: # if second failure or more
                sentenceNotUnderstoodAnims = self.aAllSentences[self.tts.getLanguage()]["notUnderstoodAnims"]
                index = random.randint( 0, len( sentenceNotUnderstoodAnims ) - 1 )
                sentence = sentenceNotUnderstoodAnims[index]
                if( self.nFrameNumber != self.aFrameNumbers["notUnderstood"] + 10*index ):
                    self.nFrameNumber = self.aFrameNumbers["notUnderstood"] + 10*index
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
            self.helpAfterFailure( sentence )

# HELP ------------------------------------------------------------------------------------------------------

    def enumerateChoices(self, bIntroToSay):
        "Enumerate choices (only the first word of each choice is taken into account)."
        sentenceHelpEnumChoices = self.aAllSentences[self.tts.getLanguage()]["helpEnumChoices"]
        sentenceHelpEnumMarks = self.aAllSentences[self.tts.getLanguage()]["enumMarks"]
        enumWords = ""
        maxNbEnumChoices = 3
        indexes = []
        for i in range( min(maxNbEnumChoices, len( self.aChoices ) - len( self.aDefaultChoices )) ):
            if( len( self.aChoices ) - len( self.aDefaultChoices ) <= maxNbEnumChoices ):
                index = len( self.aDefaultChoices ) + i
            else:
                index = random.randint( len( self.aDefaultChoices ), len( self.aChoices ) - 1 )
                while( index in indexes ):
                    index = random.randint( len( self.aDefaultChoices ), len( self.aChoices ) - 1 )
            indexes.append( index )
            if( len( indexes ) != 1 ): # if it is not the first choice
                if( len( indexes ) != min(maxNbEnumChoices, len( self.aChoices ) - len( self.aDefaultChoices )) ): # if it is not the last choice
                    enumWords += sentenceHelpEnumMarks[0]
                else:
                    enumWords += sentenceHelpEnumMarks[1]
            enumWords += self.aChoices[index][0]
        sentenceTemplate = sentenceHelpEnumChoices[2]
        if( len( self.aChoices ) - len( self.aDefaultChoices ) <= maxNbEnumChoices ): # if there are 3 or less choices
            sentenceTemplate = sentenceHelpEnumChoices[1]
        if( not bIntroToSay ):
            sentenceTemplate = sentenceHelpEnumChoices[3]
        if( len( self.aChoices ) - len( self.aDefaultChoices ) == 0 ): # if there is no choice
            sentence = sentenceHelpEnumChoices[0]
        else:
            sentence = sentenceTemplate % enumWords
        return sentence

    def enumerateDefaultChoices(self, bIntroToSay):
        "Enumerate default choices (only the first word of each choice is taken into account)."
        sentenceHelpEnumChoices = self.aAllSentences[self.tts.getLanguage()]["helpEnumChoices"]
        sentenceHelpEnumDefault = self.aAllSentences[self.tts.getLanguage()]["helpEnumDefault"]
        sentenceHelpEnumMarks = self.aAllSentences[self.tts.getLanguage()]["enumMarks"]
        enumWords = ""
        indexes = []
        for i in range( len( self.aDefaultChoices ) ):
            indexes.append( i )
            if( len( indexes ) != 1 ): # if it is not the first choice
                if( len( indexes ) != len( self.aDefaultChoices ) ): # if it is not the last choice
                    enumWords += sentenceHelpEnumMarks[0]
                else:
                    enumWords += sentenceHelpEnumMarks[1]
            enumWords += self.aDefaultChoices[i][0]
        sentenceTemplate = sentenceHelpEnumDefault[0]
        if( not bIntroToSay ):
            sentenceTemplate = sentenceHelpEnumChoices[3]
        if( len( self.aDefaultChoices ) == 0 ): # if there is no default choice
            sentence = ""
        else:
            sentence = sentenceTemplate % enumWords
        return sentence

    def explanationTactileSensor(self):
        "Explain the possible interaction with the tactile sensor."
        sentenceHelpTactile = self.aAllSentences[self.tts.getLanguage()]["helpTactile"]
        if( self.bInTactileSensorMenu ):
            sentence = sentenceHelpTactile[1]
        else:
            sentence = sentenceHelpTactile[0]
        return sentence

    def helpWhenAsked(self, sentence = ""):
        "Help when the user asked it: enumerate choices, enumerate default choices and explain tactile sensor possible interaction."
        if( not self.bInTactileSensorMenu ):
            # enumeration of choices
            sentence += self.enumerateChoices( True ) # True to ask that the introduction is played
            # enumeration of default choices
            sentence += self.enumerateDefaultChoices( True ) # True to ask that the introduction is played
        # explanation about alternative modality (tactil sensor, arm motion)
        sentence += self.explanationTactileSensor()
        # launch TTS
        idTTS = -1
        if( sentence != "" ):
            if( self.bInTactileSensorMenu ):
                idTTS = self.tts.post.say( sentence + "\\Pau=300\\" )
            else:
                idTTS = self.tts.post.say( sentence )
            self.aIdsTTS.append( idTTS )
            self.logger.debug( "Robot says: " + str(sentence) )
            # launch TTS movement animation
            if( self.bInTactileSensorMenu ):
                if( self.nFrameNumber != self.aFrameNumbers["helpTactileSensor"] ):
                    self.nFrameNumber = self.aFrameNumbers["helpTactileSensor"]
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
            else:
                if( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ):
                    self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
        # wait for the end of the TTS
        if( idTTS != -1 ):
            try:
                self.tts.wait( idTTS, 0 )
            except:
                self.logger.debug( "Warning: Could not wait the TTS." )
        # repeat the question

    def helpAfterFailure(self, sentence = ""):
        "Help when the speech recognition failed (nothing understood or incorrect answer understood)."
        if( self.nCountFailure < self.nMaxCountFailure ): # if reasonable number of failures
            if( self.bActivateHelpWhenFailure ):
                if( self.nCountFailure in [1, 2] ): # if first or second failure
                    # enumeration of choices, or default words if there is no choice
                    if( len( self.aChoices ) - len( self.aDefaultChoices ) > 0 ): # if there is at least one choice
                        sentence += self.enumerateChoices( self.nCountFailure == 1 ) # the introduction is played if it is the first failure
                    else:
                        sentence += self.enumerateDefaultChoices( self.nCountFailure == 1 ) # the introduction is played if it is the first failure
                    if( self.nCountFailure == 2 ): # if second failure
                        # explanation about alternative modality (tactil sensor, arm motion)
                        sentence += self.explanationTactileSensor()
                # launch TTS
                idTTS = -1
                if( sentence != "" ):
                    idTTS = self.tts.post.say( sentence )
                    self.aIdsTTS.append( idTTS )
                    self.logger.debug( "Robot says: " + str(sentence) )
                    # launch TTS movement animation
                    listPossibleFrames = range( len( self.aAllSentences[self.tts.getLanguage()]["notUnderstoodAnims"] ) )
                    for i in range(len(listPossibleFrames)):
                        listPossibleFrames[i] = listPossibleFrames[i] * 10 + self.aFrameNumbers["notUnderstood"]
                    if( ( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ) and not ( self.nFrameNumber in listPossibleFrames ) ):
                        try:
                            self.getTimeline().goTo(self.aFrameNumbers["bodyTalk"])
                        except: # if NAOqi < 1.14
                            try:
                                self.gotoAndStop(self.aFrameNumbers["bodyTalk"])
                            except:
                                pass
                    self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                # wait for the end of the TTS
                if( idTTS != -1 ):
                    try:
                        self.tts.wait( idTTS, 0 )
                    except:
                        self.logger.debug( "Warning: Could not wait the TTS." )
            # repeat the question
        else: # if maximum number of failures
            # skip the question
            self.goOut( self.asExitWords[0], "notUnderstood" )

# LEDS ---------------------------------------------------------------------------------------------------

    def setLeds(self, eyesLight, earsLight, brainLight):
        "Set all LEDS (eyes, ears and brain lights)."
        rDuration = 1
        if( self.bActivateEyesLight ):
            # set eyes leds
            self.leds.post.fadeRGB( "FaceLeds", eyesLight, rDuration )
        if( self.bActivateEarsLight ):
            # set ears leds
            self.leds.fadeRGB( "EarLeds", earsLight, rDuration )
        if( self.bActivateBrainLight ):
            # set brain leds light
            self.setLedsBrain( brainLight, 500 )

    def ledsUnderstood(self, bFlashEars, bFlashBrain):
        "Sequence of LEDS for eyes, ears and brain when the robot understood what it heard."
        self.bBrainAnimPaused = True
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x00FF00, rDuration )
        if( self.bActivateEarsLight ):
            if( bFlashEars ):
                self.leds.fadeRGB( "EarLeds", 0x00FF00, rDuration )
        if( self.bActivateBrainLight ):
            if( bFlashBrain ):
                self.setLedsBrain( 0.5, int(rDuration * 1000) )
        time.sleep( 0.3 )
        rDuration = 0.2
        if( self.bActivateEyesLight ):
            if( self.bInTactileSensorMenu ):
                self.leds.fadeRGB( "FaceLeds", 0xFFFFFF, rDuration )
            else:
                self.leds.fadeRGB( "FaceLeds", 0x000000, rDuration )
        if( self.bActivateEarsLight ):
            if( bFlashEars ):
                self.leds.fadeRGB( "EarLeds", 0x000000, rDuration )
        if( self.bActivateBrainLight ):
            if( bFlashBrain ):
                self.setLedsBrain( 0., int(rDuration * 1000) )
        time.sleep( 0.1 )
        if( not self.bInTactileSensorMenu ):
            self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        time.sleep( 0.1 )
        self.bBrainAnimPaused = False

    def ledsNotUnderstood(self):
        "Sequence of LEDS for eyes and ears when the robot did not understand what it heard."
        self.bBrainAnimPaused = True
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFF0000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0xFF0000, rDuration )
        time.sleep( 0.05 )
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x000000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0x000000, rDuration )
        time.sleep( 0.05 )
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFF0000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0xFF0000, rDuration )
        time.sleep( 0.05 )
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x000000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0x000000, rDuration )
        time.sleep( 0.3 )
        self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        self.bBrainAnimPaused = False

    def ledsNegative(self):
        "Sequence of LEDS for eyes and ears when the robot understood 'no'."
        self.bBrainAnimPaused = True
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFF0000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0xFF0000, rDuration )
        time.sleep( 0.3 )
        rDuration = 0.2
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x000000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0x000000, rDuration )
        time.sleep( 0.1 )
        self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        time.sleep( 0.1 )
        self.bBrainAnimPaused = False

    def loopLedsReco(self):
        "LEDS (eyes and ears) process during the speech recognition."
        self.beginTime = time.time()
        if( self.bInConfirmation ):
            timerReco = self.beginTime + self.nTimeoutRecoConfirmation
        else:
            timerReco = self.beginTime + self.nTimeoutReco
        self.bHasAlreadyHearingEyes = False
        nEarLedsNextIndex = 0
        nEyesLed = -1
        while( self.bRecoIsWaitingForVoice or self.bRecoIsHearingOrAnalysing ):
            if( self.bMustStop ):
                try:
                    self.timeToReply(time.time() - self.beginTime)
                except:
                    pass
                break
            if( self.bRecoIsWaitingForVoice ):
                if( timerReco < time.time() ):
                    try:
                        self.timeToReply(timerReco - self.beginTime)
                    except:
                        pass
                    self.sRecoInterruption = "timeout"
                    break
            nEarLedsNextIndex = self.ledsEarsTurnOneStep( nEarLedsNextIndex )
            nEyesLed += 1
            self.ledsEyesTurnOneStep( 0x0055FF, nEyesLed%8 )
            time.sleep( 0.2 )

    def ledsEarsTurnOneStep(self, nEarLedsNextIndex):
        "One step of ears LEDS sequence (turn) when the robot is in speech recognition."
        if( self.bActivateEarsLight ):
            nNbrLedByEars = 10
            rTime = 0.7
            strTemplate = "Ears/Led/%s/%dDeg/Actuator/Value"
            nAngle = (360/nNbrLedByEars) * nEarLedsNextIndex
            # update index before sending movement in case of a fast/concurrent call of the function
            nEarLedsNextIndex -= 1 # more beautiful to turn in this way
            if( nEarLedsNextIndex < 0 ):
                nEarLedsNextIndex = nNbrLedByEars-1
            self.leds.post.fade( strTemplate % ( "Left", nAngle ), 1.0, rTime )
            self.leds.post.fade( strTemplate % ( "Right", nAngle ), 1.0, rTime )
            self.leds.post.fade( strTemplate % ( "Left", nAngle ), 0.0, rTime*1.2 )
            self.leds.post.fade( strTemplate % ( "Right", nAngle ), 0.0, rTime*1.2 )
        return nEarLedsNextIndex

    def ledsEyesTurnOneStep(self, nColor, nLed):
        "One step of eyes LEDS sequence (turn) when the robot is in speech recognition."
        if( self.bActivateEyesLight ):
            rTime = 0.7
            if( self.bRecoIsHearingOrAnalysing ):
                if( not self.bHasAlreadyHearingEyes ):
                    self.leds.fadeRGB( "FaceLeds", 0xF4FF22, 0.1 )
                    # start headcheck animation
                    if( self.nFrameNumber != self.aFrameNumbers["headCheck"] ):
                        self.nFrameNumber = self.aFrameNumbers["headCheck"]
                        try:
                            self.getTimeline().goTo(self.nFrameNumber)
                        except: # if NAOqi < 1.14
                            try:
                                self.gotoAndStop(self.nFrameNumber)
                            except:
                                pass
                    self.bHasAlreadyHearingEyes = True
            elif( self.bRecoIsWaitingForVoice ):
                self.leds.post.fadeRGB( "FaceLed%d" % (nLed) , nColor, rTime )
                self.leds.post.fadeRGB( "FaceLed%d" % (nLed) , 0x000000, rTime*1.25 )

    def ledsChangeOnTactile(self):
        self.bBrainAnimPaused = True
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x0055FF, rDuration )
        self.setLedsBrain( 0.5, int(rDuration * 1000) )
        time.sleep( 0.3 )
        rDuration = 0.2
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFFFFFF, rDuration )
        self.setLedsBrain( 0., int(rDuration * 1000) )
        time.sleep( 0.2 )
        self.bBrainAnimPaused = False

    def loopLedsBrainTurn(self):
        self.setLeds( 0xFFFFFF, 0xFFFFFF, 0. )
        rIntensity = 0.5
        nTime = 50
        bAlreadyPaused = False
        while( self.bInTactileSensorMenu ):
            if( not self.bBrainAnimPaused ):
                if( self.nFront == 1 or self.nMiddle == 1 or self.nRear == 1 ):
                    if( not bAlreadyPaused ):
                        bAlreadyPaused = True
                        self.setLedsBrain( 0., 50 )
                else:
                    bAlreadyPaused = False
                    if( self.bActivateBrainLight ):
                        for i in range( 12 ):
                            if( not self.bBrainAnimPaused and self.dcm != None):
                                riseTime = self.dcm.getTime(nTime)
                                strDeviceName = self.getBrainLedName(i)
                                self.dcm.set( [ strDeviceName, "Merge",  [[ rIntensity, riseTime ]] ] )
                                time.sleep( nTime/1000. )
                                if( not self.bBrainAnimPaused ):
                                    self.dcm.set( [ strDeviceName, "Merge",  [[ 0.0, riseTime + int(nTime)/4 ]] ] )
            time.sleep( nTime/1000. )
        self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )

    def loopLedsBrainTwinkle(self):
        rIntensity = 0.5
        bOnStep = True
        bAlreadyPaused = False
        while( not self.bInTactileSensorMenu and self.bIsRunning ):
            if( not self.bBrainAnimPaused ):
                if( self.nFront == 1 or self.nMiddle == 1 or self.nRear == 1 ):
                    if( not bAlreadyPaused ):
                        bAlreadyPaused = True
                        self.setLedsBrain( 0., 50 )
                else:
                    bAlreadyPaused = False
                    if( bOnStep ):
                        self.setLedsBrain( rIntensity, 700 )
                        bOnStep = False
                    else:
                        self.setLedsBrain( 0.0, 700 )
                        bOnStep = True
            time.sleep( 1 )

    def setLedsBrain(self, rIntensity, rTimeMs):
        "One step of brain LEDS sequence (twinkle) when the robot is in speech recognition."
        if( self.bActivateBrainLight and self.dcm != None):
            riseTime = self.dcm.getTime( rTimeMs )
            for i in range( 12 ):
                strDeviceName = self.getBrainLedName(i)
                self.dcm.set( [ strDeviceName, "Merge",  [[ rIntensity, riseTime ]] ] )

# TACTILE SENSOR MENU -------------------------------------------------------------------------------------

    def onAlternativeModalityAction(self, p):
        "Process actions from alternative modalities (sequence from the tactile sensor, simple click on the torso button...)."
        if( not self.bIsRunning ): # if the box is not running
            return # then go out without doing a thing
        if( not self.bInTactileSensorMenu ): # if we are not in the tactile sensor menu (so if we are in the question-recognition-reaction loop)
            if( p in ["TapFront", "TapMiddle", "TapRear", "LongFront", "LongMiddle", "LongRear"] ):
                bTTSRunning = False # to know if TTS is running
                for idTTS in self.aIdsTTS:
                    if( self.tts.isRunning( idTTS )):
                        bTTSRunning = True
                if( bTTSRunning ): # if TTS is running
                    # skip the TTS
                    self.skipTTS()
                else: # if TTS was not running (so if in recognition)
                    # prepare to start the tactile sensor menu
                    self.bInTactileSensorMenu = True
                    # and stop the question-recognition-reaction loop
                    self.goOutOfQuestionRecoReaction()
                    self.sRecoInterruption = "onTactileSensor"
                    # start the tactile sensor menu
                    self.sayCurrentChoice()
                    # start counting timeout
                    self.rTimeWhenActionMadeInTactileMenu = time.time()
                    thread.start_new_thread( self.loopCheckTimeoutInTactileMenu, (self.rTimeWhenActionMadeInTactileMenu,) )
            elif( p in ["Tap", "CalmDown"] ):
                # skip the TTS
                self.skipTTS()
                # then stop everything and cancel the question
                self.goOut( self.asExitWords[0], "onTactileSensor" )
                self.sRecoInterruption = "onTactileSensor"
                self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        else: # if we are in the tactile sensor menu
            self.rTimeWhenActionMadeInTactileMenu = -1.
            if( p in ["TapFront"] ):
                bTTSRunning = False # to know if TTS is running
                for idTTS in self.aIdsTTS:
                    if( self.tts.isRunning( idTTS ) ):
                        bTTSRunning = True
                if( self.bIsSayingChoice or not bTTSRunning ): # else just skip the TTS (in the sayCurrentChoice function)
                    # change choice
                    self.nIndexChoice += 1
                    if( self.nIndexChoice >= len( self.aChoices ) ):
                        self.nIndexChoice = 0
                # say the choice in the tactile sensor menu
                self.sayCurrentChoice()
                self.timeoutManagingInTactileMenu()
            elif( p in ["TapRear"] ):
                bTTSRunning = False # to know if TTS is running
                for idTTS in self.aIdsTTS:
                    if( self.tts.isRunning( idTTS )):
                        bTTSRunning = True
                if( self.bIsSayingChoice or not bTTSRunning ): # else just skip the TTS (in the sayCurrentChoice function)
                    # change choice
                    self.nIndexChoice -= 1
                    if( self.nIndexChoice < 0 ):
                        self.nIndexChoice = len( self.aChoices ) - 1
                # say the choice in the tactile sensor menu
                self.sayCurrentChoice()
                self.timeoutManagingInTactileMenu()
            elif( p in ["TapMiddle", "LongMiddle"] ):
                self.rTimeWhenActionMadeInTactileMenu = time.time()
                rTimeForThisAction = self.rTimeWhenActionMadeInTactileMenu
                bWasSayingChoice = self.bIsSayingChoice
                bTTSRunning = False # to know if TTS is running
                for idTTS in self.aIdsTTS:
                    if( self.tts.isRunning( idTTS )):
                        bTTSRunning = True
                # skip the TTS if it is running
                self.skipTTS()
                if( bWasSayingChoice or not bTTSRunning ):
                    # validate choice
                    thread.start_new_thread( self.ledsUnderstood, (False, True) )
                    if( self.aChoices[self.nIndexChoice][0] == self.asRepeatWords[0] ):
                        self.repeatWhenNoQuestion()
                        # launch TTS
                        idTTS = -1
                        if( self.sQuestion != ""):
                            idTTS = self.tts.post.say( self.sQuestion + "\\Pau=300\\" )
                            self.aIdsTTS.append( idTTS )
                            self.logger.debug( "Robot says: " + str(self.sQuestion) )
                        # wait for the end of the TTS
                        if( idTTS != -1 ):
                            try:
                                self.tts.wait( idTTS, 0 )
                            except:
                                self.logger.debug( "Warning: Could not wait the TTS." )
                    else:
                        self.reactionWordUnderstood( [ self.aChoices[self.nIndexChoice][0], 1.0 ] )
                if( self.bIsRunning and rTimeForThisAction == self.rTimeWhenActionMadeInTactileMenu ): #$$$
                    self.rTimeWhenActionMadeInTactileMenu = -1.
                    # say the choice in the tactile sensor menu
                    self.sayCurrentChoice()
                    self.timeoutManagingInTactileMenu()
            elif( p == "LongFront" ):
                if( not self.bPressed ):
                    self.bPressed = True
                    bLastElementSaid = False
                    while( self.bPressed ):
                        if( self.nFront == 0 ):
                            self.bPressed = False
                            break
                        bTTSRunning = False # to know if TTS is running
                        for idTTS in self.aIdsTTS:
                            if( self.tts.isRunning( idTTS )):
                                bTTSRunning = True
                        if( self.bIsSayingChoice or not bTTSRunning ):
                            # change choice
                            self.nIndexChoice += 1
                            if( self.nIndexChoice >= len( self.aChoices ) - 1 ):
                                self.nIndexChoice = len( self.aChoices ) - 1
                                if( not bLastElementSaid ):
                                    bLastElementSaid = True
                                    # say the choice in the tactile sensor menu
                                    thread.start_new_thread( self.sayCurrentChoice, () )
                            else:
                                # say the choice in the tactile sensor menu
                                thread.start_new_thread( self.sayCurrentChoice, () )
                        else:
                            if( self.nIndexChoice == len( self.aChoices ) - 1 ):
                                bLastElementSaid = True
                            # say the choice in the tactile sensor menu
                            thread.start_new_thread( self.sayCurrentChoice, () )
                        for i in range(8):
                            if( self.nFront == 0 ):
                                self.bPressed = False
                                break
                            time.sleep(0.1)
                    for idTTS in self.aIdsTTS:
                        if( self.tts.isRunning( idTTS ) ):
                            try:
                                self.tts.wait( idTTS, 0 )
                            except:
                                self.logger.debug( "Warning: Could not wait the TTS." )
                    self.timeoutManagingInTactileMenu()
            elif( p == "LongRear" ):
                if( not self.bPressed ):
                    self.bPressed = True
                    bFirstElementSaid = False
                    while( self.bPressed ):
                        if( self.nRear == 0 ):
                            self.bPressed = False
                            break
                        bTTSRunning = False # to know if TTS is running
                        for idTTS in self.aIdsTTS:
                            if( self.tts.isRunning( idTTS )):
                                bTTSRunning = True
                        if( self.bIsSayingChoice or not bTTSRunning ):
                            # change choice
                            self.nIndexChoice -= 1
                            if( self.nIndexChoice <= 0 ):
                                self.nIndexChoice = 0
                                if( not bFirstElementSaid ):
                                    bFirstElementSaid = True
                                    # say the choice in the tactile sensor menu
                                    thread.start_new_thread( self.sayCurrentChoice, () )
                            else:
                                # say the choice in the tactile sensor menu
                                thread.start_new_thread( self.sayCurrentChoice, () )
                        else:
                            if( self.nIndexChoice == 0 ):
                                bFirstElementSaid = True
                            # say the choice in the tactile sensor menu
                            thread.start_new_thread( self.sayCurrentChoice, () )
                        for i in range(8):
                            if( self.nRear == 0 ):
                                self.bPressed = False
                                break
                            time.sleep(0.1)
                    for idTTS in self.aIdsTTS:
                        if( self.tts.isRunning( idTTS ) ):
                            try:
                                self.tts.wait( idTTS, 0 )
                            except:
                                self.logger.debug( "Warning: Could not wait the TTS." )
                    self.timeoutManagingInTactileMenu()
            elif( p in ["Tap", "CalmDown"] ):
                # then stop everything and cancel the question
                self.goOut( self.asExitWords[0], "onTactileSensor" )

    def sayCurrentChoice(self):
        "In the tactile sensor menu, make the robot say the current selected choice"
        self.bIsSayingChoice = True
        rTimeCurrent = time.time()
        self.rTimeLastChoiceSaid = rTimeCurrent
        # stop previous TTS
        self.skipTTS()
        # launch TTS
        idTTS = -1
        if( self.aChoices[ self.nIndexChoice ][0] != "" ):
            if( self.nFrameNumber != self.aFrameNumbers["headDown"] ):
                self.nFrameNumber = self.aFrameNumbers["headDown"]
                try:
                    self.getTimeline().goTo(self.nFrameNumber)
                except: # if NAOqi < 1.14
                    try:
                        self.gotoAndStop(self.nFrameNumber)
                    except:
                        pass
            sentence = self.aChoices[ self.nIndexChoice ][0] + "?"
            idTTS = self.tts.post.say( sentence )
            self.aIdsTTS.append( idTTS )
            self.logger.debug( "Robot says: " + str(sentence) )
            # launch flash leds
            thread.start_new_thread( self.ledsChangeOnTactile, () )
        if( idTTS != -1 ):
            try:
                self.tts.wait( idTTS, 0 )
            except:
                self.logger.debug( "Warning: Could not wait the TTS." )
        if( self.rTimeLastChoiceSaid == rTimeCurrent ):
            self.rTimeLastChoiceSaid = -1.
            self.bIsSayingChoice = False

    def timeoutManagingInTactileMenu(self):
        # check if there has been an other action with tts made while this one was processed
        bTTSRunning = False # to know if TTS is running
        for idTTS in self.aIdsTTS:
            if( self.tts.isRunning( idTTS )):
                bTTSRunning = True
        if( not bTTSRunning ):
            # start counting timeout
            self.rTimeWhenActionMadeInTactileMenu = time.time()
            thread.start_new_thread( self.loopCheckTimeoutInTactileMenu, (self.rTimeWhenActionMadeInTactileMenu,) )

    def loopCheckTimeoutInTactileMenu(self, rTimeForThisAction):
        nTimeout = time.time() + self.nTimeoutTactile
        if( self.rTimeWhenActionMadeInTactileMenu == rTimeForThisAction ):
            while( time.time() < nTimeout and self.rTimeWhenActionMadeInTactileMenu == rTimeForThisAction and self.bIsRunning ):
                time.sleep( 0.1 )
            if( self.rTimeWhenActionMadeInTactileMenu != rTimeForThisAction ):
                self.nCountNoReply = 0
            elif( self.bIsRunning ):
                self.rTimeWhenActionMadeInTactileMenu = -1.
                self.nCountNoReply += 1
                if( self.nCountNoReply >= self.nMaxCountNoReply ):
                    self.goOut( self.asExitWords[0], "timeout" )
                else:
                    bTTSRunning = False # to know if TTS is running
                    for idTTS in self.aIdsTTS:
                        if( self.tts.isRunning( idTTS )):
                            bTTSRunning = True
                    if( not bTTSRunning ):
                        # say the choice in the tactile sensor menu
                        self.sayCurrentChoice()
                        # start counting timeout
                        self.rTimeWhenActionMadeInTactileMenu = time.time()
                        thread.start_new_thread( self.loopCheckTimeoutInTactileMenu, (self.rTimeWhenActionMadeInTactileMenu,) )

# TACTILE SENSOR HANDLER -------------------------------------------------------------------------------

    def initSeqDetected(self):
        "Initialize the sequence handler."
        self.bSeqStarted = False
        self.aDetectedSeqs = []
        self.aDetectedSeqs.extend(self.aSeqs)
        for seq in self.aDetectedSeqs:
            seq["index"] = 0
            seq["previousStepTime"] = 0

    def convertToArrayOfPossibleStates(self, states):
        "Check if the states described in the sequences using a string are in the right syntax, and then convert them to an array of the possible states."
        aStates = []
        aStates3 = [[1, 1, 1]]
        aStates2 = [[0, 1, 1], [1, 0, 1], [1, 1, 0]]
        aStates1 = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]
        aStates0 = [[0, 0, 0]]
        try:
            if( int(states) == states ): # if states is an integer
                states = str(states)
        except:
            pass
        if( self.isString(states) ):
            if( not states in ["*", "0+", "0", "0-", "1+", "1", "1-", "2+", "2", "2-", "3+", "3", "3-", "F+", "F", "F-", "M+", "M", "M-", "R+", "R", "R-"] ):
                raise Exception( "Error in sequences states description syntax: description expected in " + str(["*", "0+", "0", "0-", "1+", "1", "1-", "2+", "2", "2-", "3+", "3", "3-", "F+", "F", "F-", "M+", "M", "M-", "R+", "R", "R-"]) + " but " + str(p) + " found with this type: " + str(type(p)) )
            if( states in ["*", "0+", "1+", "2+", "3+", "3", "3-", "F+", "M+", "R+"] ):
                aStates.extend(aStates3)
            if( states in ["*", "0+", "1+", "2+", "2", "2-", "3-"] ):
                aStates.extend(aStates2)
            if( states in ["*", "0+", "1+", "1", "1-", "2-", "3-"] ):
                aStates.extend(aStates1)
            if( states in ["*", "0+", "0", "0-", "1-", "2-", "3-", "F-", "M-", "R-"] ):
                aStates.extend(aStates0)
            if( states in ["F", "F+", "F-"] ):
                aStates.append([1, 0, 0])
            if( states in ["M", "M+", "M-"] ):
                aStates.append([0, 1, 0])
            if( states in ["R", "R+", "R-"] ):
                aStates.append([0, 0, 1])
            if( states in ["F+", "M+"] ):
                aStates.append([1, 1, 0])
            if( states in ["R+", "M+"] ):
                aStates.append([0, 1, 1])
            if( states in ["F+", "R+"] ):
                aStates.append([1, 0, 1])
        elif( self.isArray(states) ):
            if( self.isArray(states[0]) ):
                aStates = states
            elif( int(states[0]) == states[0] ):
                aStates = [states]
            else:
                raise Exception( "Error in sequences states description syntax: description expected in " + str(["*", "0+", "0", "0-", "1+", "1", "1-", "2+", "2", "2-", "3+", "3", "3-", "F+", "F", "F-", "M+", "M", "M-", "R+", "R", "R-"]) + " but " + str(p) + " found with this type: " + str(type(p)) )
        else:
            raise Exception( "Error in sequences states description syntax:\nstring, array or int expected but " + str(type(p)) + " found" )
        return aStates

    def checkIfSeqsCorrespondingLeft(self, param):
        "If the sequence handler is done (there is no sequence detected left or the first in the list corresponds), then reinitialize the sequence handler, and give the corresponding sequence if there is one."
        if( self.aDetectedSeqs == [] ):
            # then no sequence corresponding in the list
            self.initSeqDetected()
        else:
            if( self.aDetectedSeqs[0]["index"] == -1 ): # if first sequence in left ones corresponds
                # then it is this sequence which is played
                thread.start_new_thread( self.onAlternativeModalityAction, (self.aDetectedSeqs[0]["name"],) )
                self.initSeqDetected()
        self.mutexCheckIfSeqsCorrespondingLeft.unlock()

    def loopCheckTimeoutMax(self, nTimeoutMax, seq, currentState, currentTime):
        "When timeout ellapsed, check the sequence status and process it."
        nPreviousIndex = seq["index"]
        time.sleep(nTimeoutMax + 0.1)
        aSeqsTemp = []
        aSeqsTemp.extend( self.aDetectedSeqs )
        currentState = [self.nFront, self.nMiddle, self.nRear]
        currentTime = time.time()
        if( nPreviousIndex == seq["index"] and not self.mutexProcessCurrentState.test() and not (1 in currentState) ): # if no change in the sequence step but timeout ellapsed and sequence handler is not processing (so if there is no action from the user and the sequence is still at the same point)
            if( seq in aSeqsTemp and seq["index"] != -1 ): # but if sequence is still in the possible ones and not completed
                if( currentState in seq["statesAndTimeout"][seq["index"]] ): # last check if the current state corresponds to the next one
                    # then we go to the next step
                    seq["previousStepTime"] = currentTime
                    seq["index"] += 2
                    if( seq["index"] > len( seq["statesAndTimeout"] ) ): # if there is no more step
                        seq["index"] = -1 # then the sequence is completed
                    else: # if there is at least one step left
                        nTimeoutMin = 0
                        nTimeoutMax = 5
                        if( self.isArray(seq["statesAndTimeout"][seq["index"]-1]) ):
                            if( seq["statesAndTimeout"][seq["index"]-1][0] < 0 ):
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][0]
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][1]
                            else:
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][0]
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][1]
                        else:
                            if( seq["statesAndTimeout"][seq["index"]-1] < 0 ):
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1]
                            else:
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1]
                        thread.start_new_thread( self.loopCheckTimeoutMax, (nTimeoutMax, seq, currentState, currentTime) )
                else:
                    # then remove the sequence from the possible ones
                    aSeqsTemp.remove(seq)
                    self.aDetectedSeqs = aSeqsTemp
                self.mutexCheckIfSeqsCorrespondingLeft.lock( self.checkIfSeqsCorrespondingLeft, None )

    def loopCheckTimeoutMin(self, nTimeoutMin, seq):
        "Wait that the minimum timeout ellapse to check if the new tactile sensor state corresponds to the expected one for this sequence."
        if( nTimeoutMin != 0 ):
            nPreviousIndex = seq["index"]
            time.sleep(nTimeoutMin - time.time() + seq["previousStepTime"])
            currentTime = time.time()
            currentState = [self.nFront, self.nMiddle, self.nRear]
            self.mutexProcessCurrentState.lock( self.processCurrentState, [0, currentState, currentTime] )

    def updateDetectedSeqs(self, seq, aSeqsTemp, currentState, currentTime):
        "Update a detected sequence."
        if( seq["index"] > 0 ): # if not the first step
            nTimeoutMin = 0
            nTimeoutMax = 5
            if( self.isArray(seq["statesAndTimeout"][seq["index"]-1]) ):
                if( seq["statesAndTimeout"][seq["index"]-1][0] < 0 ):
                    nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][0]
                    nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][1]
                else:
                    nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][0]
                    nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][1]
            else:
                if( seq["statesAndTimeout"][seq["index"]-1] < 0 ):
                    nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1]
                else:
                    nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1]
            if( currentTime > nTimeoutMax + seq["previousStepTime"] ): # if timeout of this step ellapsed
                aSeqsTemp.remove(seq) # then it is not this sequence which is played
            elif( not (currentState in seq["statesAndTimeout"][seq["index"]]) ): # if the current state does not correspond to one of the described ones but the timeout of this step did not ellaspe
                # then we check that this state could be an intermediate one
                aIntermediateStates = [[], [], []]
                for i in range( len( currentState ) ):
                    for j in range( len( seq["statesAndTimeout"][seq["index"]] ) ):
                        aIntermediateStates[i].append( seq["statesAndTimeout"][seq["index"]][j][i] )
                    for j in range( len( seq["statesAndTimeout"][seq["index"]-2] ) ):
                        aIntermediateStates[i].append( seq["statesAndTimeout"][seq["index"]-2][j][i] )
                bIsIntermediate = True
                for i in range( len( currentState ) ):
                    bIsIntermediate = bIsIntermediate and ( currentState[i] in aIntermediateStates[i] )
                if( not bIsIntermediate ):
                    aSeqsTemp.remove(seq) # then it is not this sequence which is played
            else: # if the current state correspond to one of the described ones
                if( currentTime > nTimeoutMin + seq["previousStepTime"] ): # if the minimum time to wait the next step is ellapsed
                    # then we go to the next step
                    seq["previousStepTime"] = currentTime
                    seq["index"] += 2
                    if( seq["index"] > len( seq["statesAndTimeout"] ) ): # if there is no more step
                        seq["index"] = -1 # then the sequence is completed
                    else: # if there is at least one step left
                        # start clock to timeout
                        nTimeoutMin = 0
                        nTimeoutMax = 5
                        if( self.isArray(seq["statesAndTimeout"][seq["index"]-1]) ):
                            if( seq["statesAndTimeout"][seq["index"]-1][0] < 0 ):
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][0]
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][1]
                            else:
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][0]
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][1]
                        else:
                            if( seq["statesAndTimeout"][seq["index"]-1] < 0 ):
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1]
                            else:
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1]
                        thread.start_new_thread( self.loopCheckTimeoutMin, (nTimeoutMin, seq) )
                        thread.start_new_thread( self.loopCheckTimeoutMax, (nTimeoutMax, seq, currentState, currentTime) )
                else: # if the minimum time to wait the next step is not ellapsed
                    # then we are going to wait until it is to check then
                    thread.start_new_thread( self.loopCheckTimeoutMin, (nTimeoutMin, seq) )
        elif( seq["index"] == 0 ): # for the first step
            if( currentState in seq["statesAndTimeout"][seq["index"]] ): # if the current state correspond to one of the described ones
                # then we go to the next step
                seq["previousStepTime"] = currentTime
                seq["index"] += 2
                if( seq["index"] > len( seq["statesAndTimeout"] ) ): # if there is no more step
                    seq["index"] = -1 # then the sequence is completed
                else: # if there is at least one step left
                    # start clock to timeout
                    nTimeoutMin = 0
                    nTimeoutMax = 5
                    if( self.isArray(seq["statesAndTimeout"][seq["index"]-1]) ):
                        if( seq["statesAndTimeout"][seq["index"]-1][0] < 0 ):
                            nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][0]
                            nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][1]
                        else:
                            nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][0]
                            nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][1]
                    else:
                        if( seq["statesAndTimeout"][seq["index"]-1] < 0 ):
                            nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1]
                        else:
                            nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1]
                    thread.start_new_thread( self.loopCheckTimeoutMin, (nTimeoutMin, seq) )
                    thread.start_new_thread( self.loopCheckTimeoutMax, (nTimeoutMax, seq, currentState, currentTime) )
            else: # if the current state does not correspond to the first described
                aSeqsTemp.remove(seq) # then it is not this sequence which has just been started

    def updateSeqsHandler(self, currentState, currentTime):
        "Update list of detected sequences."
        aSeqsTemp = []
        aSeqsTemp.extend( self.aDetectedSeqs )
        for seq in self.aDetectedSeqs:
            self.updateDetectedSeqs( seq, aSeqsTemp, currentState, currentTime )
        self.aDetectedSeqs = aSeqsTemp
        self.mutexCheckIfSeqsCorrespondingLeft.lock( self.checkIfSeqsCorrespondingLeft, None )

    def processCurrentState(self, param):
        "Process the current tactile sensor state."
        pValue = param[0]
        currentState = param[1]
        currentTime = param[2]
        if( pValue == 1 and not self.bSeqStarted ):
            self.bSeqStarted = True
            for seq in self.aDetectedSeqs:
                seq["previousStepTime"] = currentTime
        # update sequences handler
        if( self.bSeqStarted ):
            self.updateSeqsHandler(currentState, currentTime)
        self.mutexProcessCurrentState.unlock()

    def onFrontTactilTouched(self, param):
        "Handle an action (touch or release) on the front tactile sensor."
        self.logger.debug( "Change detected on the front tactile sensor: " + str(param[0]) )
        pValue = param[0]
        currentTime = param[1]
        currentState = [pValue, self.nMiddle, self.nRear]
        self.nFront = pValue
        self.mutexProcessCurrentState.lock( self.processCurrentState, [pValue, currentState, currentTime] )
        self.mutexTactilTouched.unlock()

    def onMiddleTactilTouched(self, param):
        "Handle an action (touch or release) on the middle tactile sensor."
        self.logger.debug( "Change detected on the middle tactile sensor: " + str(param[0]) )
        pValue = param[0]
        currentTime = param[1]
        currentState = [self.nFront, pValue, self.nRear]
        self.nMiddle = pValue
        self.mutexProcessCurrentState.lock( self.processCurrentState, [pValue, currentState, currentTime] )
        self.mutexTactilTouched.unlock()

    def onRearTactilTouched(self, param):
        "Handle an action (touch or release) on the rear tactile sensor."
        self.logger.debug( "Change detected on the rear tactile sensor: " + str(param[0]) )
        pValue = param[0]
        currentTime = param[1]
        currentState = [self.nFront, self.nMiddle, pValue]
        self.nRear = pValue
        self.mutexProcessCurrentState.lock( self.processCurrentState, [pValue, currentState, currentTime] )
        self.mutexTactilTouched.unlock()

    def onTactilTouched(self, pDataName, pValue, pMessage):
        "Handle an action (touch or release) on the tactile sensor."
        self.mutexTactilTouched.lock( getattr( self, "on" + pDataName ), [pValue, time.time()] )

# OUTPUTS ACTIVATION --------------------------------------------------------------------------------------

    def goOut(self, outputName, cancelReason = ""):
        "Activate the right output (a choice output or the other output)."
        try:
            self.memory.unsubscribeToEvent( "FrontTactilTouched", self.getName() )
            self.memory.unsubscribeToEvent( "MiddleTactilTouched", self.getName() )
            self.memory.unsubscribeToEvent( "RearTactilTouched", self.getName() )
        except:
            pass

        self.bGoOut = True
        self.bInTactileSensorMenu = False
        if( outputName in self.asExitWords ):
            try:
                self.other( cancelReason )
                self.logger.debug( "Output 'other' stimulated because cancel asked: " + str(cancelReason) + "." )
            except:
                try:
                    self.onStopped( cancelReason )
                    self.logger.debug( "Output 'onStopped' stimulated because cancel asked: " + str(cancelReason) + "." )
                except:
                    try:
                        self.onStopped()
                        self.logger.debug( "Output 'onStopped' stimulated because cancel asked." )
                    except:
                        choregraphe = ALProxy( "ALChoregraphe" )
                        choregraphe.onPythonError( self.getName(), "goOut", "Invalid output: the main output name needs to be 'other', and it needs to be dynamic (because it can be either a string, or an integer)." )
        else:
            nOutput = -1
            for i in range( len (self.aChoices) - len (self.aDefaultChoices) ):
                if( nOutput == -1 ):
                    if( outputName in self.aChoices[i+len( self.aDefaultChoices )] ):
                        nOutput = i
            if( nOutput != -1):
                if( self.bExternChoices ):
                    if( self.bRepeatValidatedChoice ):
                        self.skipTTS()
                        self.tts.say( outputName )
                        self.logger.debug( "Robot says: " + str(outputName) )
                    try:
                        self.other( self.aChoiceIndexes[nOutput] )
                        self.logger.debug( "Output 'other' stimulated with: " + str(self.aChoiceIndexes[nOutput]) + " (corresponding to the choice '" + str(self.aChoices[nOutput+len( self.aDefaultChoices )][0]) + "')." )
                    except:
                        try:
                            self.onStopped( self.aChoiceIndexes[nOutput] )
                            self.logger.debug( "Output 'onStopped' stimulated with: " + str(self.aChoiceIndexes[nOutput]) + " (corresponding to the choice '" + str(self.aChoices[nOutput+len( self.aDefaultChoices )][0]) + "')." )
                        except:
                            choregraphe = ALProxy( "ALChoregraphe" )
                            choregraphe.onPythonError( self.getName(), "goOut", "Invalid type of output: using the input 'choicesList', the main output needs to be dynamic (because it can be either a string, or an integer)." )
                else:
                    if( self.bRepeatValidatedChoice ):
                        self.skipTTS()
                        self.tts.say( outputName )
                        self.logger.debug( "Robot says: " + str(outputName) )
                    try:
                        func = getattr( self, "output_" + str(self.aChoiceIndexes[nOutput]+1) ) #+1 because the first one is output_1 corresponding to the element 0 in the list.
                        func(outputName)
                        self.logger.debug( "Output 'output_" + str(self.aChoiceIndexes[nOutput]+1) + "' stimulated with: " + str(outputName) + "." )
                    except:
                        choregraphe = ALProxy( "ALChoregraphe" )
                        choregraphe.onPythonError( self.getName(), "goOut", "Invalid output: the output 'output_" + str(self.aChoiceIndexes[nOutput]+1) + "' was expected to be stimulated with: " + str(outputName) + " but could not." )
        self.onUnload()
        # come back to an initial position and stop movement animation
        if( self.nFrameNumber != self.aFrameNumbers["end"] ):
            self.nFrameNumber = self.aFrameNumbers["end"]
            try:
                self.getTimeline().goTo(self.nFrameNumber)
            except: # if NAOqi < 1.14
                try:
                    self.gotoAndStop(self.nFrameNumber)
                except:
                    pass

# UNLOAD --------------------------------------------------------------------------------------------------

    def goOutOfQuestionRecoReaction(self):
        "Set some variables to go out of the question-recognition-reaction loop and reinitialize other variables which are going to be used again only on the next start of this box."
        self.bGoOut = True
        self.bMustStop = True
        self.nCountFailure = 0
        self.nCountNoReply = 0
        self.bInConfirmation = False
        self.bVocabularyLoaded = False
        self.skipTTS()
        for idTTS in self.aIdsTTS:
            try:
                self.aIdsTTS.remove( idTTS )
            except:
                self.logger.debug( "Warning: The task ID corresponding to the Text-To-Speech could not have been removed from the ID tasks list." )
        try:
            self.memory.unsubscribeToEvent( "WordRecognized", self.getName() )
            self.bRecoIsWaitingForVoice = False
            self.bRecoIsHearingOrAnalysing = False
            self.logger.debug( "Speech recognition stopped." )
            self.memory.unsubscribeToEvent( "SpeechDetected", self.getName() )
        except:
            pass

    def onUnload(self):
        "Reinitialize variables to default state."
        self.goOutOfQuestionRecoReaction()
        self.bExternChoices = False
        self.bInTactileSensorMenu = False
        try:
            self.memory.unsubscribeToEvent( "FrontTactilTouched", self.getName() )
            self.memory.unsubscribeToEvent( "MiddleTactilTouched", self.getName() )
            self.memory.unsubscribeToEvent( "RearTactilTouched", self.getName() )
        except:
            pass
        self.bIsRunning = False]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <keyword>نعم</keyword>
                                                        <keyword>لا</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </arabic>
                                                    <brazilian>
                                                        <keyword>sim</keyword>
                                                        <keyword>não</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </brazilian>
                                                    <chinese>
                                                        <keyword>是</keyword>
                                                        <keyword>不是</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </chinese>
                                                    <czech>
                                                        <keyword>ano</keyword>
                                                        <keyword>ne</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </czech>
                                                    <danish>
                                                        <keyword>ja</keyword>
                                                        <keyword>nej</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </danish>
                                                    <dutch>
                                                        <keyword>ja</keyword>
                                                        <keyword>nee</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </dutch>
                                                    <english>
                                                        <keyword></keyword>
                                                        <keyword>Le</keyword>
                                                        <keyword>Na</keyword>
                                                        <keyword></keyword>
                                                    </english>
                                                    <finnish>
                                                        <keyword>kyllä</keyword>
                                                        <keyword>ei</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </finnish>
                                                    <french>
                                                        <keyword>oui</keyword>
                                                        <keyword>non</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </french>
                                                    <german>
                                                        <keyword>ja</keyword>
                                                        <keyword>nein</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </german>
                                                    <greek>
                                                        <keyword>ναί</keyword>
                                                        <keyword>κανένα</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </greek>
                                                    <italian>
                                                        <keyword>sì</keyword>
                                                        <keyword>no</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </italian>
                                                    <japanese>
                                                        <keyword>はい</keyword>
                                                        <keyword>いいえ</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </japanese>
                                                    <korean>
                                                        <keyword>예</keyword>
                                                        <keyword>아니</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </korean>
                                                    <norwegian>
                                                        <keyword>ja</keyword>
                                                        <keyword>Nei</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </norwegian>
                                                    <polish>
                                                        <keyword>tak</keyword>
                                                        <keyword>nie</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </polish>
                                                    <portuguese>
                                                        <keyword>sim</keyword>
                                                        <keyword>não</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </portuguese>
                                                    <russian>
                                                        <keyword>да</keyword>
                                                        <keyword>нет</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </russian>
                                                    <spanish>
                                                        <keyword>si</keyword>
                                                        <keyword>no</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </spanish>
                                                    <swedish>
                                                        <keyword>ja</keyword>
                                                        <keyword>ingen</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </swedish>
                                                    <turkish>
                                                        <keyword>evet</keyword>
                                                        <keyword>hayır</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </turkish>
                                                    <language>english</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="0" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is&#x0A;received on this input. The signal can be&#x0A;either a string so that the robot asks a&#x0A;question before the recognition of a&#x0A;choice, or a bang so that the speech&#x0A;recognition starts immediately without any&#x0A;question." id="2" />
                                                <Input name="choicesList" type="0" type_size="1" nature="1" inner="0" tooltip="To have extern choices list (for example,&#x0A;depending on extern variables).&#x0A;!! Warning !! : Must be set before each&#x0A;time the box is started (with onStart&#x0A;input). Otherwise, the choices displayed&#x0A;on the box will be selected." id="3" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip='Box behavior stops when a signal is&#x0A;received on this input, the &apos;other&apos; output is&#x0A;stimulated by &quot;onStop&quot;.' id="4" />
                                                <Output name="other" type="0" type_size="1" nature="1" inner="0" tooltip='When the user skipped the question, this output gives how it has been&#x0A;skipped. Gives also the number of the choice chosen in case of external&#x0A;choices.&#x0A;This output can be:&#x0A;- &quot;timeout&quot; if the user has not replied.&#x0A;- &quot;notUnderstood&quot; if the interaction with the speech recognition failed.&#x0A;- &quot;onStop&quot; if the onStop input has been activated.&#x0A;- &quot;wordRecognised&quot; if the exit command has been understood.&#x0A;- &quot;onTactileSensor&quot; if the user has tapped the tactile sensor of the robot.&#x0A;- an integer being the number of the external choice in the input list.' id="5" />
                                                <Output name="output_1" type="0" type_size="1" nature="2" inner="0" tooltip="This IO has been automatically added by box. Read box tooltip for more information." id="6" />
                                                <Output name="output_2" type="0" type_size="1" nature="2" inner="0" tooltip="This IO has been automatically added by box. Read box tooltip for more information." id="7" />
                                                <Output name="output_3" type="0" type_size="1" nature="2" inner="0" tooltip="This IO has been automatically added by box. Read box tooltip for more information." id="8" />
                                                <Parameter name="Minimum threshold to understand" inherits_from_parent="0" content_type="2" value="0.2" default_value="0.2" min="0" max="1" tooltip="Minimum threshold to get in order to be understood by the robot." id="9" />
                                                <Parameter name="Minimum threshold to be sure" inherits_from_parent="0" content_type="2" value="0.3" default_value="0.3" min="0" max="1" tooltip="Minimum threshold to get so that the robot would be sure about the user&apos;s&#x0A;answer. Below this threshold, the robot asks a confirmation about what has been&#x0A;understood." id="10" />
                                                <Parameter name="Speech recognition timeout when confirmation" inherits_from_parent="0" content_type="1" value="6" default_value="6" min="1" max="20" tooltip="When the robot asks if what he understood is correct, after this time, if there has been&#x0A;nothing heard, the speech recognition is stopped and the answer understood is&#x0A;considered as correct." id="11" />
                                                <Parameter name="Speech recognition timeout" inherits_from_parent="0" content_type="1" value="6" default_value="6" min="1" max="20" tooltip="After this time, if there has been nothing heard, the speech recognition is stopped&#x0A;and the question is repeated or is skipped." id="12" />
                                                <Parameter name="Maximum number of repetition when no reply" inherits_from_parent="0" content_type="1" value="3" default_value="3" min="1" max="20" tooltip='After this number of times when the user did not reply, the question is skipped, and&#x0A;the output other is stimulated with &quot;timeout&quot;.' id="13" />
                                                <Parameter name="Repeat validated choice" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="If this option is activated, the robot repeats the validated choice when it exits the box." id="14" />
                                                <Parameter name="Activate ears light" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="Activate ears light animation (turn, flash, etc...)." id="15" />
                                                <Parameter name="Activate eyes light" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="Activate eyes light animation (turn, flash, etc...)." id="16" />
                                                <Parameter name="Activate brain light" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="Activate brain light animation (turn, flash, etc...)." id="17" />
                                                <Parameter name="Tactile sensor menu timeout" inherits_from_parent="0" content_type="1" value="10" default_value="10" min="1" max="20" tooltip="After this time, if there has been no action made on the tactile sensor or the torso&#x0A;button, the choice currently selected is repeated or the question is skipped." id="18" />
                                                <Parameter name="Maximum number of repetition when failure" inherits_from_parent="0" content_type="1" value="5" default_value="5" min="1" max="20" tooltip='After this number of times when the robot did not understand the user, the question&#x0A;is skipped, and the output other is stimulated with &quot;notUnderstood&quot;.' id="19" />
                                                <Parameter name="Activate help when failure" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="When this parameter is activated, when the robot did not understand the user, he&#x0A;says some help enumerating available choices and attracting attention on the&#x0A;other available modalities (head tactile sensor)." id="20" />
                                                <Parameter name="Activate help command" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip='Enable the help command. So you can say &quot;help&quot; during the speech recognition&#x0A;and the robot will tell you more information.&#x0A;You will still be able to ask help by clicking the torso button.' id="21" />
                                                <Parameter name="Activate repeat command" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip='Activate the repeat command. So you can say &quot;repeat&quot; during the speech&#x0A;recognition and the robot will repeat the question.' id="22" />
                                                <Parameter name="Activate exit command" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip='Enable the exit command. So you can say &quot;exit&quot; during the speech recognition&#x0A;and the box will be stopped and the &apos;other&apos; output will be stimulated with&#x0A;&quot;wordRecognised&quot;.&#x0A;You will still be able to exit the box with&#x0A;the tactile sensor.' id="23" />
                                                <Parameter name="Sentences file" inherits_from_parent="0" content_type="4" value="/Aldebaran/choice_sentences_light.xml" default_value="/Aldebaran/choice_sentences_light.xml" tooltip="File containing all necessary sentences in each supported language." id="24" />
                                            </Box>
                                            <Box name="Localized Text" id="5" localization="8" tooltip="Send on the output the text associated with the robot&apos;s current voice language.&#x0A;You can display and edit the text associated with any language by&#x0A;selecting the language in the combobox.&#x0A;&#x0A;!!Warning!! The text sent on the output is NOT the displayed one but the one&#x0A;associated with the robot&apos;s current voice language." plugin="localizationbox_plugin" x="59" y="54">
                                                <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		try: # disable autoBind
			GeneratedClass.__init__(self, False)
		except TypeError: # if NAOqi < 1.14
			GeneratedClass.__init__( self )

		self.tts = ALProxy("ALTextToSpeech")
		self.sentences = {
			"Arabic" : "  ",
			"Czech" : " Máš rád čokoládu? ",
			"Danish" : " Kan du lide chokolade? ",
			"German" : " Mögen Sie Schokolade? ",
			"Greek" : "  ",
			"English" : " A yw eich apwyntiad yn ddeg ar bymtheg o\'r gloch ",
			"Spanish" : " ¿Te gusta el chocolate? ",
			"Finnish" : " Pidätkö suklaasta? ",
			"French" : " Aimes-tu le chocolat ? ",
			"Italian" : " Ti piace il cioccolato? ",
			"Japanese" : " チョコレートが好きですか ",
			"Korean" : " 당신은 초콜렛을 좋아합니까? ",
			"Dutch" : " Hou je van chocolade? ",
			"Norwegian" : "  ",
			"Polish" : " Lubisz czekoladę? ",
			"Brazilian" : " Você gosta de chocolate? ",
			"Portuguese" : " Gostas de chocolate? ",
			"Russian" : " Вы любите шоколад? ",
			"Swedish" : " Gillar du choklad? ",
			"Turkish" : " Çikolata sever misin? ",
			"Chinese" : "  "
		}

	def onInput_onStart(self):
		sDefaultLang = self.tts.getLanguage()
		self.onStopped(self.sentences[sDefaultLang])]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <![CDATA[]]>
</arabic>
                                                    <czech>
                                                        <![CDATA[Máš rád čokoládu?]]>
</czech>
                                                    <danish>
                                                        <![CDATA[Kan du lide chokolade?]]>
</danish>
                                                    <german>
                                                        <![CDATA[Mögen Sie Schokolade?]]>
</german>
                                                    <greek>
                                                        <![CDATA[]]>
</greek>
                                                    <english>
                                                        <![CDATA[A yw eich apwyntiad yn ddeg ar bymtheg o'r gloch]]>
</english>
                                                    <spanish>
                                                        <![CDATA[¿Te gusta el chocolate?]]>
</spanish>
                                                    <finnish>
                                                        <![CDATA[Pidätkö suklaasta?]]>
</finnish>
                                                    <french>
                                                        <![CDATA[Aimes-tu le chocolat ?]]>
</french>
                                                    <italian>
                                                        <![CDATA[Ti piace il cioccolato?]]>
</italian>
                                                    <japanese>
                                                        <![CDATA[チョコレートが好きですか]]>
</japanese>
                                                    <korean>
                                                        <![CDATA[당신은 초콜렛을 좋아합니까?]]>
</korean>
                                                    <dutch>
                                                        <![CDATA[Hou je van chocolade?]]>
</dutch>
                                                    <norwegian>
                                                        <![CDATA[]]>
</norwegian>
                                                    <polish>
                                                        <![CDATA[Lubisz czekoladę?]]>
</polish>
                                                    <brazilian>
                                                        <![CDATA[Você gosta de chocolate?]]>
</brazilian>
                                                    <portuguese>
                                                        <![CDATA[Gostas de chocolate?]]>
</portuguese>
                                                    <russian>
                                                        <![CDATA[Вы любите шоколад?]]>
</russian>
                                                    <swedish>
                                                        <![CDATA[Gillar du choklad?]]>
</swedish>
                                                    <turkish>
                                                        <![CDATA[Çikolata sever misin?]]>
</turkish>
                                                    <chinese>
                                                        <![CDATA[]]>
</chinese>
                                                    <language>5</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Data is sent on the output when this input is stimulated." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Data sent when asked." id="3" />
                                            </Box>
                                            <Link inputowner="1" indexofinput="2" outputowner="5" indexofoutput="3" />
                                            <Link inputowner="5" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="0" indexofinput="4" outputowner="1" indexofoutput="5" />
                                            <Link inputowner="0" indexofinput="5" outputowner="1" indexofoutput="6" />
                                            <Link inputowner="0" indexofinput="5" outputowner="1" indexofoutput="7" />
                                            <Link inputowner="0" indexofinput="6" outputowner="1" indexofoutput="8" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Speech" type="Lock" timeout="0" />
                            <Resource name="Speech recognition" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Choice (light) (4)" id="17" localization="8" tooltip="Launch speech recognition, and wait for one of a defined number of expected answers (written in the table of the box). the robot will prompt the speaker if he cannot understand and give suggestions as to available answers and other ways of selecting your choice. e.g. The tactile sensor on his head.&#x0A;&#x0A;Note that you must open this box to enter the question text and the available answers.&#x0A;&#x0A;This is a lighter version of Choice box from standard library which has no animation embedded.&#x0A;&#x0A;V1.1.0&#x0A;" x="319" y="756">
                            <bitmap>media/images/box/interaction/choice.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                            <Output name="answer" type="3" type_size="1" nature="1" inner="0" tooltip="Answer recognized." id="5" />
                            <Output name="output" type="3" type_size="1" nature="1" inner="0" tooltip="" id="6" />
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Choice" id="1" localization="8" tooltip="Launch the speech recognition waiting for a defined number of predicted answers (written in the table on the box). Available help&#x0A;from the robot which gives some possible answers and attracts attention on the other modalities to answer (head tactile sensor).&#x0A;&#x0A;You can edit a choice by left double-clicking on the line. You can add a choice by right clicking on a line and selecting &apos;Insert a&#x0A;row&apos;. You can delete a choice by right clicking on a line and selecting &apos;Remove a row&apos;. You can also write several alternative&#x0A;answers for the same choice by writing them on the line separated by the character &apos;/&apos;.&#x0A;Ex: apple pie / pie / apple&#x0A;Then if any of these answers (&apos;apple pie&apos;, &apos;pie&apos; or &apos;apple&apos;) are said, the corresponding output will be activated. Indeed, each output&#x0A;which name begins with &apos;output_&apos; correspond to the choice in the list placed just in front of the output.&#x0A;&#x0A;Moreover, you have advanced options appearing when you click on the blue cross. Then you can make the robot calculate the threshold&#x0A;average of choices with the 1/2/3 button. Actually, it will calculate recognition threshold of each alternative answer and put them from&#x0A;highest to smallest threshold. The threshold displayed in front of each choice then is the highest&apos;s." plugin="ui_choice_plugin" x="312" y="51">
                                                <bitmap>media/images/box/interaction/choice.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
# -*- coding: utf-8 -*-
# script of the Choice box v8.8
# @author Desktop Application team
# (c) 2011 Aldebaran Robotics

import os
import time
import random
import thread
import mutex
import xml.dom.minidom

class MyClass(GeneratedClass):
    def __init__(self):
        try: # disable autoBind
          GeneratedClass.__init__(self, False)
        except TypeError: # if NAOqi < 1.14
          GeneratedClass.__init__( self )

        # PROXIES INITIALIZATION
        self.tts = ALProxy("ALTextToSpeech")
        self.ttsStop = ALProxy("ALTextToSpeech", True) #Create another proxy as wait is blocking if audioout is remote
        self.memory = ALProxy("ALMemory")
        try:
            self.asr = ALProxy("ALSpeechRecognition")
            self.ad = ALProxy("ALAudioDevice")
            self.player = ALProxy("ALAudioPlayer")
            self.dcm = ALProxy( "DCM" )
        except:
            self.logger.warning("cannot find ALSpeechRecognition, choice box will run in simulation mode")
            self.asr = None
            self.ad = None
            self.player = None
            self.dcm = None

        self.leds = ALProxy( "ALLeds" )
        # VARIABLES INITIALIZATION
        self.aIdsTTS = []
        self.bSentencesInitialized = False
        self.bMustStop = False
        self.bIsRunning = False
        self.bGoOut = False
        self.nCountNoReply = 0
        self.nCountFailure = 0
        self.aFrameNumbers = {"end" : 1,
                              "headDown" : 10,
                              "bodyTalk" : 20,
                              "reco" : 30,
                              "headCheck" : 40,
                              "helpTactileSensor" : 50,
                              "notUnderstood" : 70}
        self.nFrameNumber = self.aFrameNumbers["end"]
        self.bInConfirmation = False
        self.bVocabularyLoaded = False
        self.bRecoIsHearingOrAnalysing = False
        self.bRecoIsWaitingForVoice = False
        self.bHasAlreadyHearingEyes = False
        self.bInTactileSensorMenu = False
        self.bExternChoices = False
        self.bBrainAnimPaused = False
        self.rTimeLastChoiceSaid = -1.
        self.bIsSayingChoice = False
        self.nIndexChoice = 0
        self.sRecoInterruption = "" # = "wordRecognised" or "timeout" or "onStop" or "onTactileSensor"
        self.sPreviousAnswer = ""
        self.rTimeWhenActionMadeInTactileMenu = -1.
        # variables used for the tactile sensor
        self.nFront = 0
        self.nMiddle = 0
        self.nRear = 0
        self.bSeqStarted = False
        self.bIsStoringParam = False
        self.bPressed = False
        self.mutexProcessCurrentState = mutex.mutex()
        self.mutexTactilTouched = mutex.mutex()
        self.mutexCheckIfSeqsCorrespondingLeft = mutex.mutex()
        self.bSeqStarted = False
        # assuming that every sequence is after [0, 0, 0]
        # and then start with one tactil sensor activated
        # timeout must be either a number (int or float) not equal to 0 or an array of two numbers not equal to 0, a negative one and a positive one
        # a negative timeout means a minimum time that has to ellapse before the next step
        # a positive timeout means a maximum time before the next step must show up
        self.aSeqs = [{"name" : "Tap", "statesAndTimeout" : [ "1+", 0.35, "2+", 0.45, "0" ]},
                      {"name" : "TapFront", "statesAndTimeout" : [ "F", 1, "0" ]},
                      {"name" : "LongFront", "statesAndTimeout" : [ "F", -1, "F" ]},
                      {"name" : "TapMiddle", "statesAndTimeout" : [ "M", 1, "0" ]},
                      {"name" : "LongMiddle", "statesAndTimeout" : [ "M", -1, "M" ]},
                      {"name" : "TapRear", "statesAndTimeout" : [ "R", 1, "0" ]},
                      {"name" : "LongRear", "statesAndTimeout" : [ "R", -1, "R" ]},
                      {"name" : "CalmDown", "statesAndTimeout" : [ "1+", 0.5, "2+", -1, "2+" ]}]
        # sequences initialization
        aSeqsTemp = []
        for seq in self.aSeqs:
            try: # ensure that the sequence has at least a name and states and timeout defined
                seq["name"]
                seq["statesAndTimeout"]
                aSeqsTemp.append(seq)
            except:
                pass
        self.aSeqs = aSeqsTemp
        for seq in self.aSeqs:
            states = range( len( seq["statesAndTimeout"][0:len(seq["statesAndTimeout"]):2] ) )
            i = 0
            for state in seq["statesAndTimeout"][0:len(seq["statesAndTimeout"]):2]:
                states[i] = self.convertToArrayOfPossibleStates(state)
                i += 1
            seq["statesAndTimeout"][0:len(seq["statesAndTimeout"]):2] = states
        self.aDetectedSeqs = []
        self.aDetectedSeqs.extend(self.aSeqs)
        # end - variables used for the tactile sensor
        self.aChoices = []
        self.aChoiceIndexes = []
        # parameters which can be changed from the parameters edition window
        self.sQuestion = ""
        self.nTimeoutReco = 6
        self.nTimeoutRecoConfirmation = 6
        self.nTimeoutTactile = 10
        self.nMaxCountNoReply = 3
        self.nMaxCountFailure = 5
        self.arUnderstoodThreshold = [0.0, 1.0] # range of self.rUnderstoodThreshold
        self.arConfirmationThreshold = [0.0, 1.0] # range of self.rConfirmationThreshold (must be higher than self.arUnderstoodThreshold)
        self.rUnderstoodThreshold = 0.2
        self.rConfirmationThreshold = 0.4
        self.bActivateEyesLight = True
        self.bActivateEarsLight = True
        self.bActivateBrainLight = True
        self.bActivateHelpWhenFailure = True
        self.bRepeatValidatedChoice = True
        self.bActivateDefaultChoiceHelp = True
        self.bActivateDefaultChoiceRepeat = True
        self.bActivateDefaultChoiceExit = True
        self.BIND_PYTHON(self.getName(), "onTactilTouched")
        self.BIND_PYTHON(self.getName(), "onWordRecognized")
        self.BIND_PYTHON(self.getName(), "onSpeechDetected")


# FUNCTIONS ===============================================================================================

    def onLoad(self):
        # initialize sentences for each language
        if( not self.bSentencesInitialized ):
            self.initializeSentences()
            self.bSentencesInitialized = True

# XML PARSER FOR SENTENCES INITIALIZATION
    def initializeSentences(self):
        "Initialize necessary sentences in each language."
        framemanager = ALProxy("ALFrameManager")
        filename = framemanager.getBehaviorPath(self.behaviorId) + self.tryGetParameter( "Sentences file", "/Aldebaran/choice_sentences.xml" )
        if not self.fileExists(filename):
            raise RuntimeError("File " + filename + " could not be found. Please update your Choice box with a newer one from Choregraphe")
        try:
            doc = self.getFileContents( filename )
            dom = xml.dom.minidom.parseString( doc )
        except Exception as e:
            raise Exception( "The " + filename + " file is not in the right format. Check the special characters and that the syntax is correct.\n" + str(e) )
        try:
            tag = "sentences"
            mainBlock = dom.getElementsByTagName( tag )[0]
            tag = "translation"
            aTranslations = mainBlock.getElementsByTagName( tag )
            self.aAllWords = {}
            self.aAllSentences = {}
            for sTranslation in aTranslations:
                sLanguage = sTranslation.getAttribute("language")
                tag = "speechReco"
                blockSpeechReco = sTranslation.getElementsByTagName( tag )[0]
                # variable used for the speech recognition
                self.aAllWords[sLanguage] = {}
                aKinds = ["negative",
                          "positive",
                          "help",
                          "exit",
                          "repeat"]
                for sKind in aKinds:
                    tag = sKind
                    blockWordsForThisKind = blockSpeechReco.getElementsByTagName( sKind )[0]
                    self.aAllWords[sLanguage][sKind] = blockWordsForThisKind.getAttribute( "text" ).encode("utf-8").split("/")
                # end - variable used for the speech recognition
                tag = "tts"
                blockTTS = sTranslation.getElementsByTagName( tag )[0]
                # variable used for the Text-To-Speech
                self.aAllSentences[sLanguage] = {}
                aKinds = ["confirmation",
                          "enumMarks",
                          "helpEnumChoices",
                          "helpEnumDefault",
                          "helpTactile",
                          "notUnderstood",
                          "noQuestion",
                          "notUnderstoodAnims"]
                for sKind in aKinds:
                    tag = sKind
                    blockSentencesForThisKind = blockTTS.getElementsByTagName( sKind )[0]
                    self.aAllSentences[sLanguage][sKind] = blockSentencesForThisKind.getAttribute( "text" ).encode("utf-8").split("/")
                # end - variable used for the Text-To-Speech
        except Exception as e:
            raise Exception( "The " + filename + " file is not in the right format. Check that the '" + tag + "' tag is defined and with the right format.\n" + str(e) )

        # choices
        # !!! don't remove any comments from this variable !!!
        # (they are here to make the plugin work)
        self.aListAllChoices = {"Arabic": ["نعم", "لا", "", ""], "Brazilian": ["sim", "não", "", ""], "Chinese": ["是", "不是", "", ""], "Czech": ["ano", "ne", "", ""], "Danish": ["ja", "nej", "", ""], "Dutch": ["ja", "nee", "", ""], "English": ["", "Na", "Le", ""], "Finnish": ["kyllä", "ei", "", ""], "French": ["oui", "non", "", ""], "German": ["ja", "nein", "", ""], "Greek": ["ναί", "κανένα", "", ""], "Italian": ["sì", "no", "", ""], "Japanese": ["はい", "いいえ", "", ""], "Korean": ["예", "아니", "", ""], "Norwegian": ["ja", "Nei", "", ""], "Polish": ["tak", "nie", "", ""], "Portuguese": ["sim", "não", "", ""], "Russian": ["да", "нет", "", ""], "Spanish": ["si", "no", "", ""], "Swedish": ["ja", "ingen", "", ""], "Turkish": ["evet", "hayır", "", ""]
                               }
        # end - choices

# INPUTS ACTIVATION PROCESSING ------------------------------------------------------------------------------
    def onInput_onStart(self, question=None):
        "Initialize variables and start box behaviour."
        self.logger.debug( "Input onStart stimulated." )
        if( self.bIsRunning): # to avoid starting the process twice
            return
        self.bIsRunning = True
        if(self.asr != None):
            self.asr.setVisualExpression( False )
        language = self.tts.getLanguage()
        if(self.asr != None):
            self.asr.setLanguage( language )
        try:
            self.aAllWords[language]
            self.aAllSentences[language]
        except:
            raise Exception( "The current language is not supported by this Choice box. It is probably deprecated. Try to use the one supplied in Choregraphe library instead." )
        self.asNegativeWords = self.aAllWords[language]["negative"]
        self.asPositiveWords = self.aAllWords[language]["positive"]
        self.asHelpWords = self.aAllWords[language]["help"]
        self.asExitWords = self.aAllWords[language]["exit"]
        self.asRepeatWords = self.aAllWords[language]["repeat"]
        self.bGoOut = False
        self.bVocabularyLoaded = False
        self.bRecoIsHearingOrAnalysing = False
        self.bRecoIsWaitingForVoice = False
        self.bHasAlreadyHearingEyes = False
        self.sRecoInterruption = ""
        self.sPreviousAnswer = ""
        self.bMustStop = False
        self.nCountNoReply = 0
        self.nCountFailure = 0
        self.nFrameNumber = self.aFrameNumbers["end"]
        self.beginTime = time.time()
        self.bInConfirmation = False
        self.bInTactileSensorMenu = False
        self.bBrainAnimPaused = False
        self.bPressed = False
        self.rTimeWhenActionMadeInTactileMenu = -1.
        self.nFront = 0
        self.nMiddle = 0
        self.nRear = 0
        self.bSeqStarted = False
        self.bIsStoringParam = False
        self.rUnderstoodThreshold = self.tryGetParameter( "Minimum threshold to understand", 0.2 )
        self.rConfirmationThreshold = self.tryGetParameter( "Minimum threshold to be sure", 0.4 )
        self.nTimeoutReco = self.tryGetParameter( "Speech recognition timeout", 6 )
        self.nTimeoutRecoConfirmation = self.tryGetParameter( "Speech recognition timeout when confirmation", 6 )
        self.nTimeoutTactile = self.tryGetParameter( "Tactile sensor menu timeout", 10 )
        self.nMaxCountNoReply = self.tryGetParameter( "Maximum number of repetition when no reply", 3 )
        self.nMaxCountFailure = self.tryGetParameter( "Maximum number of repetition when failure", 5 )
        self.bActivateEyesLight = self.tryGetParameter( "Activate eyes light", True )
        self.bActivateEarsLight = self.tryGetParameter( "Activate ears light", True )
        self.bActivateBrainLight = self.tryGetParameter( "Activate brain light", True )
        self.bActivateHelpWhenFailure = self.tryGetParameter( "Activate help when failure", True )
        self.bRepeatValidatedChoice = self.tryGetParameter( "Repeat validated choice", True )
        self.bActivateDefaultChoiceHelp = self.tryGetParameter( "Activate help command", True )
        self.bActivateDefaultChoiceRepeat = self.tryGetParameter( "Activate repeat command", True )
        self.bActivateDefaultChoiceExit = self.tryGetParameter( "Activate exit command", True )
        self.aDefaultChoices = []
        if (self.bActivateDefaultChoiceHelp):
            self.aDefaultChoices.append( self.asHelpWords )
        if (self.bActivateDefaultChoiceRepeat):
            self.aDefaultChoices.append( self.asRepeatWords )
        if (self.bActivateDefaultChoiceExit):
            self.aDefaultChoices.append( self.asExitWords )
        if( question == None ):
            question = ""
        self.initQuestionAndChoices( question )
        if( len( self.aChoices ) > len( self.aDefaultChoices ) ): # if there is at least one choice (not a default one)
            self.nIndexChoice = len( self.aDefaultChoices )
        else: # if there are only default words
            self.nIndexChoice = 0
        self.bGoOut = False
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFFFFFF, 0.1 )
        # initialize tactile sensor handler
        self.initSeqDetected()
        # subscribe to tactile sensors extractors (launch tactile sensor handler)
        self.memory.subscribeToEvent( "FrontTactilTouched", self.getName(), "onTactilTouched" )
        self.memory.subscribeToEvent( "MiddleTactilTouched", self.getName(), "onTactilTouched" )
        self.memory.subscribeToEvent( "RearTactilTouched", self.getName(), "onTactilTouched" )
        thread.start_new_thread( self.loopLedsBrainTwinkle, () )
        while( not self.bGoOut ):
            self.questionRecognitionReaction()
        if( self.bInTactileSensorMenu ):
            self.nCountNoReply = 0
            if( self.nFrameNumber != self.aFrameNumbers["headDown"] ):
                self.nFrameNumber = self.aFrameNumbers["headDown"]
                try:
                    self.getTimeline().goTo(self.nFrameNumber)
                except: # if NAOqi < 1.14
                    try:
                        self.gotoAndStop(self.nFrameNumber)
                    except:
                        pass
            self.loopLedsBrainTurn()
        else:
            self.bIsRunning = False

    def onInput_choicesList(self, p):
        "Set choices list."
        self.logger.debug( "Input choicesList stimulated." )
        if( not self.bIsRunning ):
            self.bExternChoices = True
            language = "English"
            if(self.asr != None):
                language =  self.asr.getLanguage()
            self.asNegativeWords = self.aAllWords[language]["negative"]
            self.asPositiveWords = self.aAllWords[language]["positive"]
            self.asHelpWords = self.aAllWords[language]["help"]
            self.asExitWords = self.aAllWords[language]["exit"]
            self.asRepeatWords = self.aAllWords[language]["repeat"]
            self.bActivateDefaultChoiceHelp = self.tryGetParameter( "Activate help command", True )
            self.bActivateDefaultChoiceRepeat = self.tryGetParameter( "Activate repeat command", True )
            self.bActivateDefaultChoiceExit = self.tryGetParameter( "Activate exit command", True )
            self.aDefaultChoices = []
            if (self.bActivateDefaultChoiceHelp):
                self.aDefaultChoices.append( self.asHelpWords )
            if (self.bActivateDefaultChoiceRepeat):
                self.aDefaultChoices.append( self.asRepeatWords )
            if (self.bActivateDefaultChoiceExit):
                self.aDefaultChoices.append( self.asExitWords )
            self.aChoices = []
            self.aChoiceIndexes = []
            self.aChoices.extend( self.aDefaultChoices )
            index = 0
            for choice in p:
                if( self.isString(choice) ):
                    choice = choice.strip(" \t,;.\n") # remove space or tabs at beginning or end of a choice
                    if( choice != "" ):
                        choice = [ choice ]
                    else:
                        choice = []
                elif( self.isArray(choice) ):
                    if( choice != [] ):
                        for i in range( len( choice ) ):
                            if( self.isString(choice[i]) ):
                                choice[i] = choice[i].strip(" \t,;.\n") # remove space or tabs at beginning or end of a choice
                                if( len( choice[i] ) < 1 ):
                                    del choice[i]
                                    i -= 1 # to parse the good one next loop
                            else:
                                raise Exception( "Error in choices input syntax:\nIt must be an array of choices and each choice can be either a string or an array of strings (several possibilities for one choice)\nEx: ['choice1',['choice2a','choice2b']]\nbut: " + str(p) + " found" )
                else:
                    raise Exception( "Error in choices input syntax:\nIt must be an array of choices and each choice can be either a string or an array of strings (several possibilities for one choice)\nEx: ['choice1',['choice2a','choice2b']]\nbut: " + str(p) + " found" )
                if( len( choice ) > 0 ):
                    for sWord in choice:
                        for aDefaultChoice in self.aDefaultChoices:
                            if( sWord in aDefaultChoice ):
                                raise Exception( "Error in input choices list: You chose a word which is already used for default choices:\n" + str(sWord) + " is used for the default choice: " + str(aDefaultChoice[0]) )
                    self.aChoices.append( choice )
                    self.aChoiceIndexes.append( index )
                index += 1

    def onInput_onStop(self):
        "Stop box behaviour."
        self.logger.debug( "Input onStop stimulated." )
        if( self.bIsRunning ):
            self.goOut( self.asExitWords[0], "onStop" )
            self.sRecoInterruption = "onStop"
        else:
            self.onUnload()

# GENERAL FUNCTIONS ------------------------------------------------------------------------------------------

    def isString(self, strVariable):
        try:
            if( type( strVariable ) == type( "some string" ) ):
                return True
        except:
            pass
        return False

    def isArray(self, aVariable):
        try:
            if( type( aVariable ) == type( ["some array"] ) ):
                return True
        except:
            pass
        return False

    def fileExists(self, strPathFilename ):
        try:
            file = open( strPathFilename, 'r' )
            if( file ):
                file.close()
                return True
        except (IOError, os.error), err:
            pass
        return False

    def getFileContents(self, sFilename ):
        "read a file and return it's contents, or '' if not found, empty, ..."
        try:
            fileContent = open( sFilename )
            aBuf = fileContent.read()
            fileContent.close()
        except:
            try:
                fileContent.close()
            except:
                pass
            return ""
        return aBuf

    def getBrainLedName(self, nNumLed):
        "Get the name of the DCM led device from its number"
        "0 => front left; 1 => next in clock wise; until 11"
        numLed = nNumLed%12
        if( numLed <= 1 ):
            return "Head/Led/Front/Right/%d/Actuator/Value" % (1-numLed)
        elif( numLed >= 10 ):
            return "Head/Led/Front/Left/%d/Actuator/Value" % (numLed-10)
        elif( numLed <= 2 ):
            return "Head/Led/Middle/Right/%d/Actuator/Value" % (2-numLed)
        elif( numLed >= 9 ):
            return "Head/Led/Middle/Left/%d/Actuator/Value" % (numLed-9)
        elif( numLed <= 5 ):
            return "Head/Led/Rear/Right/%d/Actuator/Value" % (numLed-3)
        else:
            return "Head/Led/Rear/Left/%d/Actuator/Value" % (8-numLed)

    def skipTTS(self):
        for idtts in self.aIdsTTS:
            try:
                self.ttsStop.stop(idtts)
            except:
                self.logger.debug( "Warning: The Text-To-Speech could not have been stopped." )

    def tryGetParameter(self, sParameterName, defaultValue):
        try:
            return self.getParameter( sParameterName )
        except:
            return defaultValue

# QUESTION AND CHOICES INITIALIZATION ----------------------------------------------------------------------

    def initQuestionAndChoices(self, p):
        "Initialize the question and the choices."
        # question processing
        if( self.isString(p) ):
            self.sQuestion = p
        else:
            raise Exception( "Error in question input syntax:\nQuestion text\nexpected for example, but:\n" + str(p[0]) + "\nfound" )
        # choices processing
        if( not self.bExternChoices ):
            self.aChoices = []
            self.aChoiceIndexes = []
            self.aChoices.extend( self.aDefaultChoices )
            index = 0
            listChoices = self.aListAllChoices[self.tts.getLanguage()]
            for choice in listChoices:
                aChoice = choice.split( "/" )
                if( aChoice != [] ):
                    for i in range( len( aChoice ) ):
                        aChoice[i] = aChoice[i].strip(" \t,;.\n") # remove space or tabs at beginning or end of a choice
                        if( len( aChoice[i] ) < 1 ):
                            del aChoice[i]
                            i -= 1 # to parse the good one next loop
                if( len( aChoice ) > 0 ):
                    # check if there is a word which is already used for the default choices
                    for sWord in aChoice:
                        for aDefaultChoice in self.aDefaultChoices:
                            if( sWord in aDefaultChoice ):
                                raise Exception( "Error in choices list: You chose a word which is already used for default choices:\n" + str(sWord) + " is used for the default choice: " + str(aDefaultChoice[0]) )
                    # append the choice to the list if everything worked well
                    self.aChoices.append( aChoice )
                    self.aChoiceIndexes.append( index )
                index += 1
        # check that there is at least one choice (a default one or not)
        if( len( self.aChoices ) < 1 ):
            raise Exception( "Error in choices list: It is empty. There is no default choice nor choice entered." )

# QUESTION-RECOGNITION-REACTION -----------------------------------------------------------------------------

    def questionRecognitionReaction(self):
        "Ask question, launch speech recognition and process answer."
        self.ttsQuestionAndRecoInit()
        if( not self.bMustStop ):
            # stop movement animation
            if( self.nFrameNumber != self.aFrameNumbers["reco"] ):
                self.nFrameNumber = self.aFrameNumbers["reco"]
                try:
                    self.getTimeline().goTo(self.nFrameNumber)
                except: # if NAOqi < 1.14
                    try:
                        self.gotoAndStop(self.nFrameNumber)
                    except:
                        pass
            # start speech recognition
            self.logger.debug( "Speech recognition started." )
            self.memory.subscribeToEvent( "WordRecognized", self.getName(), "onWordRecognized" )
            self.bRecoIsWaitingForVoice = True
            self.memory.subscribeToEvent( "SpeechDetected", self.getName(), "onSpeechDetected" )
        # leds during the recognition
        self.loopLedsReco()
        # process the reco loop break
        self.processRecoInterruption()

    def ttsQuestionAndRecoInit(self):
        "Ask question and initialize the speech recognition during the question to gain time in the interaction."
        if( not self.bInConfirmation ):
            # launch TTS
            idTTS = -1
            if( self.sQuestion != ""):
                idTTS = self.tts.post.say( self.sQuestion )
                self.aIdsTTS.append( idTTS )
                self.logger.debug( "Robot says: " + str(self.sQuestion) )
                # launch TTS movement animation
                if( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ):
                    self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
            # prepare speech recognition
            if(self.asr != None):
                self.asr.setLanguage( self.tts.getLanguage() )
            if( not self.bVocabularyLoaded ):
                aWordsRecognised = []
                for i in range( len( self.aChoices ) ):
                    if( self.aChoices[i] != [] ):
                        aWordsRecognised.extend( self.aChoices[i] )
                sWordsRecognised = "You can say: "
                if( len( aWordsRecognised ) > 1 ):
                    for i in range( len( aWordsRecognised ) - 1 ):
                        sWordsRecognised += "'" + aWordsRecognised[i] + "', "
                if( len( aWordsRecognised ) > 0 ):
                    sWordsRecognised += "'" + aWordsRecognised[len( aWordsRecognised ) - 1] + "'"
                sWordsRecognised += "."
                self.logger.debug( sWordsRecognised )
                if(self.asr != None):
                    self.asr.setVocabulary( aWordsRecognised, False )
                self.bVocabularyLoaded = True
        else:
            # launch TTS
            sentence = self.aAllSentences[self.tts.getLanguage()]["confirmation"][0]
            idTTS = -1
            sentenceToSay = sentence % self.sPreviousAnswer
            if( sentenceToSay != ""):
                idTTS = self.tts.post.say( sentenceToSay )
                self.aIdsTTS.append( idTTS )
                self.logger.debug( "Robot says: " + str(sentenceToSay) )
                # launch TTS movement animation
                if( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ):
                    self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
            # prepare speech recognition
            aWordsRecognised = []
            aWordsRecognised.extend( self.asNegativeWords )
            aWordsRecognised.extend( self.asPositiveWords )
            sWordsRecognised = "You can say: "
            if( len( aWordsRecognised ) > 1 ):
                for i in range( len( aWordsRecognised ) - 1 ):
                    sWordsRecognised += "'" + aWordsRecognised[i] + "', "
            if( len( aWordsRecognised ) > 0 ):
                sWordsRecognised += "'" + aWordsRecognised[len( aWordsRecognised ) - 1] + "'"
            sWordsRecognised += "."
            self.logger.debug( sWordsRecognised )
            if(self.asr != None):
                self.asr.setVocabulary( aWordsRecognised, False )
            self.bVocabularyLoaded = False
        # wait for the end of the TTS
        if( idTTS != -1 ):
            try:
                self.tts.wait( idTTS, 0 )
            except:
                self.logger.debug( "Warning: Could not wait the TTS." )

    def processRecoInterruption(self):
        "Process speech recognition interruption (timeout, action on tactile sensor, word said, etc...)"
        # wait for the end of the reaction (help, not understood, etc...)
        while( self.sRecoInterruption == "" ):
            time.sleep( 0.2 )
        self.logger.debug( "The speech recognition has been interrupted because of: " + str(self.sRecoInterruption) + "." )
        if( self.sRecoInterruption == "timeout" ): # if recognition interrupted by timeout
            try:
                # stop recognition
                self.memory.unsubscribeToEvent( "WordRecognized", self.getName() )
                self.bRecoIsWaitingForVoice = False
                self.bRecoIsHearingOrAnalysing = False
                self.logger.debug( "Speech recognition stopped." )
                self.memory.unsubscribeToEvent( "SpeechDetected", self.getName() )
            except:
                pass
            if( self.bInConfirmation ): # if it was a confirmation question
                # leds noticing that the robot confirm its guessing
                thread.start_new_thread( self.ledsUnderstood, (True, False) )
                # if nothing has been said, we assume that the user agree
                self.bInConfirmation = False
                if( self.sPreviousAnswer in self.asHelpWords ): # if help asked
                    self.helpWhenAsked()
                elif( self.sPreviousAnswer in self.asRepeatWords ): # if repeat asked
                    self.repeatWhenNoQuestion()
                    # repeat the question
                else: # if not repeat nor help asked
                    self.goOut( self.sPreviousAnswer, "wordRecognised" )
            else:
                # reinitialize leds
                self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
                self.nCountNoReply += 1
                if( self.nCountNoReply >= self.nMaxCountNoReply ):
                    self.goOut( self.asExitWords[0], "timeout" )
        else:
            self.nCountNoReply = 0
            if( self.sRecoInterruption in [ "onStop" ] ):
                self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        self.sRecoInterruption = ""

    def repeatWhenNoQuestion(self):
        "Robot's reaction when it is asked to repeat the question when there is no question."
        if( self.sQuestion == "" ):
            sentenceNoQuestion = self.aAllSentences[self.tts.getLanguage()]["noQuestion"][0]
            sentenceNoQuestion += self.enumerateChoices( True ) # True to ask that the introduction is played
            if( len( self.aChoices ) - len( self.aDefaultChoices ) == 0 ): # if there is no choice
                sentenceNoQuestion += self.enumerateDefaultChoices( True ) # True to ask that the introduction is played
            # launch TTS
            idTTS = -1
            if( sentenceNoQuestion != ""):
                if( self.bInTactileSensorMenu ):
                    idTTS = self.tts.post.say( sentenceNoQuestion + "\\Pau=300\\" )
                else:
                    idTTS = self.tts.post.say( sentenceNoQuestion )
                self.aIdsTTS.append( idTTS )
                self.logger.debug( "Robot says: " + str(sentenceNoQuestion) )
                if( not self.bInTactileSensorMenu ):
                    # launch TTS movement animation
                    if( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ):
                        self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                        try:
                            self.getTimeline().goTo(self.nFrameNumber)
                        except: # if NAOqi < 1.14
                            try:
                                self.gotoAndStop(self.nFrameNumber)
                            except:
                                pass
            # wait for the end of the TTS
            if( idTTS != -1 ):
                try:
                    self.tts.wait( idTTS, 0 )
                except:
                    self.logger.debug( "Warning: Could not wait the TTS." )

# RECO OUTPUT PROCESSING --------------------------------------------------------------------------------------

    def onWordRecognized(self, pDataName, pValue, pMessage):
        "Handler for when a word is recognised by the speech recognition system."
        aState = pValue
        self.logger.debug( "The word '" + str(aState[0]) + "' has been recognised with a threshold of " + str(aState[1]) + "." )
        # interrupt loops:
            # - stop reco
            # - stop leds
            # - stop asking the question on and on
        try:
            self.memory.unsubscribeToEvent( "WordRecognized", self.getName() )
            self.logger.debug( "Speech recognition stopped." )
            self.memory.unsubscribeToEvent( "SpeechDetected", self.getName() )
        except:
            pass
        self.bRecoIsHearingOrAnalysing = False
        self.bRecoIsWaitingForVoice = False
        if( aState[0] != "" ):
            if( aState[1] >= self.rUnderstoodThreshold ):
                if( self.rUnderstoodThreshold <= self.arUnderstoodThreshold[1] - 0.02 ):
                    self.rUnderstoodThreshold += 0.02
                else:
                    self.rUnderstoodThreshold = self.arUnderstoodThreshold[1]
                if( self.bInConfirmation ):
                    if( aState[0] in self.asNegativeWords ):
                        thread.start_new_thread( self.ledsNegative, () )
                    else:
                        thread.start_new_thread( self.ledsUnderstood, (True, False) )
                else:
                    thread.start_new_thread( self.ledsUnderstood, (True, False) )
                self.reactionWordUnderstood( aState )
            else:
                if( self.rUnderstoodThreshold >= self.arUnderstoodThreshold[0] + 0.05 ):
                    self.rUnderstoodThreshold -= 0.05
                else:
                    self.rUnderstoodThreshold = self.arUnderstoodThreshold[0]
                aCurrentChoice = ""
                for choice in self.aChoices:
                    if( aCurrentChoice == "" ):
                        if( aState[0] in choice ):
                            aCurrentChoice = choice
                if( self.sPreviousAnswer in aCurrentChoice ): # if answer in the same choice as previously
                    # then ask confirmation
                    aState[1] = self.rConfirmationThreshold - 0.01
                    thread.start_new_thread( self.ledsUnderstood, (True, False) )
                    self.reactionWordUnderstood( aState )
                else:
                    # else not understood
                    if( self.bInConfirmation ):
                        thread.start_new_thread( self.ledsUnderstood, (True, False) )
                    else:
                        self.sPreviousAnswer = aState[0]
                        thread.start_new_thread( self.ledsNotUnderstood, () )
                    self.reactionNothingUnderstood()
        else:
            if( self.bInConfirmation ):
                thread.start_new_thread( self.ledsUnderstood, (True, False) )
            else:
                thread.start_new_thread( self.ledsNotUnderstood, () )
            self.reactionNothingUnderstood()
        if( pMessage == "" ):
            self.sRecoInterruption = "wordRecognised"
        else:
            self.sRecoInterruption = pMessage

    def onSpeechDetected(self, pDataName, pValue, pMessage):
        "Handler for when something has been heard by the speech recognition system."
        aState = pValue
        if( aState == 1):
            if( self.bRecoIsWaitingForVoice ):
                # make eyes leds switch from an animation to an other
                self.bRecoIsHearingOrAnalysing = True
                self.bRecoIsWaitingForVoice = False
                try:
                    self.timeToReply(time.time() - self.beginTime)
                except:
                    pass

    def reactionWordUnderstood(self, word):
        "Reaction depending on the word recognised (help, repeat, word in choices, etc...) and its recognition confidence."
        if( self.bInConfirmation ):
            self.bInConfirmation = False
            if( word[0] in self.asNegativeWords ):
                # update number of failures
                self.nCountFailure += 1
                if( self.sPreviousAnswer in self.asHelpWords ):
                    if( self.nCountFailure >= self.nMaxCountFailure ): # if maximum number of failures
                        # skip the question
                        self.goOut( self.asExitWords[0], "notUnderstood" )
                else:
                    self.helpAfterFailure()
            else:
                if( (self.sPreviousAnswer in self.asHelpWords) or (word[0] in self.asHelpWords) ):
                    self.helpWhenAsked()
                elif( self.sPreviousAnswer in self.asRepeatWords or (word[0] in self.asRepeatWords) ):
                    self.repeatWhenNoQuestion()
                    # repeat the question
                else:
                    self.goOut( self.sPreviousAnswer, "wordRecognised" )
                self.sPreviousAnswer = ""
        else:
            self.sPreviousAnswer = word[0]
            if( word[1] >= self.rConfirmationThreshold ):
                if( self.rConfirmationThreshold <= self.arConfirmationThreshold[1] - 0.02 ):
                    self.rConfirmationThreshold += 0.02
                else:
                    self.rConfirmationThreshold = self.arConfirmationThreshold[1]
                if( self.sPreviousAnswer in self.asHelpWords ):
                    self.helpWhenAsked()
                elif( self.sPreviousAnswer in self.asRepeatWords ):
                    self.repeatWhenNoQuestion()
                    # repeat the question
                else:
                    self.goOut( self.sPreviousAnswer, "wordRecognised" )
                self.sPreviousAnswer = ""
            else:
                if( self.rConfirmationThreshold >= self.arConfirmationThreshold[0] + 0.05 ):
                    self.rConfirmationThreshold -= 0.05
                else:
                    self.rConfirmationThreshold = self.arConfirmationThreshold[0]
                self.bInConfirmation = True

    def reactionNothingUnderstood(self):
        "Reaction when nothing has been understood or without an enough confidence."
        if( self.bInConfirmation ):
            # if the robot did not understand, we assume that the user agree
            self.bInConfirmation = False
            if( self.sPreviousAnswer in self.asHelpWords ): # if help asked
                self.helpWhenAsked()
            elif( self.sPreviousAnswer in self.asRepeatWords ): # if repeat asked
                self.repeatWhenNoQuestion()
                # repeat the question
            else: # if not repeat nor help asked
                self.goOut( self.sPreviousAnswer, "wordRecognised" )
        else:
            # update number of failures
            self.nCountFailure += 1
            if( self.nCountFailure <= 1 ): # if first failure
                sentence = self.aAllSentences[self.tts.getLanguage()]["notUnderstood"][0]
            else: # if second failure or more
                sentenceNotUnderstoodAnims = self.aAllSentences[self.tts.getLanguage()]["notUnderstoodAnims"]
                index = random.randint( 0, len( sentenceNotUnderstoodAnims ) - 1 )
                sentence = sentenceNotUnderstoodAnims[index]
                if( self.nFrameNumber != self.aFrameNumbers["notUnderstood"] + 10*index ):
                    self.nFrameNumber = self.aFrameNumbers["notUnderstood"] + 10*index
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
            self.helpAfterFailure( sentence )

# HELP ------------------------------------------------------------------------------------------------------

    def enumerateChoices(self, bIntroToSay):
        "Enumerate choices (only the first word of each choice is taken into account)."
        sentenceHelpEnumChoices = self.aAllSentences[self.tts.getLanguage()]["helpEnumChoices"]
        sentenceHelpEnumMarks = self.aAllSentences[self.tts.getLanguage()]["enumMarks"]
        enumWords = ""
        maxNbEnumChoices = 3
        indexes = []
        for i in range( min(maxNbEnumChoices, len( self.aChoices ) - len( self.aDefaultChoices )) ):
            if( len( self.aChoices ) - len( self.aDefaultChoices ) <= maxNbEnumChoices ):
                index = len( self.aDefaultChoices ) + i
            else:
                index = random.randint( len( self.aDefaultChoices ), len( self.aChoices ) - 1 )
                while( index in indexes ):
                    index = random.randint( len( self.aDefaultChoices ), len( self.aChoices ) - 1 )
            indexes.append( index )
            if( len( indexes ) != 1 ): # if it is not the first choice
                if( len( indexes ) != min(maxNbEnumChoices, len( self.aChoices ) - len( self.aDefaultChoices )) ): # if it is not the last choice
                    enumWords += sentenceHelpEnumMarks[0]
                else:
                    enumWords += sentenceHelpEnumMarks[1]
            enumWords += self.aChoices[index][0]
        sentenceTemplate = sentenceHelpEnumChoices[2]
        if( len( self.aChoices ) - len( self.aDefaultChoices ) <= maxNbEnumChoices ): # if there are 3 or less choices
            sentenceTemplate = sentenceHelpEnumChoices[1]
        if( not bIntroToSay ):
            sentenceTemplate = sentenceHelpEnumChoices[3]
        if( len( self.aChoices ) - len( self.aDefaultChoices ) == 0 ): # if there is no choice
            sentence = sentenceHelpEnumChoices[0]
        else:
            sentence = sentenceTemplate % enumWords
        return sentence

    def enumerateDefaultChoices(self, bIntroToSay):
        "Enumerate default choices (only the first word of each choice is taken into account)."
        sentenceHelpEnumChoices = self.aAllSentences[self.tts.getLanguage()]["helpEnumChoices"]
        sentenceHelpEnumDefault = self.aAllSentences[self.tts.getLanguage()]["helpEnumDefault"]
        sentenceHelpEnumMarks = self.aAllSentences[self.tts.getLanguage()]["enumMarks"]
        enumWords = ""
        indexes = []
        for i in range( len( self.aDefaultChoices ) ):
            indexes.append( i )
            if( len( indexes ) != 1 ): # if it is not the first choice
                if( len( indexes ) != len( self.aDefaultChoices ) ): # if it is not the last choice
                    enumWords += sentenceHelpEnumMarks[0]
                else:
                    enumWords += sentenceHelpEnumMarks[1]
            enumWords += self.aDefaultChoices[i][0]
        sentenceTemplate = sentenceHelpEnumDefault[0]
        if( not bIntroToSay ):
            sentenceTemplate = sentenceHelpEnumChoices[3]
        if( len( self.aDefaultChoices ) == 0 ): # if there is no default choice
            sentence = ""
        else:
            sentence = sentenceTemplate % enumWords
        return sentence

    def explanationTactileSensor(self):
        "Explain the possible interaction with the tactile sensor."
        sentenceHelpTactile = self.aAllSentences[self.tts.getLanguage()]["helpTactile"]
        if( self.bInTactileSensorMenu ):
            sentence = sentenceHelpTactile[1]
        else:
            sentence = sentenceHelpTactile[0]
        return sentence

    def helpWhenAsked(self, sentence = ""):
        "Help when the user asked it: enumerate choices, enumerate default choices and explain tactile sensor possible interaction."
        if( not self.bInTactileSensorMenu ):
            # enumeration of choices
            sentence += self.enumerateChoices( True ) # True to ask that the introduction is played
            # enumeration of default choices
            sentence += self.enumerateDefaultChoices( True ) # True to ask that the introduction is played
        # explanation about alternative modality (tactil sensor, arm motion)
        sentence += self.explanationTactileSensor()
        # launch TTS
        idTTS = -1
        if( sentence != "" ):
            if( self.bInTactileSensorMenu ):
                idTTS = self.tts.post.say( sentence + "\\Pau=300\\" )
            else:
                idTTS = self.tts.post.say( sentence )
            self.aIdsTTS.append( idTTS )
            self.logger.debug( "Robot says: " + str(sentence) )
            # launch TTS movement animation
            if( self.bInTactileSensorMenu ):
                if( self.nFrameNumber != self.aFrameNumbers["helpTactileSensor"] ):
                    self.nFrameNumber = self.aFrameNumbers["helpTactileSensor"]
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
            else:
                if( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ):
                    self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
        # wait for the end of the TTS
        if( idTTS != -1 ):
            try:
                self.tts.wait( idTTS, 0 )
            except:
                self.logger.debug( "Warning: Could not wait the TTS." )
        # repeat the question

    def helpAfterFailure(self, sentence = ""):
        "Help when the speech recognition failed (nothing understood or incorrect answer understood)."
        if( self.nCountFailure < self.nMaxCountFailure ): # if reasonable number of failures
            if( self.bActivateHelpWhenFailure ):
                if( self.nCountFailure in [1, 2] ): # if first or second failure
                    # enumeration of choices, or default words if there is no choice
                    if( len( self.aChoices ) - len( self.aDefaultChoices ) > 0 ): # if there is at least one choice
                        sentence += self.enumerateChoices( self.nCountFailure == 1 ) # the introduction is played if it is the first failure
                    else:
                        sentence += self.enumerateDefaultChoices( self.nCountFailure == 1 ) # the introduction is played if it is the first failure
                    if( self.nCountFailure == 2 ): # if second failure
                        # explanation about alternative modality (tactil sensor, arm motion)
                        sentence += self.explanationTactileSensor()
                # launch TTS
                idTTS = -1
                if( sentence != "" ):
                    idTTS = self.tts.post.say( sentence )
                    self.aIdsTTS.append( idTTS )
                    self.logger.debug( "Robot says: " + str(sentence) )
                    # launch TTS movement animation
                    listPossibleFrames = range( len( self.aAllSentences[self.tts.getLanguage()]["notUnderstoodAnims"] ) )
                    for i in range(len(listPossibleFrames)):
                        listPossibleFrames[i] = listPossibleFrames[i] * 10 + self.aFrameNumbers["notUnderstood"]
                    if( ( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ) and not ( self.nFrameNumber in listPossibleFrames ) ):
                        try:
                            self.getTimeline().goTo(self.aFrameNumbers["bodyTalk"])
                        except: # if NAOqi < 1.14
                            try:
                                self.gotoAndStop(self.aFrameNumbers["bodyTalk"])
                            except:
                                pass
                    self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                # wait for the end of the TTS
                if( idTTS != -1 ):
                    try:
                        self.tts.wait( idTTS, 0 )
                    except:
                        self.logger.debug( "Warning: Could not wait the TTS." )
            # repeat the question
        else: # if maximum number of failures
            # skip the question
            self.goOut( self.asExitWords[0], "notUnderstood" )

# LEDS ---------------------------------------------------------------------------------------------------

    def setLeds(self, eyesLight, earsLight, brainLight):
        "Set all LEDS (eyes, ears and brain lights)."
        rDuration = 1
        if( self.bActivateEyesLight ):
            # set eyes leds
            self.leds.post.fadeRGB( "FaceLeds", eyesLight, rDuration )
        if( self.bActivateEarsLight ):
            # set ears leds
            self.leds.fadeRGB( "EarLeds", earsLight, rDuration )
        if( self.bActivateBrainLight ):
            # set brain leds light
            self.setLedsBrain( brainLight, 500 )

    def ledsUnderstood(self, bFlashEars, bFlashBrain):
        "Sequence of LEDS for eyes, ears and brain when the robot understood what it heard."
        self.bBrainAnimPaused = True
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x00FF00, rDuration )
        if( self.bActivateEarsLight ):
            if( bFlashEars ):
                self.leds.fadeRGB( "EarLeds", 0x00FF00, rDuration )
        if( self.bActivateBrainLight ):
            if( bFlashBrain ):
                self.setLedsBrain( 0.5, int(rDuration * 1000) )
        time.sleep( 0.3 )
        rDuration = 0.2
        if( self.bActivateEyesLight ):
            if( self.bInTactileSensorMenu ):
                self.leds.fadeRGB( "FaceLeds", 0xFFFFFF, rDuration )
            else:
                self.leds.fadeRGB( "FaceLeds", 0x000000, rDuration )
        if( self.bActivateEarsLight ):
            if( bFlashEars ):
                self.leds.fadeRGB( "EarLeds", 0x000000, rDuration )
        if( self.bActivateBrainLight ):
            if( bFlashBrain ):
                self.setLedsBrain( 0., int(rDuration * 1000) )
        time.sleep( 0.1 )
        if( not self.bInTactileSensorMenu ):
            self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        time.sleep( 0.1 )
        self.bBrainAnimPaused = False

    def ledsNotUnderstood(self):
        "Sequence of LEDS for eyes and ears when the robot did not understand what it heard."
        self.bBrainAnimPaused = True
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFF0000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0xFF0000, rDuration )
        time.sleep( 0.05 )
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x000000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0x000000, rDuration )
        time.sleep( 0.05 )
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFF0000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0xFF0000, rDuration )
        time.sleep( 0.05 )
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x000000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0x000000, rDuration )
        time.sleep( 0.3 )
        self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        self.bBrainAnimPaused = False

    def ledsNegative(self):
        "Sequence of LEDS for eyes and ears when the robot understood 'no'."
        self.bBrainAnimPaused = True
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFF0000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0xFF0000, rDuration )
        time.sleep( 0.3 )
        rDuration = 0.2
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x000000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0x000000, rDuration )
        time.sleep( 0.1 )
        self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        time.sleep( 0.1 )
        self.bBrainAnimPaused = False

    def loopLedsReco(self):
        "LEDS (eyes and ears) process during the speech recognition."
        self.beginTime = time.time()
        if( self.bInConfirmation ):
            timerReco = self.beginTime + self.nTimeoutRecoConfirmation
        else:
            timerReco = self.beginTime + self.nTimeoutReco
        self.bHasAlreadyHearingEyes = False
        nEarLedsNextIndex = 0
        nEyesLed = -1
        while( self.bRecoIsWaitingForVoice or self.bRecoIsHearingOrAnalysing ):
            if( self.bMustStop ):
                try:
                    self.timeToReply(time.time() - self.beginTime)
                except:
                    pass
                break
            if( self.bRecoIsWaitingForVoice ):
                if( timerReco < time.time() ):
                    try:
                        self.timeToReply(timerReco - self.beginTime)
                    except:
                        pass
                    self.sRecoInterruption = "timeout"
                    break
            nEarLedsNextIndex = self.ledsEarsTurnOneStep( nEarLedsNextIndex )
            nEyesLed += 1
            self.ledsEyesTurnOneStep( 0x0055FF, nEyesLed%8 )
            time.sleep( 0.2 )

    def ledsEarsTurnOneStep(self, nEarLedsNextIndex):
        "One step of ears LEDS sequence (turn) when the robot is in speech recognition."
        if( self.bActivateEarsLight ):
            nNbrLedByEars = 10
            rTime = 0.7
            strTemplate = "Ears/Led/%s/%dDeg/Actuator/Value"
            nAngle = (360/nNbrLedByEars) * nEarLedsNextIndex
            # update index before sending movement in case of a fast/concurrent call of the function
            nEarLedsNextIndex -= 1 # more beautiful to turn in this way
            if( nEarLedsNextIndex < 0 ):
                nEarLedsNextIndex = nNbrLedByEars-1
            self.leds.post.fade( strTemplate % ( "Left", nAngle ), 1.0, rTime )
            self.leds.post.fade( strTemplate % ( "Right", nAngle ), 1.0, rTime )
            self.leds.post.fade( strTemplate % ( "Left", nAngle ), 0.0, rTime*1.2 )
            self.leds.post.fade( strTemplate % ( "Right", nAngle ), 0.0, rTime*1.2 )
        return nEarLedsNextIndex

    def ledsEyesTurnOneStep(self, nColor, nLed):
        "One step of eyes LEDS sequence (turn) when the robot is in speech recognition."
        if( self.bActivateEyesLight ):
            rTime = 0.7
            if( self.bRecoIsHearingOrAnalysing ):
                if( not self.bHasAlreadyHearingEyes ):
                    self.leds.fadeRGB( "FaceLeds", 0xF4FF22, 0.1 )
                    # start headcheck animation
                    if( self.nFrameNumber != self.aFrameNumbers["headCheck"] ):
                        self.nFrameNumber = self.aFrameNumbers["headCheck"]
                        try:
                            self.getTimeline().goTo(self.nFrameNumber)
                        except: # if NAOqi < 1.14
                            try:
                                self.gotoAndStop(self.nFrameNumber)
                            except:
                                pass
                    self.bHasAlreadyHearingEyes = True
            elif( self.bRecoIsWaitingForVoice ):
                self.leds.post.fadeRGB( "FaceLed%d" % (nLed) , nColor, rTime )
                self.leds.post.fadeRGB( "FaceLed%d" % (nLed) , 0x000000, rTime*1.25 )

    def ledsChangeOnTactile(self):
        self.bBrainAnimPaused = True
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x0055FF, rDuration )
        self.setLedsBrain( 0.5, int(rDuration * 1000) )
        time.sleep( 0.3 )
        rDuration = 0.2
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFFFFFF, rDuration )
        self.setLedsBrain( 0., int(rDuration * 1000) )
        time.sleep( 0.2 )
        self.bBrainAnimPaused = False

    def loopLedsBrainTurn(self):
        self.setLeds( 0xFFFFFF, 0xFFFFFF, 0. )
        rIntensity = 0.5
        nTime = 50
        bAlreadyPaused = False
        while( self.bInTactileSensorMenu ):
            if( not self.bBrainAnimPaused ):
                if( self.nFront == 1 or self.nMiddle == 1 or self.nRear == 1 ):
                    if( not bAlreadyPaused ):
                        bAlreadyPaused = True
                        self.setLedsBrain( 0., 50 )
                else:
                    bAlreadyPaused = False
                    if( self.bActivateBrainLight ):
                        for i in range( 12 ):
                            if( not self.bBrainAnimPaused and self.dcm != None):
                                riseTime = self.dcm.getTime(nTime)
                                strDeviceName = self.getBrainLedName(i)
                                self.dcm.set( [ strDeviceName, "Merge",  [[ rIntensity, riseTime ]] ] )
                                time.sleep( nTime/1000. )
                                if( not self.bBrainAnimPaused ):
                                    self.dcm.set( [ strDeviceName, "Merge",  [[ 0.0, riseTime + int(nTime)/4 ]] ] )
            time.sleep( nTime/1000. )
        self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )

    def loopLedsBrainTwinkle(self):
        rIntensity = 0.5
        bOnStep = True
        bAlreadyPaused = False
        while( not self.bInTactileSensorMenu and self.bIsRunning ):
            if( not self.bBrainAnimPaused ):
                if( self.nFront == 1 or self.nMiddle == 1 or self.nRear == 1 ):
                    if( not bAlreadyPaused ):
                        bAlreadyPaused = True
                        self.setLedsBrain( 0., 50 )
                else:
                    bAlreadyPaused = False
                    if( bOnStep ):
                        self.setLedsBrain( rIntensity, 700 )
                        bOnStep = False
                    else:
                        self.setLedsBrain( 0.0, 700 )
                        bOnStep = True
            time.sleep( 1 )

    def setLedsBrain(self, rIntensity, rTimeMs):
        "One step of brain LEDS sequence (twinkle) when the robot is in speech recognition."
        if( self.bActivateBrainLight and self.dcm != None):
            riseTime = self.dcm.getTime( rTimeMs )
            for i in range( 12 ):
                strDeviceName = self.getBrainLedName(i)
                self.dcm.set( [ strDeviceName, "Merge",  [[ rIntensity, riseTime ]] ] )

# TACTILE SENSOR MENU -------------------------------------------------------------------------------------

    def onAlternativeModalityAction(self, p):
        "Process actions from alternative modalities (sequence from the tactile sensor, simple click on the torso button...)."
        if( not self.bIsRunning ): # if the box is not running
            return # then go out without doing a thing
        if( not self.bInTactileSensorMenu ): # if we are not in the tactile sensor menu (so if we are in the question-recognition-reaction loop)
            if( p in ["TapFront", "TapMiddle", "TapRear", "LongFront", "LongMiddle", "LongRear"] ):
                bTTSRunning = False # to know if TTS is running
                for idTTS in self.aIdsTTS:
                    if( self.tts.isRunning( idTTS )):
                        bTTSRunning = True
                if( bTTSRunning ): # if TTS is running
                    # skip the TTS
                    self.skipTTS()
                else: # if TTS was not running (so if in recognition)
                    # prepare to start the tactile sensor menu
                    self.bInTactileSensorMenu = True
                    # and stop the question-recognition-reaction loop
                    self.goOutOfQuestionRecoReaction()
                    self.sRecoInterruption = "onTactileSensor"
                    # start the tactile sensor menu
                    self.sayCurrentChoice()
                    # start counting timeout
                    self.rTimeWhenActionMadeInTactileMenu = time.time()
                    thread.start_new_thread( self.loopCheckTimeoutInTactileMenu, (self.rTimeWhenActionMadeInTactileMenu,) )
            elif( p in ["Tap", "CalmDown"] ):
                # skip the TTS
                self.skipTTS()
                # then stop everything and cancel the question
                self.goOut( self.asExitWords[0], "onTactileSensor" )
                self.sRecoInterruption = "onTactileSensor"
                self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        else: # if we are in the tactile sensor menu
            self.rTimeWhenActionMadeInTactileMenu = -1.
            if( p in ["TapFront"] ):
                bTTSRunning = False # to know if TTS is running
                for idTTS in self.aIdsTTS:
                    if( self.tts.isRunning( idTTS ) ):
                        bTTSRunning = True
                if( self.bIsSayingChoice or not bTTSRunning ): # else just skip the TTS (in the sayCurrentChoice function)
                    # change choice
                    self.nIndexChoice += 1
                    if( self.nIndexChoice >= len( self.aChoices ) ):
                        self.nIndexChoice = 0
                # say the choice in the tactile sensor menu
                self.sayCurrentChoice()
                self.timeoutManagingInTactileMenu()
            elif( p in ["TapRear"] ):
                bTTSRunning = False # to know if TTS is running
                for idTTS in self.aIdsTTS:
                    if( self.tts.isRunning( idTTS )):
                        bTTSRunning = True
                if( self.bIsSayingChoice or not bTTSRunning ): # else just skip the TTS (in the sayCurrentChoice function)
                    # change choice
                    self.nIndexChoice -= 1
                    if( self.nIndexChoice < 0 ):
                        self.nIndexChoice = len( self.aChoices ) - 1
                # say the choice in the tactile sensor menu
                self.sayCurrentChoice()
                self.timeoutManagingInTactileMenu()
            elif( p in ["TapMiddle", "LongMiddle"] ):
                self.rTimeWhenActionMadeInTactileMenu = time.time()
                rTimeForThisAction = self.rTimeWhenActionMadeInTactileMenu
                bWasSayingChoice = self.bIsSayingChoice
                bTTSRunning = False # to know if TTS is running
                for idTTS in self.aIdsTTS:
                    if( self.tts.isRunning( idTTS )):
                        bTTSRunning = True
                # skip the TTS if it is running
                self.skipTTS()
                if( bWasSayingChoice or not bTTSRunning ):
                    # validate choice
                    thread.start_new_thread( self.ledsUnderstood, (False, True) )
                    if( self.aChoices[self.nIndexChoice][0] == self.asRepeatWords[0] ):
                        self.repeatWhenNoQuestion()
                        # launch TTS
                        idTTS = -1
                        if( self.sQuestion != ""):
                            idTTS = self.tts.post.say( self.sQuestion + "\\Pau=300\\" )
                            self.aIdsTTS.append( idTTS )
                            self.logger.debug( "Robot says: " + str(self.sQuestion) )
                        # wait for the end of the TTS
                        if( idTTS != -1 ):
                            try:
                                self.tts.wait( idTTS, 0 )
                            except:
                                self.logger.debug( "Warning: Could not wait the TTS." )
                    else:
                        self.reactionWordUnderstood( [ self.aChoices[self.nIndexChoice][0], 1.0 ] )
                if( self.bIsRunning and rTimeForThisAction == self.rTimeWhenActionMadeInTactileMenu ): #$$$
                    self.rTimeWhenActionMadeInTactileMenu = -1.
                    # say the choice in the tactile sensor menu
                    self.sayCurrentChoice()
                    self.timeoutManagingInTactileMenu()
            elif( p == "LongFront" ):
                if( not self.bPressed ):
                    self.bPressed = True
                    bLastElementSaid = False
                    while( self.bPressed ):
                        if( self.nFront == 0 ):
                            self.bPressed = False
                            break
                        bTTSRunning = False # to know if TTS is running
                        for idTTS in self.aIdsTTS:
                            if( self.tts.isRunning( idTTS )):
                                bTTSRunning = True
                        if( self.bIsSayingChoice or not bTTSRunning ):
                            # change choice
                            self.nIndexChoice += 1
                            if( self.nIndexChoice >= len( self.aChoices ) - 1 ):
                                self.nIndexChoice = len( self.aChoices ) - 1
                                if( not bLastElementSaid ):
                                    bLastElementSaid = True
                                    # say the choice in the tactile sensor menu
                                    thread.start_new_thread( self.sayCurrentChoice, () )
                            else:
                                # say the choice in the tactile sensor menu
                                thread.start_new_thread( self.sayCurrentChoice, () )
                        else:
                            if( self.nIndexChoice == len( self.aChoices ) - 1 ):
                                bLastElementSaid = True
                            # say the choice in the tactile sensor menu
                            thread.start_new_thread( self.sayCurrentChoice, () )
                        for i in range(8):
                            if( self.nFront == 0 ):
                                self.bPressed = False
                                break
                            time.sleep(0.1)
                    for idTTS in self.aIdsTTS:
                        if( self.tts.isRunning( idTTS ) ):
                            try:
                                self.tts.wait( idTTS, 0 )
                            except:
                                self.logger.debug( "Warning: Could not wait the TTS." )
                    self.timeoutManagingInTactileMenu()
            elif( p == "LongRear" ):
                if( not self.bPressed ):
                    self.bPressed = True
                    bFirstElementSaid = False
                    while( self.bPressed ):
                        if( self.nRear == 0 ):
                            self.bPressed = False
                            break
                        bTTSRunning = False # to know if TTS is running
                        for idTTS in self.aIdsTTS:
                            if( self.tts.isRunning( idTTS )):
                                bTTSRunning = True
                        if( self.bIsSayingChoice or not bTTSRunning ):
                            # change choice
                            self.nIndexChoice -= 1
                            if( self.nIndexChoice <= 0 ):
                                self.nIndexChoice = 0
                                if( not bFirstElementSaid ):
                                    bFirstElementSaid = True
                                    # say the choice in the tactile sensor menu
                                    thread.start_new_thread( self.sayCurrentChoice, () )
                            else:
                                # say the choice in the tactile sensor menu
                                thread.start_new_thread( self.sayCurrentChoice, () )
                        else:
                            if( self.nIndexChoice == 0 ):
                                bFirstElementSaid = True
                            # say the choice in the tactile sensor menu
                            thread.start_new_thread( self.sayCurrentChoice, () )
                        for i in range(8):
                            if( self.nRear == 0 ):
                                self.bPressed = False
                                break
                            time.sleep(0.1)
                    for idTTS in self.aIdsTTS:
                        if( self.tts.isRunning( idTTS ) ):
                            try:
                                self.tts.wait( idTTS, 0 )
                            except:
                                self.logger.debug( "Warning: Could not wait the TTS." )
                    self.timeoutManagingInTactileMenu()
            elif( p in ["Tap", "CalmDown"] ):
                # then stop everything and cancel the question
                self.goOut( self.asExitWords[0], "onTactileSensor" )

    def sayCurrentChoice(self):
        "In the tactile sensor menu, make the robot say the current selected choice"
        self.bIsSayingChoice = True
        rTimeCurrent = time.time()
        self.rTimeLastChoiceSaid = rTimeCurrent
        # stop previous TTS
        self.skipTTS()
        # launch TTS
        idTTS = -1
        if( self.aChoices[ self.nIndexChoice ][0] != "" ):
            if( self.nFrameNumber != self.aFrameNumbers["headDown"] ):
                self.nFrameNumber = self.aFrameNumbers["headDown"]
                try:
                    self.getTimeline().goTo(self.nFrameNumber)
                except: # if NAOqi < 1.14
                    try:
                        self.gotoAndStop(self.nFrameNumber)
                    except:
                        pass
            sentence = self.aChoices[ self.nIndexChoice ][0] + "?"
            idTTS = self.tts.post.say( sentence )
            self.aIdsTTS.append( idTTS )
            self.logger.debug( "Robot says: " + str(sentence) )
            # launch flash leds
            thread.start_new_thread( self.ledsChangeOnTactile, () )
        if( idTTS != -1 ):
            try:
                self.tts.wait( idTTS, 0 )
            except:
                self.logger.debug( "Warning: Could not wait the TTS." )
        if( self.rTimeLastChoiceSaid == rTimeCurrent ):
            self.rTimeLastChoiceSaid = -1.
            self.bIsSayingChoice = False

    def timeoutManagingInTactileMenu(self):
        # check if there has been an other action with tts made while this one was processed
        bTTSRunning = False # to know if TTS is running
        for idTTS in self.aIdsTTS:
            if( self.tts.isRunning( idTTS )):
                bTTSRunning = True
        if( not bTTSRunning ):
            # start counting timeout
            self.rTimeWhenActionMadeInTactileMenu = time.time()
            thread.start_new_thread( self.loopCheckTimeoutInTactileMenu, (self.rTimeWhenActionMadeInTactileMenu,) )

    def loopCheckTimeoutInTactileMenu(self, rTimeForThisAction):
        nTimeout = time.time() + self.nTimeoutTactile
        if( self.rTimeWhenActionMadeInTactileMenu == rTimeForThisAction ):
            while( time.time() < nTimeout and self.rTimeWhenActionMadeInTactileMenu == rTimeForThisAction and self.bIsRunning ):
                time.sleep( 0.1 )
            if( self.rTimeWhenActionMadeInTactileMenu != rTimeForThisAction ):
                self.nCountNoReply = 0
            elif( self.bIsRunning ):
                self.rTimeWhenActionMadeInTactileMenu = -1.
                self.nCountNoReply += 1
                if( self.nCountNoReply >= self.nMaxCountNoReply ):
                    self.goOut( self.asExitWords[0], "timeout" )
                else:
                    bTTSRunning = False # to know if TTS is running
                    for idTTS in self.aIdsTTS:
                        if( self.tts.isRunning( idTTS )):
                            bTTSRunning = True
                    if( not bTTSRunning ):
                        # say the choice in the tactile sensor menu
                        self.sayCurrentChoice()
                        # start counting timeout
                        self.rTimeWhenActionMadeInTactileMenu = time.time()
                        thread.start_new_thread( self.loopCheckTimeoutInTactileMenu, (self.rTimeWhenActionMadeInTactileMenu,) )

# TACTILE SENSOR HANDLER -------------------------------------------------------------------------------

    def initSeqDetected(self):
        "Initialize the sequence handler."
        self.bSeqStarted = False
        self.aDetectedSeqs = []
        self.aDetectedSeqs.extend(self.aSeqs)
        for seq in self.aDetectedSeqs:
            seq["index"] = 0
            seq["previousStepTime"] = 0

    def convertToArrayOfPossibleStates(self, states):
        "Check if the states described in the sequences using a string are in the right syntax, and then convert them to an array of the possible states."
        aStates = []
        aStates3 = [[1, 1, 1]]
        aStates2 = [[0, 1, 1], [1, 0, 1], [1, 1, 0]]
        aStates1 = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]
        aStates0 = [[0, 0, 0]]
        try:
            if( int(states) == states ): # if states is an integer
                states = str(states)
        except:
            pass
        if( self.isString(states) ):
            if( not states in ["*", "0+", "0", "0-", "1+", "1", "1-", "2+", "2", "2-", "3+", "3", "3-", "F+", "F", "F-", "M+", "M", "M-", "R+", "R", "R-"] ):
                raise Exception( "Error in sequences states description syntax: description expected in " + str(["*", "0+", "0", "0-", "1+", "1", "1-", "2+", "2", "2-", "3+", "3", "3-", "F+", "F", "F-", "M+", "M", "M-", "R+", "R", "R-"]) + " but " + str(p) + " found with this type: " + str(type(p)) )
            if( states in ["*", "0+", "1+", "2+", "3+", "3", "3-", "F+", "M+", "R+"] ):
                aStates.extend(aStates3)
            if( states in ["*", "0+", "1+", "2+", "2", "2-", "3-"] ):
                aStates.extend(aStates2)
            if( states in ["*", "0+", "1+", "1", "1-", "2-", "3-"] ):
                aStates.extend(aStates1)
            if( states in ["*", "0+", "0", "0-", "1-", "2-", "3-", "F-", "M-", "R-"] ):
                aStates.extend(aStates0)
            if( states in ["F", "F+", "F-"] ):
                aStates.append([1, 0, 0])
            if( states in ["M", "M+", "M-"] ):
                aStates.append([0, 1, 0])
            if( states in ["R", "R+", "R-"] ):
                aStates.append([0, 0, 1])
            if( states in ["F+", "M+"] ):
                aStates.append([1, 1, 0])
            if( states in ["R+", "M+"] ):
                aStates.append([0, 1, 1])
            if( states in ["F+", "R+"] ):
                aStates.append([1, 0, 1])
        elif( self.isArray(states) ):
            if( self.isArray(states[0]) ):
                aStates = states
            elif( int(states[0]) == states[0] ):
                aStates = [states]
            else:
                raise Exception( "Error in sequences states description syntax: description expected in " + str(["*", "0+", "0", "0-", "1+", "1", "1-", "2+", "2", "2-", "3+", "3", "3-", "F+", "F", "F-", "M+", "M", "M-", "R+", "R", "R-"]) + " but " + str(p) + " found with this type: " + str(type(p)) )
        else:
            raise Exception( "Error in sequences states description syntax:\nstring, array or int expected but " + str(type(p)) + " found" )
        return aStates

    def checkIfSeqsCorrespondingLeft(self, param):
        "If the sequence handler is done (there is no sequence detected left or the first in the list corresponds), then reinitialize the sequence handler, and give the corresponding sequence if there is one."
        if( self.aDetectedSeqs == [] ):
            # then no sequence corresponding in the list
            self.initSeqDetected()
        else:
            if( self.aDetectedSeqs[0]["index"] == -1 ): # if first sequence in left ones corresponds
                # then it is this sequence which is played
                thread.start_new_thread( self.onAlternativeModalityAction, (self.aDetectedSeqs[0]["name"],) )
                self.initSeqDetected()
        self.mutexCheckIfSeqsCorrespondingLeft.unlock()

    def loopCheckTimeoutMax(self, nTimeoutMax, seq, currentState, currentTime):
        "When timeout ellapsed, check the sequence status and process it."
        nPreviousIndex = seq["index"]
        time.sleep(nTimeoutMax + 0.1)
        aSeqsTemp = []
        aSeqsTemp.extend( self.aDetectedSeqs )
        currentState = [self.nFront, self.nMiddle, self.nRear]
        currentTime = time.time()
        if( nPreviousIndex == seq["index"] and not self.mutexProcessCurrentState.test() and not (1 in currentState) ): # if no change in the sequence step but timeout ellapsed and sequence handler is not processing (so if there is no action from the user and the sequence is still at the same point)
            if( seq in aSeqsTemp and seq["index"] != -1 ): # but if sequence is still in the possible ones and not completed
                if( currentState in seq["statesAndTimeout"][seq["index"]] ): # last check if the current state corresponds to the next one
                    # then we go to the next step
                    seq["previousStepTime"] = currentTime
                    seq["index"] += 2
                    if( seq["index"] > len( seq["statesAndTimeout"] ) ): # if there is no more step
                        seq["index"] = -1 # then the sequence is completed
                    else: # if there is at least one step left
                        nTimeoutMin = 0
                        nTimeoutMax = 5
                        if( self.isArray(seq["statesAndTimeout"][seq["index"]-1]) ):
                            if( seq["statesAndTimeout"][seq["index"]-1][0] < 0 ):
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][0]
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][1]
                            else:
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][0]
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][1]
                        else:
                            if( seq["statesAndTimeout"][seq["index"]-1] < 0 ):
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1]
                            else:
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1]
                        thread.start_new_thread( self.loopCheckTimeoutMax, (nTimeoutMax, seq, currentState, currentTime) )
                else:
                    # then remove the sequence from the possible ones
                    aSeqsTemp.remove(seq)
                    self.aDetectedSeqs = aSeqsTemp
                self.mutexCheckIfSeqsCorrespondingLeft.lock( self.checkIfSeqsCorrespondingLeft, None )

    def loopCheckTimeoutMin(self, nTimeoutMin, seq):
        "Wait that the minimum timeout ellapse to check if the new tactile sensor state corresponds to the expected one for this sequence."
        if( nTimeoutMin != 0 ):
            nPreviousIndex = seq["index"]
            time.sleep(nTimeoutMin - time.time() + seq["previousStepTime"])
            currentTime = time.time()
            currentState = [self.nFront, self.nMiddle, self.nRear]
            self.mutexProcessCurrentState.lock( self.processCurrentState, [0, currentState, currentTime] )

    def updateDetectedSeqs(self, seq, aSeqsTemp, currentState, currentTime):
        "Update a detected sequence."
        if( seq["index"] > 0 ): # if not the first step
            nTimeoutMin = 0
            nTimeoutMax = 5
            if( self.isArray(seq["statesAndTimeout"][seq["index"]-1]) ):
                if( seq["statesAndTimeout"][seq["index"]-1][0] < 0 ):
                    nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][0]
                    nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][1]
                else:
                    nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][0]
                    nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][1]
            else:
                if( seq["statesAndTimeout"][seq["index"]-1] < 0 ):
                    nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1]
                else:
                    nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1]
            if( currentTime > nTimeoutMax + seq["previousStepTime"] ): # if timeout of this step ellapsed
                aSeqsTemp.remove(seq) # then it is not this sequence which is played
            elif( not (currentState in seq["statesAndTimeout"][seq["index"]]) ): # if the current state does not correspond to one of the described ones but the timeout of this step did not ellaspe
                # then we check that this state could be an intermediate one
                aIntermediateStates = [[], [], []]
                for i in range( len( currentState ) ):
                    for j in range( len( seq["statesAndTimeout"][seq["index"]] ) ):
                        aIntermediateStates[i].append( seq["statesAndTimeout"][seq["index"]][j][i] )
                    for j in range( len( seq["statesAndTimeout"][seq["index"]-2] ) ):
                        aIntermediateStates[i].append( seq["statesAndTimeout"][seq["index"]-2][j][i] )
                bIsIntermediate = True
                for i in range( len( currentState ) ):
                    bIsIntermediate = bIsIntermediate and ( currentState[i] in aIntermediateStates[i] )
                if( not bIsIntermediate ):
                    aSeqsTemp.remove(seq) # then it is not this sequence which is played
            else: # if the current state correspond to one of the described ones
                if( currentTime > nTimeoutMin + seq["previousStepTime"] ): # if the minimum time to wait the next step is ellapsed
                    # then we go to the next step
                    seq["previousStepTime"] = currentTime
                    seq["index"] += 2
                    if( seq["index"] > len( seq["statesAndTimeout"] ) ): # if there is no more step
                        seq["index"] = -1 # then the sequence is completed
                    else: # if there is at least one step left
                        # start clock to timeout
                        nTimeoutMin = 0
                        nTimeoutMax = 5
                        if( self.isArray(seq["statesAndTimeout"][seq["index"]-1]) ):
                            if( seq["statesAndTimeout"][seq["index"]-1][0] < 0 ):
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][0]
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][1]
                            else:
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][0]
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][1]
                        else:
                            if( seq["statesAndTimeout"][seq["index"]-1] < 0 ):
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1]
                            else:
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1]
                        thread.start_new_thread( self.loopCheckTimeoutMin, (nTimeoutMin, seq) )
                        thread.start_new_thread( self.loopCheckTimeoutMax, (nTimeoutMax, seq, currentState, currentTime) )
                else: # if the minimum time to wait the next step is not ellapsed
                    # then we are going to wait until it is to check then
                    thread.start_new_thread( self.loopCheckTimeoutMin, (nTimeoutMin, seq) )
        elif( seq["index"] == 0 ): # for the first step
            if( currentState in seq["statesAndTimeout"][seq["index"]] ): # if the current state correspond to one of the described ones
                # then we go to the next step
                seq["previousStepTime"] = currentTime
                seq["index"] += 2
                if( seq["index"] > len( seq["statesAndTimeout"] ) ): # if there is no more step
                    seq["index"] = -1 # then the sequence is completed
                else: # if there is at least one step left
                    # start clock to timeout
                    nTimeoutMin = 0
                    nTimeoutMax = 5
                    if( self.isArray(seq["statesAndTimeout"][seq["index"]-1]) ):
                        if( seq["statesAndTimeout"][seq["index"]-1][0] < 0 ):
                            nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][0]
                            nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][1]
                        else:
                            nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][0]
                            nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][1]
                    else:
                        if( seq["statesAndTimeout"][seq["index"]-1] < 0 ):
                            nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1]
                        else:
                            nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1]
                    thread.start_new_thread( self.loopCheckTimeoutMin, (nTimeoutMin, seq) )
                    thread.start_new_thread( self.loopCheckTimeoutMax, (nTimeoutMax, seq, currentState, currentTime) )
            else: # if the current state does not correspond to the first described
                aSeqsTemp.remove(seq) # then it is not this sequence which has just been started

    def updateSeqsHandler(self, currentState, currentTime):
        "Update list of detected sequences."
        aSeqsTemp = []
        aSeqsTemp.extend( self.aDetectedSeqs )
        for seq in self.aDetectedSeqs:
            self.updateDetectedSeqs( seq, aSeqsTemp, currentState, currentTime )
        self.aDetectedSeqs = aSeqsTemp
        self.mutexCheckIfSeqsCorrespondingLeft.lock( self.checkIfSeqsCorrespondingLeft, None )

    def processCurrentState(self, param):
        "Process the current tactile sensor state."
        pValue = param[0]
        currentState = param[1]
        currentTime = param[2]
        if( pValue == 1 and not self.bSeqStarted ):
            self.bSeqStarted = True
            for seq in self.aDetectedSeqs:
                seq["previousStepTime"] = currentTime
        # update sequences handler
        if( self.bSeqStarted ):
            self.updateSeqsHandler(currentState, currentTime)
        self.mutexProcessCurrentState.unlock()

    def onFrontTactilTouched(self, param):
        "Handle an action (touch or release) on the front tactile sensor."
        self.logger.debug( "Change detected on the front tactile sensor: " + str(param[0]) )
        pValue = param[0]
        currentTime = param[1]
        currentState = [pValue, self.nMiddle, self.nRear]
        self.nFront = pValue
        self.mutexProcessCurrentState.lock( self.processCurrentState, [pValue, currentState, currentTime] )
        self.mutexTactilTouched.unlock()

    def onMiddleTactilTouched(self, param):
        "Handle an action (touch or release) on the middle tactile sensor."
        self.logger.debug( "Change detected on the middle tactile sensor: " + str(param[0]) )
        pValue = param[0]
        currentTime = param[1]
        currentState = [self.nFront, pValue, self.nRear]
        self.nMiddle = pValue
        self.mutexProcessCurrentState.lock( self.processCurrentState, [pValue, currentState, currentTime] )
        self.mutexTactilTouched.unlock()

    def onRearTactilTouched(self, param):
        "Handle an action (touch or release) on the rear tactile sensor."
        self.logger.debug( "Change detected on the rear tactile sensor: " + str(param[0]) )
        pValue = param[0]
        currentTime = param[1]
        currentState = [self.nFront, self.nMiddle, pValue]
        self.nRear = pValue
        self.mutexProcessCurrentState.lock( self.processCurrentState, [pValue, currentState, currentTime] )
        self.mutexTactilTouched.unlock()

    def onTactilTouched(self, pDataName, pValue, pMessage):
        "Handle an action (touch or release) on the tactile sensor."
        self.mutexTactilTouched.lock( getattr( self, "on" + pDataName ), [pValue, time.time()] )

# OUTPUTS ACTIVATION --------------------------------------------------------------------------------------

    def goOut(self, outputName, cancelReason = ""):
        "Activate the right output (a choice output or the other output)."
        try:
            self.memory.unsubscribeToEvent( "FrontTactilTouched", self.getName() )
            self.memory.unsubscribeToEvent( "MiddleTactilTouched", self.getName() )
            self.memory.unsubscribeToEvent( "RearTactilTouched", self.getName() )
        except:
            pass

        self.bGoOut = True
        self.bInTactileSensorMenu = False
        if( outputName in self.asExitWords ):
            try:
                self.other( cancelReason )
                self.logger.debug( "Output 'other' stimulated because cancel asked: " + str(cancelReason) + "." )
            except:
                try:
                    self.onStopped( cancelReason )
                    self.logger.debug( "Output 'onStopped' stimulated because cancel asked: " + str(cancelReason) + "." )
                except:
                    try:
                        self.onStopped()
                        self.logger.debug( "Output 'onStopped' stimulated because cancel asked." )
                    except:
                        choregraphe = ALProxy( "ALChoregraphe" )
                        choregraphe.onPythonError( self.getName(), "goOut", "Invalid output: the main output name needs to be 'other', and it needs to be dynamic (because it can be either a string, or an integer)." )
        else:
            nOutput = -1
            for i in range( len (self.aChoices) - len (self.aDefaultChoices) ):
                if( nOutput == -1 ):
                    if( outputName in self.aChoices[i+len( self.aDefaultChoices )] ):
                        nOutput = i
            if( nOutput != -1):
                if( self.bExternChoices ):
                    if( self.bRepeatValidatedChoice ):
                        self.skipTTS()
                        self.tts.say( outputName )
                        self.logger.debug( "Robot says: " + str(outputName) )
                    try:
                        self.other( self.aChoiceIndexes[nOutput] )
                        self.logger.debug( "Output 'other' stimulated with: " + str(self.aChoiceIndexes[nOutput]) + " (corresponding to the choice '" + str(self.aChoices[nOutput+len( self.aDefaultChoices )][0]) + "')." )
                    except:
                        try:
                            self.onStopped( self.aChoiceIndexes[nOutput] )
                            self.logger.debug( "Output 'onStopped' stimulated with: " + str(self.aChoiceIndexes[nOutput]) + " (corresponding to the choice '" + str(self.aChoices[nOutput+len( self.aDefaultChoices )][0]) + "')." )
                        except:
                            choregraphe = ALProxy( "ALChoregraphe" )
                            choregraphe.onPythonError( self.getName(), "goOut", "Invalid type of output: using the input 'choicesList', the main output needs to be dynamic (because it can be either a string, or an integer)." )
                else:
                    if( self.bRepeatValidatedChoice ):
                        self.skipTTS()
                        self.tts.say( outputName )
                        self.logger.debug( "Robot says: " + str(outputName) )
                    try:
                        func = getattr( self, "output_" + str(self.aChoiceIndexes[nOutput]+1) ) #+1 because the first one is output_1 corresponding to the element 0 in the list.
                        func(outputName)
                        self.logger.debug( "Output 'output_" + str(self.aChoiceIndexes[nOutput]+1) + "' stimulated with: " + str(outputName) + "." )
                    except:
                        choregraphe = ALProxy( "ALChoregraphe" )
                        choregraphe.onPythonError( self.getName(), "goOut", "Invalid output: the output 'output_" + str(self.aChoiceIndexes[nOutput]+1) + "' was expected to be stimulated with: " + str(outputName) + " but could not." )
        self.onUnload()
        # come back to an initial position and stop movement animation
        if( self.nFrameNumber != self.aFrameNumbers["end"] ):
            self.nFrameNumber = self.aFrameNumbers["end"]
            try:
                self.getTimeline().goTo(self.nFrameNumber)
            except: # if NAOqi < 1.14
                try:
                    self.gotoAndStop(self.nFrameNumber)
                except:
                    pass

# UNLOAD --------------------------------------------------------------------------------------------------

    def goOutOfQuestionRecoReaction(self):
        "Set some variables to go out of the question-recognition-reaction loop and reinitialize other variables which are going to be used again only on the next start of this box."
        self.bGoOut = True
        self.bMustStop = True
        self.nCountFailure = 0
        self.nCountNoReply = 0
        self.bInConfirmation = False
        self.bVocabularyLoaded = False
        self.skipTTS()
        for idTTS in self.aIdsTTS:
            try:
                self.aIdsTTS.remove( idTTS )
            except:
                self.logger.debug( "Warning: The task ID corresponding to the Text-To-Speech could not have been removed from the ID tasks list." )
        try:
            self.memory.unsubscribeToEvent( "WordRecognized", self.getName() )
            self.bRecoIsWaitingForVoice = False
            self.bRecoIsHearingOrAnalysing = False
            self.logger.debug( "Speech recognition stopped." )
            self.memory.unsubscribeToEvent( "SpeechDetected", self.getName() )
        except:
            pass

    def onUnload(self):
        "Reinitialize variables to default state."
        self.goOutOfQuestionRecoReaction()
        self.bExternChoices = False
        self.bInTactileSensorMenu = False
        try:
            self.memory.unsubscribeToEvent( "FrontTactilTouched", self.getName() )
            self.memory.unsubscribeToEvent( "MiddleTactilTouched", self.getName() )
            self.memory.unsubscribeToEvent( "RearTactilTouched", self.getName() )
        except:
            pass
        self.bIsRunning = False]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <keyword>نعم</keyword>
                                                        <keyword>لا</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </arabic>
                                                    <brazilian>
                                                        <keyword>sim</keyword>
                                                        <keyword>não</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </brazilian>
                                                    <chinese>
                                                        <keyword>是</keyword>
                                                        <keyword>不是</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </chinese>
                                                    <czech>
                                                        <keyword>ano</keyword>
                                                        <keyword>ne</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </czech>
                                                    <danish>
                                                        <keyword>ja</keyword>
                                                        <keyword>nej</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </danish>
                                                    <dutch>
                                                        <keyword>ja</keyword>
                                                        <keyword>nee</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </dutch>
                                                    <english>
                                                        <keyword></keyword>
                                                        <keyword>Na</keyword>
                                                        <keyword>Le</keyword>
                                                        <keyword></keyword>
                                                    </english>
                                                    <finnish>
                                                        <keyword>kyllä</keyword>
                                                        <keyword>ei</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </finnish>
                                                    <french>
                                                        <keyword>oui</keyword>
                                                        <keyword>non</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </french>
                                                    <german>
                                                        <keyword>ja</keyword>
                                                        <keyword>nein</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </german>
                                                    <greek>
                                                        <keyword>ναί</keyword>
                                                        <keyword>κανένα</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </greek>
                                                    <italian>
                                                        <keyword>sì</keyword>
                                                        <keyword>no</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </italian>
                                                    <japanese>
                                                        <keyword>はい</keyword>
                                                        <keyword>いいえ</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </japanese>
                                                    <korean>
                                                        <keyword>예</keyword>
                                                        <keyword>아니</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </korean>
                                                    <norwegian>
                                                        <keyword>ja</keyword>
                                                        <keyword>Nei</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </norwegian>
                                                    <polish>
                                                        <keyword>tak</keyword>
                                                        <keyword>nie</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </polish>
                                                    <portuguese>
                                                        <keyword>sim</keyword>
                                                        <keyword>não</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </portuguese>
                                                    <russian>
                                                        <keyword>да</keyword>
                                                        <keyword>нет</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </russian>
                                                    <spanish>
                                                        <keyword>si</keyword>
                                                        <keyword>no</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </spanish>
                                                    <swedish>
                                                        <keyword>ja</keyword>
                                                        <keyword>ingen</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </swedish>
                                                    <turkish>
                                                        <keyword>evet</keyword>
                                                        <keyword>hayır</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </turkish>
                                                    <language>english</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="0" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is&#x0A;received on this input. The signal can be&#x0A;either a string so that the robot asks a&#x0A;question before the recognition of a&#x0A;choice, or a bang so that the speech&#x0A;recognition starts immediately without any&#x0A;question." id="2" />
                                                <Input name="choicesList" type="0" type_size="1" nature="1" inner="0" tooltip="To have extern choices list (for example,&#x0A;depending on extern variables).&#x0A;!! Warning !! : Must be set before each&#x0A;time the box is started (with onStart&#x0A;input). Otherwise, the choices displayed&#x0A;on the box will be selected." id="3" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip='Box behavior stops when a signal is&#x0A;received on this input, the &apos;other&apos; output is&#x0A;stimulated by &quot;onStop&quot;.' id="4" />
                                                <Output name="other" type="0" type_size="1" nature="1" inner="0" tooltip='When the user skipped the question, this output gives how it has been&#x0A;skipped. Gives also the number of the choice chosen in case of external&#x0A;choices.&#x0A;This output can be:&#x0A;- &quot;timeout&quot; if the user has not replied.&#x0A;- &quot;notUnderstood&quot; if the interaction with the speech recognition failed.&#x0A;- &quot;onStop&quot; if the onStop input has been activated.&#x0A;- &quot;wordRecognised&quot; if the exit command has been understood.&#x0A;- &quot;onTactileSensor&quot; if the user has tapped the tactile sensor of the robot.&#x0A;- an integer being the number of the external choice in the input list.' id="5" />
                                                <Output name="output_1" type="0" type_size="1" nature="2" inner="0" tooltip="This IO has been automatically added by box. Read box tooltip for more information." id="6" />
                                                <Output name="output_2" type="0" type_size="1" nature="2" inner="0" tooltip="This IO has been automatically added by box. Read box tooltip for more information." id="7" />
                                                <Output name="output_3" type="0" type_size="1" nature="2" inner="0" tooltip="This IO has been automatically added by box. Read box tooltip for more information." id="8" />
                                                <Parameter name="Minimum threshold to understand" inherits_from_parent="0" content_type="2" value="0.2" default_value="0.2" min="0" max="1" tooltip="Minimum threshold to get in order to be understood by the robot." id="9" />
                                                <Parameter name="Minimum threshold to be sure" inherits_from_parent="0" content_type="2" value="0.3" default_value="0.3" min="0" max="1" tooltip="Minimum threshold to get so that the robot would be sure about the user&apos;s&#x0A;answer. Below this threshold, the robot asks a confirmation about what has been&#x0A;understood." id="10" />
                                                <Parameter name="Speech recognition timeout when confirmation" inherits_from_parent="0" content_type="1" value="6" default_value="6" min="1" max="20" tooltip="When the robot asks if what he understood is correct, after this time, if there has been&#x0A;nothing heard, the speech recognition is stopped and the answer understood is&#x0A;considered as correct." id="11" />
                                                <Parameter name="Speech recognition timeout" inherits_from_parent="0" content_type="1" value="6" default_value="6" min="1" max="20" tooltip="After this time, if there has been nothing heard, the speech recognition is stopped&#x0A;and the question is repeated or is skipped." id="12" />
                                                <Parameter name="Maximum number of repetition when no reply" inherits_from_parent="0" content_type="1" value="3" default_value="3" min="1" max="20" tooltip='After this number of times when the user did not reply, the question is skipped, and&#x0A;the output other is stimulated with &quot;timeout&quot;.' id="13" />
                                                <Parameter name="Repeat validated choice" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="If this option is activated, the robot repeats the validated choice when it exits the box." id="14" />
                                                <Parameter name="Activate ears light" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="Activate ears light animation (turn, flash, etc...)." id="15" />
                                                <Parameter name="Activate eyes light" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="Activate eyes light animation (turn, flash, etc...)." id="16" />
                                                <Parameter name="Activate brain light" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="Activate brain light animation (turn, flash, etc...)." id="17" />
                                                <Parameter name="Tactile sensor menu timeout" inherits_from_parent="0" content_type="1" value="10" default_value="10" min="1" max="20" tooltip="After this time, if there has been no action made on the tactile sensor or the torso&#x0A;button, the choice currently selected is repeated or the question is skipped." id="18" />
                                                <Parameter name="Maximum number of repetition when failure" inherits_from_parent="0" content_type="1" value="5" default_value="5" min="1" max="20" tooltip='After this number of times when the robot did not understand the user, the question&#x0A;is skipped, and the output other is stimulated with &quot;notUnderstood&quot;.' id="19" />
                                                <Parameter name="Activate help when failure" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="When this parameter is activated, when the robot did not understand the user, he&#x0A;says some help enumerating available choices and attracting attention on the&#x0A;other available modalities (head tactile sensor)." id="20" />
                                                <Parameter name="Activate help command" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip='Enable the help command. So you can say &quot;help&quot; during the speech recognition&#x0A;and the robot will tell you more information.&#x0A;You will still be able to ask help by clicking the torso button.' id="21" />
                                                <Parameter name="Activate repeat command" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip='Activate the repeat command. So you can say &quot;repeat&quot; during the speech&#x0A;recognition and the robot will repeat the question.' id="22" />
                                                <Parameter name="Activate exit command" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip='Enable the exit command. So you can say &quot;exit&quot; during the speech recognition&#x0A;and the box will be stopped and the &apos;other&apos; output will be stimulated with&#x0A;&quot;wordRecognised&quot;.&#x0A;You will still be able to exit the box with&#x0A;the tactile sensor.' id="23" />
                                                <Parameter name="Sentences file" inherits_from_parent="0" content_type="4" value="/Aldebaran/choice_sentences_light.xml" default_value="/Aldebaran/choice_sentences_light.xml" tooltip="File containing all necessary sentences in each supported language." id="24" />
                                            </Box>
                                            <Box name="Localized Text" id="5" localization="8" tooltip="Send on the output the text associated with the robot&apos;s current voice language.&#x0A;You can display and edit the text associated with any language by&#x0A;selecting the language in the combobox.&#x0A;&#x0A;!!Warning!! The text sent on the output is NOT the displayed one but the one&#x0A;associated with the robot&apos;s current voice language." plugin="localizationbox_plugin" x="59" y="54">
                                                <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		try: # disable autoBind
			GeneratedClass.__init__(self, False)
		except TypeError: # if NAOqi < 1.14
			GeneratedClass.__init__( self )

		self.tts = ALProxy("ALTextToSpeech")
		self.sentences = {
			"Arabic" : "  ",
			"Czech" : " Máš rád čokoládu? ",
			"Danish" : " Kan du lide chokolade? ",
			"German" : " Mögen Sie Schokolade? ",
			"Greek" : "  ",
			"English" : " A oes gennych apwyntiad ",
			"Spanish" : " ¿Te gusta el chocolate? ",
			"Finnish" : " Pidätkö suklaasta? ",
			"French" : " Aimes-tu le chocolat ? ",
			"Italian" : " Ti piace il cioccolato? ",
			"Japanese" : " チョコレートが好きですか ",
			"Korean" : " 당신은 초콜렛을 좋아합니까? ",
			"Dutch" : " Hou je van chocolade? ",
			"Norwegian" : "  ",
			"Polish" : " Lubisz czekoladę? ",
			"Brazilian" : " Você gosta de chocolate? ",
			"Portuguese" : " Gostas de chocolate? ",
			"Russian" : " Вы любите шоколад? ",
			"Swedish" : " Gillar du choklad? ",
			"Turkish" : " Çikolata sever misin? ",
			"Chinese" : "  "
		}

	def onInput_onStart(self):
		sDefaultLang = self.tts.getLanguage()
		self.onStopped(self.sentences[sDefaultLang])]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <![CDATA[]]>
</arabic>
                                                    <czech>
                                                        <![CDATA[Máš rád čokoládu?]]>
</czech>
                                                    <danish>
                                                        <![CDATA[Kan du lide chokolade?]]>
</danish>
                                                    <german>
                                                        <![CDATA[Mögen Sie Schokolade?]]>
</german>
                                                    <greek>
                                                        <![CDATA[]]>
</greek>
                                                    <english>
                                                        <![CDATA[A oes gennych apwyntiad]]>
</english>
                                                    <spanish>
                                                        <![CDATA[¿Te gusta el chocolate?]]>
</spanish>
                                                    <finnish>
                                                        <![CDATA[Pidätkö suklaasta?]]>
</finnish>
                                                    <french>
                                                        <![CDATA[Aimes-tu le chocolat ?]]>
</french>
                                                    <italian>
                                                        <![CDATA[Ti piace il cioccolato?]]>
</italian>
                                                    <japanese>
                                                        <![CDATA[チョコレートが好きですか]]>
</japanese>
                                                    <korean>
                                                        <![CDATA[당신은 초콜렛을 좋아합니까?]]>
</korean>
                                                    <dutch>
                                                        <![CDATA[Hou je van chocolade?]]>
</dutch>
                                                    <norwegian>
                                                        <![CDATA[]]>
</norwegian>
                                                    <polish>
                                                        <![CDATA[Lubisz czekoladę?]]>
</polish>
                                                    <brazilian>
                                                        <![CDATA[Você gosta de chocolate?]]>
</brazilian>
                                                    <portuguese>
                                                        <![CDATA[Gostas de chocolate?]]>
</portuguese>
                                                    <russian>
                                                        <![CDATA[Вы любите шоколад?]]>
</russian>
                                                    <swedish>
                                                        <![CDATA[Gillar du choklad?]]>
</swedish>
                                                    <turkish>
                                                        <![CDATA[Çikolata sever misin?]]>
</turkish>
                                                    <chinese>
                                                        <![CDATA[]]>
</chinese>
                                                    <language>5</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Data is sent on the output when this input is stimulated." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Data sent when asked." id="3" />
                                            </Box>
                                            <Link inputowner="1" indexofinput="2" outputowner="5" indexofoutput="3" />
                                            <Link inputowner="5" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="0" indexofinput="4" outputowner="1" indexofoutput="5" />
                                            <Link inputowner="0" indexofinput="5" outputowner="1" indexofoutput="6" />
                                            <Link inputowner="0" indexofinput="5" outputowner="1" indexofoutput="7" />
                                            <Link inputowner="0" indexofinput="6" outputowner="1" indexofoutput="8" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Speech" type="Lock" timeout="0" />
                            <Resource name="Speech recognition" type="Lock" timeout="0" />
                        </Box>
                        <Box name="How to make appointment online (1)" id="18" localization="8" tooltip="Nao gives user information on how to make appointment online " x="850" y="1603">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean." id="6" />
                            <Parameter name="Body language mode" inherits_from_parent="0" content_type="3" value="contextual" default_value="contextual" custom_choice="0" tooltip="Change the body language mode during the speech.&#x0A;disabled: The robot will only play the animations given by the user. ex: ^start(...) or ^tag(...)&#x0A;random: During time the robot has no animation to play, he will launch random neutral animations.&#x0A;contextual: During time the robot has no animation to play, he will try to launch a new one accordingly to the saying text. Every time the robot can&apos;t find a contextual animation he will launch a random neutral animation." id="7">
                                <Choice value="disabled" />
                                <Choice value="random" />
                                <Choice value="contextual" />
                            </Parameter>
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Animated Say Text" id="2" localization="8" tooltip="Say the text received on its input and move during its speech." x="422" y="65">
                                                <bitmap>media/images/box/interaction/say.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.animSpeech = ALProxy('ALAnimatedSpeech')

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.animSpeech.stop(id)
            except:
                pass

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            configuration =\
            {"bodyLanguageMode":self.getParameter("Body language mode")}
            id = self.animSpeech.post.say(str(sentence), configuration)
            self.ids.append(id)
            self.animSpeech.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                                                <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                                                <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                                                <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                                                <Parameter name="Body language mode" inherits_from_parent="1" content_type="3" value="contextual" default_value="contextual" custom_choice="0" tooltip="Change the body language mode during the speech.&#x0A;disabled: The robot will only play the animations given by the user. ex: ^start(...) or ^tag(...)&#x0A;random: During time the robot has no animation to play, he will launch random neutral animations.&#x0A;contextual: During time the robot has no animation to play, he will try to launch a new one accordingly to the saying text. Every time the robot can&apos;t find a contextual animation he will launch a random neutral animation." id="7">
                                                    <Choice value="disabled" />
                                                    <Choice value="random" />
                                                    <Choice value="contextual" />
                                                </Parameter>
                                            </Box>
                                            <Box name="Localized Text" id="5" localization="8" tooltip="Send on the output the text associated with the robot&apos;s current voice language.&#x0A;You can display and edit the text associated with any language by&#x0A;selecting the language in the combobox.&#x0A;&#x0A;!!Warning!! The text sent on the output is NOT the displayed one but the one&#x0A;associated with the robot&apos;s current voice language." plugin="localizationbox_plugin" x="114" y="68">
                                                <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		try: # disable autoBind
			GeneratedClass.__init__(self, False)
		except TypeError: # if NAOqi < 1.14
			GeneratedClass.__init__( self )

		self.tts = ALProxy("ALTextToSpeech")
		self.sentences = {
			"Arabic" : "  ",
			"Czech" : " ^start(animations/Stand/Gestures/Hey_1) Ahoj ^wait(animations/Stand/Gestures/Hey_1) ",
			"Danish" : " ^start(animations/Stand/Gestures/Hey_1) Hej ^wait(animations/Stand/Gestures/Hey_1) ",
			"German" : " ^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1) ",
			"Greek" : "  ",
			"English" : " Ewch i\'n gwefan am fwy o wybodaeth am drefnu apwyntiad ",
			"Spanish" : " ^start(animations/Stand/Gestures/Hey_1) Hola ^wait(animations/Stand/Gestures/Hey_1) ",
			"Finnish" : " ^start(animations/Stand/Gestures/Hey_1) Hei ^wait(animations/Stand/Gestures/Hey_1) ",
			"French" : " ^start(animations/Stand/Gestures/Hey_1) Bonjour ^wait(animations/Stand/Gestures/Hey_1) ",
			"Italian" : " ^start(animations/Stand/Gestures/Hey_1) Ciao ^wait(animations/Stand/Gestures/Hey_1) ",
			"Japanese" : " ^start(animations/Stand/Gestures/Hey_1) こんにちは ^wait(animations/Stand/Gestures/Hey_1) ",
			"Korean" : " ^start(animations/Stand/Gestures/Hey_1) 안녕하세요 ^wait(animations/Stand/Gestures/Hey_1) ",
			"Dutch" : " ^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1) ",
			"Norwegian" : "  ",
			"Polish" : " ^start(animations/Stand/Gestures/Hey_1) Cześć ^wait(animations/Stand/Gestures/Hey_1) ",
			"Brazilian" : " ^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1) ",
			"Portuguese" : " ^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1) ",
			"Russian" : " ^start(animations/Stand/Gestures/Hey_1) Привет ^wait(animations/Stand/Gestures/Hey_1) ",
			"Swedish" : " ^start(animations/Stand/Gestures/Hey_1) Hallå ^wait(animations/Stand/Gestures/Hey_1) ",
			"Turkish" : " ^start(animations/Stand/Gestures/Hey_1) Merhaba ^wait(animations/Stand/Gestures/Hey_1) ",
			"Chinese" : "  "
		}

	def onInput_onStart(self):
		sDefaultLang = self.tts.getLanguage()
		self.onStopped(self.sentences[sDefaultLang])]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <![CDATA[]]>
</arabic>
                                                    <czech>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Ahoj ^wait(animations/Stand/Gestures/Hey_1)]]>
</czech>
                                                    <danish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hej ^wait(animations/Stand/Gestures/Hey_1)]]>
</danish>
                                                    <german>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1)]]>
</german>
                                                    <greek>
                                                        <![CDATA[]]>
</greek>
                                                    <english>
                                                        <![CDATA[Ewch i'n gwefan am fwy o wybodaeth am drefnu apwyntiad]]>
</english>
                                                    <spanish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hola ^wait(animations/Stand/Gestures/Hey_1)]]>
</spanish>
                                                    <finnish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hei ^wait(animations/Stand/Gestures/Hey_1)]]>
</finnish>
                                                    <french>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Bonjour ^wait(animations/Stand/Gestures/Hey_1)]]>
</french>
                                                    <italian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Ciao ^wait(animations/Stand/Gestures/Hey_1)]]>
</italian>
                                                    <japanese>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) こんにちは ^wait(animations/Stand/Gestures/Hey_1)]]>
</japanese>
                                                    <korean>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) 안녕하세요 ^wait(animations/Stand/Gestures/Hey_1)]]>
</korean>
                                                    <dutch>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1)]]>
</dutch>
                                                    <norwegian>
                                                        <![CDATA[]]>
</norwegian>
                                                    <polish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Cześć ^wait(animations/Stand/Gestures/Hey_1)]]>
</polish>
                                                    <brazilian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1)]]>
</brazilian>
                                                    <portuguese>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1)]]>
</portuguese>
                                                    <russian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Привет ^wait(animations/Stand/Gestures/Hey_1)]]>
</russian>
                                                    <swedish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallå ^wait(animations/Stand/Gestures/Hey_1)]]>
</swedish>
                                                    <turkish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Merhaba ^wait(animations/Stand/Gestures/Hey_1)]]>
</turkish>
                                                    <chinese>
                                                        <![CDATA[]]>
</chinese>
                                                    <language>5</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Data is sent on the output when this input is stimulated." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Data sent when asked." id="3" />
                                            </Box>
                                            <Link inputowner="0" indexofinput="4" outputowner="2" indexofoutput="4" />
                                            <Link inputowner="5" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="2" indexofinput="2" outputowner="5" indexofoutput="3" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Appointment date (1)" id="20" localization="8" tooltip="Nao asks user their prefered appointment time" x="838" y="1307">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean." id="6" />
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Say Text" id="2" localization="8" tooltip="Say the text received on its input." x="422" y="65">
                                                <bitmap>media/images/box/interaction/say.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.tts = ALProxy('ALTextToSpeech')
        self.ttsStop = ALProxy('ALTextToSpeech', True) #Create another proxy as wait is blocking if audioout is remote

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            id = self.tts.post.say(str(sentence))
            self.ids.append(id)
            self.tts.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                                                <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                                                <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                                                <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                                            </Box>
                                            <Box name="Localized Text" id="5" localization="8" tooltip="Send on the output the text associated with the robot&apos;s current voice language.&#x0A;You can display and edit the text associated with any language by&#x0A;selecting the language in the combobox.&#x0A;&#x0A;!!Warning!! The text sent on the output is NOT the displayed one but the one&#x0A;associated with the robot&apos;s current voice language." plugin="localizationbox_plugin" x="114" y="68">
                                                <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		try: # disable autoBind
			GeneratedClass.__init__(self, False)
		except TypeError: # if NAOqi < 1.14
			GeneratedClass.__init__( self )

		self.tts = ALProxy("ALTextToSpeech")
		self.sentences = {
			"Arabic" : "  ",
			"Czech" : " Ahoj ",
			"Danish" : " Hej ",
			"German" : " Hallo ",
			"Greek" : "  ",
			"English" : " Rhowch wybod i mi pa ddyddiad ac amser yr hoffech gael eich apwyntiad. ",
			"Spanish" : " Hola ",
			"Finnish" : " Hei ",
			"French" : " Bonjour ",
			"Italian" : " Ciao ",
			"Japanese" : " こんにちは ",
			"Korean" : " 안녕하세요 ",
			"Dutch" : " Hallo ",
			"Norwegian" : "  ",
			"Polish" : " Cześć ",
			"Brazilian" : " Olá ",
			"Portuguese" : " Olá ",
			"Russian" : " Привет ",
			"Swedish" : " Hallå ",
			"Turkish" : " Merhaba ",
			"Chinese" : "  "
		}

	def onInput_onStart(self):
		sDefaultLang = self.tts.getLanguage()
		self.onStopped(self.sentences[sDefaultLang])]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <![CDATA[]]>
</arabic>
                                                    <czech>
                                                        <![CDATA[Ahoj]]>
</czech>
                                                    <danish>
                                                        <![CDATA[Hej]]>
</danish>
                                                    <german>
                                                        <![CDATA[Hallo]]>
</german>
                                                    <greek>
                                                        <![CDATA[]]>
</greek>
                                                    <english>
                                                        <![CDATA[Rhowch wybod i mi pa ddyddiad ac amser yr hoffech gael eich apwyntiad.]]>
</english>
                                                    <spanish>
                                                        <![CDATA[Hola]]>
</spanish>
                                                    <finnish>
                                                        <![CDATA[Hei]]>
</finnish>
                                                    <french>
                                                        <![CDATA[Bonjour]]>
</french>
                                                    <italian>
                                                        <![CDATA[Ciao]]>
</italian>
                                                    <japanese>
                                                        <![CDATA[こんにちは]]>
</japanese>
                                                    <korean>
                                                        <![CDATA[안녕하세요]]>
</korean>
                                                    <dutch>
                                                        <![CDATA[Hallo]]>
</dutch>
                                                    <norwegian>
                                                        <![CDATA[]]>
</norwegian>
                                                    <polish>
                                                        <![CDATA[Cześć]]>
</polish>
                                                    <brazilian>
                                                        <![CDATA[Olá]]>
</brazilian>
                                                    <portuguese>
                                                        <![CDATA[Olá]]>
</portuguese>
                                                    <russian>
                                                        <![CDATA[Привет]]>
</russian>
                                                    <swedish>
                                                        <![CDATA[Hallå]]>
</swedish>
                                                    <turkish>
                                                        <![CDATA[Merhaba]]>
</turkish>
                                                    <chinese>
                                                        <![CDATA[]]>
</chinese>
                                                    <language>5</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Data is sent on the output when this input is stimulated." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Data sent when asked." id="3" />
                                            </Box>
                                            <Link inputowner="0" indexofinput="4" outputowner="2" indexofoutput="4" />
                                            <Link inputowner="5" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="2" indexofinput="2" outputowner="5" indexofoutput="3" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Email address (1)" id="21" localization="8" tooltip="Nao asks user their email address " x="1060" y="1491">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean." id="6" />
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Say Text" id="2" localization="8" tooltip="Say the text received on its input." x="422" y="65">
                                                <bitmap>media/images/box/interaction/say.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.tts = ALProxy('ALTextToSpeech')
        self.ttsStop = ALProxy('ALTextToSpeech', True) #Create another proxy as wait is blocking if audioout is remote

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            id = self.tts.post.say(str(sentence))
            self.ids.append(id)
            self.tts.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                                                <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                                                <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                                                <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                                            </Box>
                                            <Box name="Localized Text" id="5" localization="8" tooltip="Send on the output the text associated with the robot&apos;s current voice language.&#x0A;You can display and edit the text associated with any language by&#x0A;selecting the language in the combobox.&#x0A;&#x0A;!!Warning!! The text sent on the output is NOT the displayed one but the one&#x0A;associated with the robot&apos;s current voice language." plugin="localizationbox_plugin" x="114" y="68">
                                                <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		try: # disable autoBind
			GeneratedClass.__init__(self, False)
		except TypeError: # if NAOqi < 1.14
			GeneratedClass.__init__( self )

		self.tts = ALProxy("ALTextToSpeech")
		self.sentences = {
			"Arabic" : "  ",
			"Czech" : " Ahoj ",
			"Danish" : " Hej ",
			"German" : " Hallo ",
			"Greek" : "  ",
			"English" : " Beth yw’ch cyfeiriad e-bost ",
			"Spanish" : " Hola ",
			"Finnish" : " Hei ",
			"French" : " Bonjour ",
			"Italian" : " Ciao ",
			"Japanese" : " こんにちは ",
			"Korean" : " 안녕하세요 ",
			"Dutch" : " Hallo ",
			"Norwegian" : "  ",
			"Polish" : " Cześć ",
			"Brazilian" : " Olá ",
			"Portuguese" : " Olá ",
			"Russian" : " Привет ",
			"Swedish" : " Hallå ",
			"Turkish" : " Merhaba ",
			"Chinese" : "  "
		}

	def onInput_onStart(self):
		sDefaultLang = self.tts.getLanguage()
		self.onStopped(self.sentences[sDefaultLang])]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <![CDATA[]]>
</arabic>
                                                    <czech>
                                                        <![CDATA[Ahoj]]>
</czech>
                                                    <danish>
                                                        <![CDATA[Hej]]>
</danish>
                                                    <german>
                                                        <![CDATA[Hallo]]>
</german>
                                                    <greek>
                                                        <![CDATA[]]>
</greek>
                                                    <english>
                                                        <![CDATA[Beth yw’ch cyfeiriad e-bost]]>
</english>
                                                    <spanish>
                                                        <![CDATA[Hola]]>
</spanish>
                                                    <finnish>
                                                        <![CDATA[Hei]]>
</finnish>
                                                    <french>
                                                        <![CDATA[Bonjour]]>
</french>
                                                    <italian>
                                                        <![CDATA[Ciao]]>
</italian>
                                                    <japanese>
                                                        <![CDATA[こんにちは]]>
</japanese>
                                                    <korean>
                                                        <![CDATA[안녕하세요]]>
</korean>
                                                    <dutch>
                                                        <![CDATA[Hallo]]>
</dutch>
                                                    <norwegian>
                                                        <![CDATA[]]>
</norwegian>
                                                    <polish>
                                                        <![CDATA[Cześć]]>
</polish>
                                                    <brazilian>
                                                        <![CDATA[Olá]]>
</brazilian>
                                                    <portuguese>
                                                        <![CDATA[Olá]]>
</portuguese>
                                                    <russian>
                                                        <![CDATA[Привет]]>
</russian>
                                                    <swedish>
                                                        <![CDATA[Hallå]]>
</swedish>
                                                    <turkish>
                                                        <![CDATA[Merhaba]]>
</turkish>
                                                    <chinese>
                                                        <![CDATA[]]>
</chinese>
                                                    <language>5</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Data is sent on the output when this input is stimulated." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Data sent when asked." id="3" />
                                            </Box>
                                            <Link inputowner="0" indexofinput="4" outputowner="2" indexofoutput="4" />
                                            <Link inputowner="5" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="2" indexofinput="2" outputowner="5" indexofoutput="3" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Send E-mail (1)" id="27" localization="8" tooltip="Send an e-mail. Set all parameters of this e-mail before sending it.&#x0A;&#x0A;!!Warning!! The Password has to be hardcoded inside the behavior, and will not&#x0A;be encrypted or hidden. You should create an e-mail account for your robot, that&#x0A;uses a password that you are comfortable to leave un-encrypted." x="1223" y="1501">
                            <bitmap>media/images/box/internet/email.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import sys, os
import smtplib, email

def mail(email_user, to, subject, text, attach, email_pwd, smtp, port):
  msg = email.MIMEMultipart.MIMEMultipart()
  msg['From'] = email_user
  msg['To'] = to
  msg['Subject'] = subject

  msg.attach(email.MIMEText.MIMEText(text))

  if attach:
     part = email.MIMEBase.MIMEBase('application', 'octet-stream')
     part.set_payload(open(attach, 'rb').read())
     email.Encoders.encode_base64(part)
     part.add_header('Content-Disposition',
             'attachment; filename="%s"' % os.path.basename(attach))
     msg.attach(part)

  if( port != "" ):
      mailServer = smtplib.SMTP(smtp, port)
  else:
      mailServer = smtplib.SMTP(smtp)
  mailServer.ehlo()
  mailServer.starttls()
  mailServer.ehlo()
  mailServer.login(email_user, email_pwd)
  mailServer.sendmail(email_user, to, msg.as_string())

  mailServer.close()

class MyClass(GeneratedClass):
  def __init__(self):
    GeneratedClass.__init__(self, False)

  def onLoad(self):
    pass

  def onUnload(self):
    #puts code for box cleanup here
    pass

  def onInput_onSend(self):
    sEmailUser = self.getParameter("From")
    aTo = self.getParameter("To").split(";")
    sSubject = self.getParameter("Subject")
    sText = self.getParameter("Contents")
    sAttachedFilePath = self.getParameter("Attachment")
    sPwd = self.getParameter("Password")
    sSmtp = self.getParameter("SMTP address")
    sPort = int( self.getParameter("Port number") )
    try:
        sPort = int( sPort )
        bValidPort = ( sPort >= 0 and sPort <= 65535 )
    except:
        bValidPort = False
    if( not bValidPort ):
        raise Exception( str(sPort) + " is not a valid port number to use to send e-mail. It must be an integer between 0 and 65535. Please check that the port parameter of the box is correct." )
    for address in aTo:
      try:
        mail(
          sEmailUser,
          address,
          sSubject,
          sText,
          sAttachedFilePath,
          sPwd,
          sSmtp,
          sPort)
      except smtplib.SMTPAuthenticationError as e:
        raise(Exception("Authentication error, server answered : [%s] %s" % (e.smtp_code, e.smtp_error)))


    self.onSent() # activate output of the box]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onSend" type="1" type_size="1" nature="1" inner="0" tooltip="Send the e-mail." id="2" />
                            <Output name="onSent" type="1" type_size="1" nature="2" inner="0" tooltip="E-mail sent." id="3" />
                            <Output name="onError" type="3" type_size="1" nature="2" inner="0" tooltip="" id="4" />
                            <Parameter name="From" inherits_from_parent="0" content_type="3" value="myemail@email.com" default_value="myemail@email.com" custom_choice="0" tooltip="E-mail address of the sender." id="5" />
                            <Parameter name="Password" inherits_from_parent="0" content_type="3" value="" default_value="" custom_choice="0" password="1" tooltip="Password of your e-mail account." id="6" />
                            <Parameter name="To" inherits_from_parent="0" content_type="3" value="to@email.com" default_value="to@email.com" custom_choice="0" tooltip="Receiver(s) of the e-mail. Separate e-mail addresses by &apos;;&apos;." id="7" />
                            <Parameter name="Subject" inherits_from_parent="0" content_type="3" value="" default_value="" custom_choice="0" tooltip="Subject of the e-mail." id="8" />
                            <Parameter name="Contents" inherits_from_parent="0" content_type="3" value="" default_value="" custom_choice="0" tooltip="Contents of the e-mail." id="9" />
                            <Parameter name="Attachment" inherits_from_parent="0" content_type="3" value="" default_value="" custom_choice="0" tooltip="Attachment path." id="10" />
                            <Parameter name="SMTP address" inherits_from_parent="0" content_type="3" value="smtp.email.com" default_value="smtp.email.com" custom_choice="0" tooltip="SMTP server this box is supposed to use." id="11" />
                            <Parameter name="Port number" inherits_from_parent="0" content_type="3" value="587" default_value="587" custom_choice="1" tooltip="Port of the server to use.&#x0A;&#x0A;Note: For example, for a gmail address to use TLS/STARTTLS you need to set the&#x0A;port to 587, and to use SSL you need to set it to 465." id="12">
                                <Choice value="587" />
                                <Choice value="465" />
                            </Parameter>
                        </Box>
                        <Box name="Email conformation  (1)" id="28" localization="8" tooltip="Nao confirms that the email has sent " x="1425" y="1510">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean." id="6" />
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Say Text" id="2" localization="8" tooltip="Say the text received on its input." x="422" y="65">
                                                <bitmap>media/images/box/interaction/say.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.tts = ALProxy('ALTextToSpeech')
        self.ttsStop = ALProxy('ALTextToSpeech', True) #Create another proxy as wait is blocking if audioout is remote

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            id = self.tts.post.say(str(sentence))
            self.ids.append(id)
            self.tts.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                                                <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                                                <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                                                <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                                            </Box>
                                            <Box name="Localized Text" id="5" localization="8" tooltip="Send on the output the text associated with the robot&apos;s current voice language.&#x0A;You can display and edit the text associated with any language by&#x0A;selecting the language in the combobox.&#x0A;&#x0A;!!Warning!! The text sent on the output is NOT the displayed one but the one&#x0A;associated with the robot&apos;s current voice language." plugin="localizationbox_plugin" x="114" y="68">
                                                <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		try: # disable autoBind
			GeneratedClass.__init__(self, False)
		except TypeError: # if NAOqi < 1.14
			GeneratedClass.__init__( self )

		self.tts = ALProxy("ALTextToSpeech")
		self.sentences = {
			"Arabic" : "  ",
			"Czech" : " Ahoj ",
			"Danish" : " Hej ",
			"German" : " Hallo ",
			"Greek" : "  ",
			"English" : " Anfon e-bost ",
			"Spanish" : " Hola ",
			"Finnish" : " Hei ",
			"French" : " Bonjour ",
			"Italian" : " Ciao ",
			"Japanese" : " こんにちは ",
			"Korean" : " 안녕하세요 ",
			"Dutch" : " Hallo ",
			"Norwegian" : "  ",
			"Polish" : " Cześć ",
			"Brazilian" : " Olá ",
			"Portuguese" : " Olá ",
			"Russian" : " Привет ",
			"Swedish" : " Hallå ",
			"Turkish" : " Merhaba ",
			"Chinese" : "  "
		}

	def onInput_onStart(self):
		sDefaultLang = self.tts.getLanguage()
		self.onStopped(self.sentences[sDefaultLang])]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <![CDATA[]]>
</arabic>
                                                    <czech>
                                                        <![CDATA[Ahoj]]>
</czech>
                                                    <danish>
                                                        <![CDATA[Hej]]>
</danish>
                                                    <german>
                                                        <![CDATA[Hallo]]>
</german>
                                                    <greek>
                                                        <![CDATA[]]>
</greek>
                                                    <english>
                                                        <![CDATA[Anfon e-bost]]>
</english>
                                                    <spanish>
                                                        <![CDATA[Hola]]>
</spanish>
                                                    <finnish>
                                                        <![CDATA[Hei]]>
</finnish>
                                                    <french>
                                                        <![CDATA[Bonjour]]>
</french>
                                                    <italian>
                                                        <![CDATA[Ciao]]>
</italian>
                                                    <japanese>
                                                        <![CDATA[こんにちは]]>
</japanese>
                                                    <korean>
                                                        <![CDATA[안녕하세요]]>
</korean>
                                                    <dutch>
                                                        <![CDATA[Hallo]]>
</dutch>
                                                    <norwegian>
                                                        <![CDATA[]]>
</norwegian>
                                                    <polish>
                                                        <![CDATA[Cześć]]>
</polish>
                                                    <brazilian>
                                                        <![CDATA[Olá]]>
</brazilian>
                                                    <portuguese>
                                                        <![CDATA[Olá]]>
</portuguese>
                                                    <russian>
                                                        <![CDATA[Привет]]>
</russian>
                                                    <swedish>
                                                        <![CDATA[Hallå]]>
</swedish>
                                                    <turkish>
                                                        <![CDATA[Merhaba]]>
</turkish>
                                                    <chinese>
                                                        <![CDATA[]]>
</chinese>
                                                    <language>5</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Data is sent on the output when this input is stimulated." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Data sent when asked." id="3" />
                                            </Box>
                                            <Link inputowner="0" indexofinput="4" outputowner="2" indexofoutput="4" />
                                            <Link inputowner="5" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="2" indexofinput="2" outputowner="5" indexofoutput="3" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Blink" id="29" localization="8" tooltip="This box makes the robot blink once." x="1196" y="1273">
                            <bitmap>media/images/box/interaction/LED.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.leds = ALProxy("ALLeds")

    def onUnload(self):
        #~ puts code for box cleanup here
        pass

    def onInput_onStart(self):
        rDuration = 0.05
        self.leds.post.fadeRGB( "FaceLed0", 0x000000, rDuration )
        self.leds.post.fadeRGB( "FaceLed1", 0x000000, rDuration )
        self.leds.post.fadeRGB( "FaceLed2", 0xffffff, rDuration )
        self.leds.post.fadeRGB( "FaceLed3", 0x000000, rDuration )
        self.leds.post.fadeRGB( "FaceLed4", 0x000000, rDuration )
        self.leds.post.fadeRGB( "FaceLed5", 0x000000, rDuration )
        self.leds.post.fadeRGB( "FaceLed6", 0xffffff, rDuration )
        self.leds.fadeRGB( "FaceLed7", 0x000000, rDuration )
        time.sleep( 0.1 )
        self.leds.fadeRGB( "FaceLeds", 0xffffff, rDuration )
        self.onDone()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Output name="onDone" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="3" />
                        </Box>
                        <Box name="Choice (light) (5)" id="38" localization="8" tooltip="Launch speech recognition, and wait for one of a defined number of expected answers (written in the table of the box). the robot will prompt the speaker if he cannot understand and give suggestions as to available answers and other ways of selecting your choice. e.g. The tactile sensor on his head.&#x0A;&#x0A;Note that you must open this box to enter the question text and the available answers.&#x0A;&#x0A;This is a lighter version of Choice box from standard library which has no animation embedded.&#x0A;&#x0A;V1.1.0&#x0A;" x="693" y="1433">
                            <bitmap>media/images/box/interaction/choice.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                            <Output name="answer" type="3" type_size="1" nature="1" inner="0" tooltip="Answer recognized." id="5" />
                            <Output name="yes" type="1" type_size="1" nature="1" inner="0" tooltip="" id="6" />
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Choice" id="1" localization="8" tooltip="Launch the speech recognition waiting for a defined number of predicted answers (written in the table on the box). Available help&#x0A;from the robot which gives some possible answers and attracts attention on the other modalities to answer (head tactile sensor).&#x0A;&#x0A;You can edit a choice by left double-clicking on the line. You can add a choice by right clicking on a line and selecting &apos;Insert a&#x0A;row&apos;. You can delete a choice by right clicking on a line and selecting &apos;Remove a row&apos;. You can also write several alternative&#x0A;answers for the same choice by writing them on the line separated by the character &apos;/&apos;.&#x0A;Ex: apple pie / pie / apple&#x0A;Then if any of these answers (&apos;apple pie&apos;, &apos;pie&apos; or &apos;apple&apos;) are said, the corresponding output will be activated. Indeed, each output&#x0A;which name begins with &apos;output_&apos; correspond to the choice in the list placed just in front of the output.&#x0A;&#x0A;Moreover, you have advanced options appearing when you click on the blue cross. Then you can make the robot calculate the threshold&#x0A;average of choices with the 1/2/3 button. Actually, it will calculate recognition threshold of each alternative answer and put them from&#x0A;highest to smallest threshold. The threshold displayed in front of each choice then is the highest&apos;s." plugin="ui_choice_plugin" x="312" y="51">
                                                <bitmap>media/images/box/interaction/choice.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
# -*- coding: utf-8 -*-
# script of the Choice box v8.8
# @author Desktop Application team
# (c) 2011 Aldebaran Robotics

import os
import time
import random
import thread
import mutex
import xml.dom.minidom

class MyClass(GeneratedClass):
    def __init__(self):
        try: # disable autoBind
          GeneratedClass.__init__(self, False)
        except TypeError: # if NAOqi < 1.14
          GeneratedClass.__init__( self )

        # PROXIES INITIALIZATION
        self.tts = ALProxy("ALTextToSpeech")
        self.ttsStop = ALProxy("ALTextToSpeech", True) #Create another proxy as wait is blocking if audioout is remote
        self.memory = ALProxy("ALMemory")
        try:
            self.asr = ALProxy("ALSpeechRecognition")
            self.ad = ALProxy("ALAudioDevice")
            self.player = ALProxy("ALAudioPlayer")
            self.dcm = ALProxy( "DCM" )
        except:
            self.logger.warning("cannot find ALSpeechRecognition, choice box will run in simulation mode")
            self.asr = None
            self.ad = None
            self.player = None
            self.dcm = None

        self.leds = ALProxy( "ALLeds" )
        # VARIABLES INITIALIZATION
        self.aIdsTTS = []
        self.bSentencesInitialized = False
        self.bMustStop = False
        self.bIsRunning = False
        self.bGoOut = False
        self.nCountNoReply = 0
        self.nCountFailure = 0
        self.aFrameNumbers = {"end" : 1,
                              "headDown" : 10,
                              "bodyTalk" : 20,
                              "reco" : 30,
                              "headCheck" : 40,
                              "helpTactileSensor" : 50,
                              "notUnderstood" : 70}
        self.nFrameNumber = self.aFrameNumbers["end"]
        self.bInConfirmation = False
        self.bVocabularyLoaded = False
        self.bRecoIsHearingOrAnalysing = False
        self.bRecoIsWaitingForVoice = False
        self.bHasAlreadyHearingEyes = False
        self.bInTactileSensorMenu = False
        self.bExternChoices = False
        self.bBrainAnimPaused = False
        self.rTimeLastChoiceSaid = -1.
        self.bIsSayingChoice = False
        self.nIndexChoice = 0
        self.sRecoInterruption = "" # = "wordRecognised" or "timeout" or "onStop" or "onTactileSensor"
        self.sPreviousAnswer = ""
        self.rTimeWhenActionMadeInTactileMenu = -1.
        # variables used for the tactile sensor
        self.nFront = 0
        self.nMiddle = 0
        self.nRear = 0
        self.bSeqStarted = False
        self.bIsStoringParam = False
        self.bPressed = False
        self.mutexProcessCurrentState = mutex.mutex()
        self.mutexTactilTouched = mutex.mutex()
        self.mutexCheckIfSeqsCorrespondingLeft = mutex.mutex()
        self.bSeqStarted = False
        # assuming that every sequence is after [0, 0, 0]
        # and then start with one tactil sensor activated
        # timeout must be either a number (int or float) not equal to 0 or an array of two numbers not equal to 0, a negative one and a positive one
        # a negative timeout means a minimum time that has to ellapse before the next step
        # a positive timeout means a maximum time before the next step must show up
        self.aSeqs = [{"name" : "Tap", "statesAndTimeout" : [ "1+", 0.35, "2+", 0.45, "0" ]},
                      {"name" : "TapFront", "statesAndTimeout" : [ "F", 1, "0" ]},
                      {"name" : "LongFront", "statesAndTimeout" : [ "F", -1, "F" ]},
                      {"name" : "TapMiddle", "statesAndTimeout" : [ "M", 1, "0" ]},
                      {"name" : "LongMiddle", "statesAndTimeout" : [ "M", -1, "M" ]},
                      {"name" : "TapRear", "statesAndTimeout" : [ "R", 1, "0" ]},
                      {"name" : "LongRear", "statesAndTimeout" : [ "R", -1, "R" ]},
                      {"name" : "CalmDown", "statesAndTimeout" : [ "1+", 0.5, "2+", -1, "2+" ]}]
        # sequences initialization
        aSeqsTemp = []
        for seq in self.aSeqs:
            try: # ensure that the sequence has at least a name and states and timeout defined
                seq["name"]
                seq["statesAndTimeout"]
                aSeqsTemp.append(seq)
            except:
                pass
        self.aSeqs = aSeqsTemp
        for seq in self.aSeqs:
            states = range( len( seq["statesAndTimeout"][0:len(seq["statesAndTimeout"]):2] ) )
            i = 0
            for state in seq["statesAndTimeout"][0:len(seq["statesAndTimeout"]):2]:
                states[i] = self.convertToArrayOfPossibleStates(state)
                i += 1
            seq["statesAndTimeout"][0:len(seq["statesAndTimeout"]):2] = states
        self.aDetectedSeqs = []
        self.aDetectedSeqs.extend(self.aSeqs)
        # end - variables used for the tactile sensor
        self.aChoices = []
        self.aChoiceIndexes = []
        # parameters which can be changed from the parameters edition window
        self.sQuestion = ""
        self.nTimeoutReco = 6
        self.nTimeoutRecoConfirmation = 6
        self.nTimeoutTactile = 10
        self.nMaxCountNoReply = 3
        self.nMaxCountFailure = 5
        self.arUnderstoodThreshold = [0.0, 1.0] # range of self.rUnderstoodThreshold
        self.arConfirmationThreshold = [0.0, 1.0] # range of self.rConfirmationThreshold (must be higher than self.arUnderstoodThreshold)
        self.rUnderstoodThreshold = 0.2
        self.rConfirmationThreshold = 0.4
        self.bActivateEyesLight = True
        self.bActivateEarsLight = True
        self.bActivateBrainLight = True
        self.bActivateHelpWhenFailure = True
        self.bRepeatValidatedChoice = True
        self.bActivateDefaultChoiceHelp = True
        self.bActivateDefaultChoiceRepeat = True
        self.bActivateDefaultChoiceExit = True
        self.BIND_PYTHON(self.getName(), "onTactilTouched")
        self.BIND_PYTHON(self.getName(), "onWordRecognized")
        self.BIND_PYTHON(self.getName(), "onSpeechDetected")


# FUNCTIONS ===============================================================================================

    def onLoad(self):
        # initialize sentences for each language
        if( not self.bSentencesInitialized ):
            self.initializeSentences()
            self.bSentencesInitialized = True

# XML PARSER FOR SENTENCES INITIALIZATION
    def initializeSentences(self):
        "Initialize necessary sentences in each language."
        framemanager = ALProxy("ALFrameManager")
        filename = framemanager.getBehaviorPath(self.behaviorId) + self.tryGetParameter( "Sentences file", "/Aldebaran/choice_sentences.xml" )
        if not self.fileExists(filename):
            raise RuntimeError("File " + filename + " could not be found. Please update your Choice box with a newer one from Choregraphe")
        try:
            doc = self.getFileContents( filename )
            dom = xml.dom.minidom.parseString( doc )
        except Exception as e:
            raise Exception( "The " + filename + " file is not in the right format. Check the special characters and that the syntax is correct.\n" + str(e) )
        try:
            tag = "sentences"
            mainBlock = dom.getElementsByTagName( tag )[0]
            tag = "translation"
            aTranslations = mainBlock.getElementsByTagName( tag )
            self.aAllWords = {}
            self.aAllSentences = {}
            for sTranslation in aTranslations:
                sLanguage = sTranslation.getAttribute("language")
                tag = "speechReco"
                blockSpeechReco = sTranslation.getElementsByTagName( tag )[0]
                # variable used for the speech recognition
                self.aAllWords[sLanguage] = {}
                aKinds = ["negative",
                          "positive",
                          "help",
                          "exit",
                          "repeat"]
                for sKind in aKinds:
                    tag = sKind
                    blockWordsForThisKind = blockSpeechReco.getElementsByTagName( sKind )[0]
                    self.aAllWords[sLanguage][sKind] = blockWordsForThisKind.getAttribute( "text" ).encode("utf-8").split("/")
                # end - variable used for the speech recognition
                tag = "tts"
                blockTTS = sTranslation.getElementsByTagName( tag )[0]
                # variable used for the Text-To-Speech
                self.aAllSentences[sLanguage] = {}
                aKinds = ["confirmation",
                          "enumMarks",
                          "helpEnumChoices",
                          "helpEnumDefault",
                          "helpTactile",
                          "notUnderstood",
                          "noQuestion",
                          "notUnderstoodAnims"]
                for sKind in aKinds:
                    tag = sKind
                    blockSentencesForThisKind = blockTTS.getElementsByTagName( sKind )[0]
                    self.aAllSentences[sLanguage][sKind] = blockSentencesForThisKind.getAttribute( "text" ).encode("utf-8").split("/")
                # end - variable used for the Text-To-Speech
        except Exception as e:
            raise Exception( "The " + filename + " file is not in the right format. Check that the '" + tag + "' tag is defined and with the right format.\n" + str(e) )

        # choices
        # !!! don't remove any comments from this variable !!!
        # (they are here to make the plugin work)
        self.aListAllChoices = {"Arabic": ["نعم", "لا", "", ""], "Brazilian": ["sim", "não", "", ""], "Chinese": ["是", "不是", "", ""], "Czech": ["ano", "ne", "", ""], "Danish": ["ja", "nej", "", ""], "Dutch": ["ja", "nee", "", ""], "English": ["", "Na", "Le", ""], "Finnish": ["kyllä", "ei", "", ""], "French": ["oui", "non", "", ""], "German": ["ja", "nein", "", ""], "Greek": ["ναί", "κανένα", "", ""], "Italian": ["sì", "no", "", ""], "Japanese": ["はい", "いいえ", "", ""], "Korean": ["예", "아니", "", ""], "Norwegian": ["ja", "Nei", "", ""], "Polish": ["tak", "nie", "", ""], "Portuguese": ["sim", "não", "", ""], "Russian": ["да", "нет", "", ""], "Spanish": ["si", "no", "", ""], "Swedish": ["ja", "ingen", "", ""], "Turkish": ["evet", "hayır", "", ""]
                               }
        # end - choices

# INPUTS ACTIVATION PROCESSING ------------------------------------------------------------------------------
    def onInput_onStart(self, question=None):
        "Initialize variables and start box behaviour."
        self.logger.debug( "Input onStart stimulated." )
        if( self.bIsRunning): # to avoid starting the process twice
            return
        self.bIsRunning = True
        if(self.asr != None):
            self.asr.setVisualExpression( False )
        language = self.tts.getLanguage()
        if(self.asr != None):
            self.asr.setLanguage( language )
        try:
            self.aAllWords[language]
            self.aAllSentences[language]
        except:
            raise Exception( "The current language is not supported by this Choice box. It is probably deprecated. Try to use the one supplied in Choregraphe library instead." )
        self.asNegativeWords = self.aAllWords[language]["negative"]
        self.asPositiveWords = self.aAllWords[language]["positive"]
        self.asHelpWords = self.aAllWords[language]["help"]
        self.asExitWords = self.aAllWords[language]["exit"]
        self.asRepeatWords = self.aAllWords[language]["repeat"]
        self.bGoOut = False
        self.bVocabularyLoaded = False
        self.bRecoIsHearingOrAnalysing = False
        self.bRecoIsWaitingForVoice = False
        self.bHasAlreadyHearingEyes = False
        self.sRecoInterruption = ""
        self.sPreviousAnswer = ""
        self.bMustStop = False
        self.nCountNoReply = 0
        self.nCountFailure = 0
        self.nFrameNumber = self.aFrameNumbers["end"]
        self.beginTime = time.time()
        self.bInConfirmation = False
        self.bInTactileSensorMenu = False
        self.bBrainAnimPaused = False
        self.bPressed = False
        self.rTimeWhenActionMadeInTactileMenu = -1.
        self.nFront = 0
        self.nMiddle = 0
        self.nRear = 0
        self.bSeqStarted = False
        self.bIsStoringParam = False
        self.rUnderstoodThreshold = self.tryGetParameter( "Minimum threshold to understand", 0.2 )
        self.rConfirmationThreshold = self.tryGetParameter( "Minimum threshold to be sure", 0.4 )
        self.nTimeoutReco = self.tryGetParameter( "Speech recognition timeout", 6 )
        self.nTimeoutRecoConfirmation = self.tryGetParameter( "Speech recognition timeout when confirmation", 6 )
        self.nTimeoutTactile = self.tryGetParameter( "Tactile sensor menu timeout", 10 )
        self.nMaxCountNoReply = self.tryGetParameter( "Maximum number of repetition when no reply", 3 )
        self.nMaxCountFailure = self.tryGetParameter( "Maximum number of repetition when failure", 5 )
        self.bActivateEyesLight = self.tryGetParameter( "Activate eyes light", True )
        self.bActivateEarsLight = self.tryGetParameter( "Activate ears light", True )
        self.bActivateBrainLight = self.tryGetParameter( "Activate brain light", True )
        self.bActivateHelpWhenFailure = self.tryGetParameter( "Activate help when failure", True )
        self.bRepeatValidatedChoice = self.tryGetParameter( "Repeat validated choice", True )
        self.bActivateDefaultChoiceHelp = self.tryGetParameter( "Activate help command", True )
        self.bActivateDefaultChoiceRepeat = self.tryGetParameter( "Activate repeat command", True )
        self.bActivateDefaultChoiceExit = self.tryGetParameter( "Activate exit command", True )
        self.aDefaultChoices = []
        if (self.bActivateDefaultChoiceHelp):
            self.aDefaultChoices.append( self.asHelpWords )
        if (self.bActivateDefaultChoiceRepeat):
            self.aDefaultChoices.append( self.asRepeatWords )
        if (self.bActivateDefaultChoiceExit):
            self.aDefaultChoices.append( self.asExitWords )
        if( question == None ):
            question = ""
        self.initQuestionAndChoices( question )
        if( len( self.aChoices ) > len( self.aDefaultChoices ) ): # if there is at least one choice (not a default one)
            self.nIndexChoice = len( self.aDefaultChoices )
        else: # if there are only default words
            self.nIndexChoice = 0
        self.bGoOut = False
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFFFFFF, 0.1 )
        # initialize tactile sensor handler
        self.initSeqDetected()
        # subscribe to tactile sensors extractors (launch tactile sensor handler)
        self.memory.subscribeToEvent( "FrontTactilTouched", self.getName(), "onTactilTouched" )
        self.memory.subscribeToEvent( "MiddleTactilTouched", self.getName(), "onTactilTouched" )
        self.memory.subscribeToEvent( "RearTactilTouched", self.getName(), "onTactilTouched" )
        thread.start_new_thread( self.loopLedsBrainTwinkle, () )
        while( not self.bGoOut ):
            self.questionRecognitionReaction()
        if( self.bInTactileSensorMenu ):
            self.nCountNoReply = 0
            if( self.nFrameNumber != self.aFrameNumbers["headDown"] ):
                self.nFrameNumber = self.aFrameNumbers["headDown"]
                try:
                    self.getTimeline().goTo(self.nFrameNumber)
                except: # if NAOqi < 1.14
                    try:
                        self.gotoAndStop(self.nFrameNumber)
                    except:
                        pass
            self.loopLedsBrainTurn()
        else:
            self.bIsRunning = False

    def onInput_choicesList(self, p):
        "Set choices list."
        self.logger.debug( "Input choicesList stimulated." )
        if( not self.bIsRunning ):
            self.bExternChoices = True
            language = "English"
            if(self.asr != None):
                language =  self.asr.getLanguage()
            self.asNegativeWords = self.aAllWords[language]["negative"]
            self.asPositiveWords = self.aAllWords[language]["positive"]
            self.asHelpWords = self.aAllWords[language]["help"]
            self.asExitWords = self.aAllWords[language]["exit"]
            self.asRepeatWords = self.aAllWords[language]["repeat"]
            self.bActivateDefaultChoiceHelp = self.tryGetParameter( "Activate help command", True )
            self.bActivateDefaultChoiceRepeat = self.tryGetParameter( "Activate repeat command", True )
            self.bActivateDefaultChoiceExit = self.tryGetParameter( "Activate exit command", True )
            self.aDefaultChoices = []
            if (self.bActivateDefaultChoiceHelp):
                self.aDefaultChoices.append( self.asHelpWords )
            if (self.bActivateDefaultChoiceRepeat):
                self.aDefaultChoices.append( self.asRepeatWords )
            if (self.bActivateDefaultChoiceExit):
                self.aDefaultChoices.append( self.asExitWords )
            self.aChoices = []
            self.aChoiceIndexes = []
            self.aChoices.extend( self.aDefaultChoices )
            index = 0
            for choice in p:
                if( self.isString(choice) ):
                    choice = choice.strip(" \t,;.\n") # remove space or tabs at beginning or end of a choice
                    if( choice != "" ):
                        choice = [ choice ]
                    else:
                        choice = []
                elif( self.isArray(choice) ):
                    if( choice != [] ):
                        for i in range( len( choice ) ):
                            if( self.isString(choice[i]) ):
                                choice[i] = choice[i].strip(" \t,;.\n") # remove space or tabs at beginning or end of a choice
                                if( len( choice[i] ) < 1 ):
                                    del choice[i]
                                    i -= 1 # to parse the good one next loop
                            else:
                                raise Exception( "Error in choices input syntax:\nIt must be an array of choices and each choice can be either a string or an array of strings (several possibilities for one choice)\nEx: ['choice1',['choice2a','choice2b']]\nbut: " + str(p) + " found" )
                else:
                    raise Exception( "Error in choices input syntax:\nIt must be an array of choices and each choice can be either a string or an array of strings (several possibilities for one choice)\nEx: ['choice1',['choice2a','choice2b']]\nbut: " + str(p) + " found" )
                if( len( choice ) > 0 ):
                    for sWord in choice:
                        for aDefaultChoice in self.aDefaultChoices:
                            if( sWord in aDefaultChoice ):
                                raise Exception( "Error in input choices list: You chose a word which is already used for default choices:\n" + str(sWord) + " is used for the default choice: " + str(aDefaultChoice[0]) )
                    self.aChoices.append( choice )
                    self.aChoiceIndexes.append( index )
                index += 1

    def onInput_onStop(self):
        "Stop box behaviour."
        self.logger.debug( "Input onStop stimulated." )
        if( self.bIsRunning ):
            self.goOut( self.asExitWords[0], "onStop" )
            self.sRecoInterruption = "onStop"
        else:
            self.onUnload()

# GENERAL FUNCTIONS ------------------------------------------------------------------------------------------

    def isString(self, strVariable):
        try:
            if( type( strVariable ) == type( "some string" ) ):
                return True
        except:
            pass
        return False

    def isArray(self, aVariable):
        try:
            if( type( aVariable ) == type( ["some array"] ) ):
                return True
        except:
            pass
        return False

    def fileExists(self, strPathFilename ):
        try:
            file = open( strPathFilename, 'r' )
            if( file ):
                file.close()
                return True
        except (IOError, os.error), err:
            pass
        return False

    def getFileContents(self, sFilename ):
        "read a file and return it's contents, or '' if not found, empty, ..."
        try:
            fileContent = open( sFilename )
            aBuf = fileContent.read()
            fileContent.close()
        except:
            try:
                fileContent.close()
            except:
                pass
            return ""
        return aBuf

    def getBrainLedName(self, nNumLed):
        "Get the name of the DCM led device from its number"
        "0 => front left; 1 => next in clock wise; until 11"
        numLed = nNumLed%12
        if( numLed <= 1 ):
            return "Head/Led/Front/Right/%d/Actuator/Value" % (1-numLed)
        elif( numLed >= 10 ):
            return "Head/Led/Front/Left/%d/Actuator/Value" % (numLed-10)
        elif( numLed <= 2 ):
            return "Head/Led/Middle/Right/%d/Actuator/Value" % (2-numLed)
        elif( numLed >= 9 ):
            return "Head/Led/Middle/Left/%d/Actuator/Value" % (numLed-9)
        elif( numLed <= 5 ):
            return "Head/Led/Rear/Right/%d/Actuator/Value" % (numLed-3)
        else:
            return "Head/Led/Rear/Left/%d/Actuator/Value" % (8-numLed)

    def skipTTS(self):
        for idtts in self.aIdsTTS:
            try:
                self.ttsStop.stop(idtts)
            except:
                self.logger.debug( "Warning: The Text-To-Speech could not have been stopped." )

    def tryGetParameter(self, sParameterName, defaultValue):
        try:
            return self.getParameter( sParameterName )
        except:
            return defaultValue

# QUESTION AND CHOICES INITIALIZATION ----------------------------------------------------------------------

    def initQuestionAndChoices(self, p):
        "Initialize the question and the choices."
        # question processing
        if( self.isString(p) ):
            self.sQuestion = p
        else:
            raise Exception( "Error in question input syntax:\nQuestion text\nexpected for example, but:\n" + str(p[0]) + "\nfound" )
        # choices processing
        if( not self.bExternChoices ):
            self.aChoices = []
            self.aChoiceIndexes = []
            self.aChoices.extend( self.aDefaultChoices )
            index = 0
            listChoices = self.aListAllChoices[self.tts.getLanguage()]
            for choice in listChoices:
                aChoice = choice.split( "/" )
                if( aChoice != [] ):
                    for i in range( len( aChoice ) ):
                        aChoice[i] = aChoice[i].strip(" \t,;.\n") # remove space or tabs at beginning or end of a choice
                        if( len( aChoice[i] ) < 1 ):
                            del aChoice[i]
                            i -= 1 # to parse the good one next loop
                if( len( aChoice ) > 0 ):
                    # check if there is a word which is already used for the default choices
                    for sWord in aChoice:
                        for aDefaultChoice in self.aDefaultChoices:
                            if( sWord in aDefaultChoice ):
                                raise Exception( "Error in choices list: You chose a word which is already used for default choices:\n" + str(sWord) + " is used for the default choice: " + str(aDefaultChoice[0]) )
                    # append the choice to the list if everything worked well
                    self.aChoices.append( aChoice )
                    self.aChoiceIndexes.append( index )
                index += 1
        # check that there is at least one choice (a default one or not)
        if( len( self.aChoices ) < 1 ):
            raise Exception( "Error in choices list: It is empty. There is no default choice nor choice entered." )

# QUESTION-RECOGNITION-REACTION -----------------------------------------------------------------------------

    def questionRecognitionReaction(self):
        "Ask question, launch speech recognition and process answer."
        self.ttsQuestionAndRecoInit()
        if( not self.bMustStop ):
            # stop movement animation
            if( self.nFrameNumber != self.aFrameNumbers["reco"] ):
                self.nFrameNumber = self.aFrameNumbers["reco"]
                try:
                    self.getTimeline().goTo(self.nFrameNumber)
                except: # if NAOqi < 1.14
                    try:
                        self.gotoAndStop(self.nFrameNumber)
                    except:
                        pass
            # start speech recognition
            self.logger.debug( "Speech recognition started." )
            self.memory.subscribeToEvent( "WordRecognized", self.getName(), "onWordRecognized" )
            self.bRecoIsWaitingForVoice = True
            self.memory.subscribeToEvent( "SpeechDetected", self.getName(), "onSpeechDetected" )
        # leds during the recognition
        self.loopLedsReco()
        # process the reco loop break
        self.processRecoInterruption()

    def ttsQuestionAndRecoInit(self):
        "Ask question and initialize the speech recognition during the question to gain time in the interaction."
        if( not self.bInConfirmation ):
            # launch TTS
            idTTS = -1
            if( self.sQuestion != ""):
                idTTS = self.tts.post.say( self.sQuestion )
                self.aIdsTTS.append( idTTS )
                self.logger.debug( "Robot says: " + str(self.sQuestion) )
                # launch TTS movement animation
                if( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ):
                    self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
            # prepare speech recognition
            if(self.asr != None):
                self.asr.setLanguage( self.tts.getLanguage() )
            if( not self.bVocabularyLoaded ):
                aWordsRecognised = []
                for i in range( len( self.aChoices ) ):
                    if( self.aChoices[i] != [] ):
                        aWordsRecognised.extend( self.aChoices[i] )
                sWordsRecognised = "You can say: "
                if( len( aWordsRecognised ) > 1 ):
                    for i in range( len( aWordsRecognised ) - 1 ):
                        sWordsRecognised += "'" + aWordsRecognised[i] + "', "
                if( len( aWordsRecognised ) > 0 ):
                    sWordsRecognised += "'" + aWordsRecognised[len( aWordsRecognised ) - 1] + "'"
                sWordsRecognised += "."
                self.logger.debug( sWordsRecognised )
                if(self.asr != None):
                    self.asr.setVocabulary( aWordsRecognised, False )
                self.bVocabularyLoaded = True
        else:
            # launch TTS
            sentence = self.aAllSentences[self.tts.getLanguage()]["confirmation"][0]
            idTTS = -1
            sentenceToSay = sentence % self.sPreviousAnswer
            if( sentenceToSay != ""):
                idTTS = self.tts.post.say( sentenceToSay )
                self.aIdsTTS.append( idTTS )
                self.logger.debug( "Robot says: " + str(sentenceToSay) )
                # launch TTS movement animation
                if( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ):
                    self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
            # prepare speech recognition
            aWordsRecognised = []
            aWordsRecognised.extend( self.asNegativeWords )
            aWordsRecognised.extend( self.asPositiveWords )
            sWordsRecognised = "You can say: "
            if( len( aWordsRecognised ) > 1 ):
                for i in range( len( aWordsRecognised ) - 1 ):
                    sWordsRecognised += "'" + aWordsRecognised[i] + "', "
            if( len( aWordsRecognised ) > 0 ):
                sWordsRecognised += "'" + aWordsRecognised[len( aWordsRecognised ) - 1] + "'"
            sWordsRecognised += "."
            self.logger.debug( sWordsRecognised )
            if(self.asr != None):
                self.asr.setVocabulary( aWordsRecognised, False )
            self.bVocabularyLoaded = False
        # wait for the end of the TTS
        if( idTTS != -1 ):
            try:
                self.tts.wait( idTTS, 0 )
            except:
                self.logger.debug( "Warning: Could not wait the TTS." )

    def processRecoInterruption(self):
        "Process speech recognition interruption (timeout, action on tactile sensor, word said, etc...)"
        # wait for the end of the reaction (help, not understood, etc...)
        while( self.sRecoInterruption == "" ):
            time.sleep( 0.2 )
        self.logger.debug( "The speech recognition has been interrupted because of: " + str(self.sRecoInterruption) + "." )
        if( self.sRecoInterruption == "timeout" ): # if recognition interrupted by timeout
            try:
                # stop recognition
                self.memory.unsubscribeToEvent( "WordRecognized", self.getName() )
                self.bRecoIsWaitingForVoice = False
                self.bRecoIsHearingOrAnalysing = False
                self.logger.debug( "Speech recognition stopped." )
                self.memory.unsubscribeToEvent( "SpeechDetected", self.getName() )
            except:
                pass
            if( self.bInConfirmation ): # if it was a confirmation question
                # leds noticing that the robot confirm its guessing
                thread.start_new_thread( self.ledsUnderstood, (True, False) )
                # if nothing has been said, we assume that the user agree
                self.bInConfirmation = False
                if( self.sPreviousAnswer in self.asHelpWords ): # if help asked
                    self.helpWhenAsked()
                elif( self.sPreviousAnswer in self.asRepeatWords ): # if repeat asked
                    self.repeatWhenNoQuestion()
                    # repeat the question
                else: # if not repeat nor help asked
                    self.goOut( self.sPreviousAnswer, "wordRecognised" )
            else:
                # reinitialize leds
                self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
                self.nCountNoReply += 1
                if( self.nCountNoReply >= self.nMaxCountNoReply ):
                    self.goOut( self.asExitWords[0], "timeout" )
        else:
            self.nCountNoReply = 0
            if( self.sRecoInterruption in [ "onStop" ] ):
                self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        self.sRecoInterruption = ""

    def repeatWhenNoQuestion(self):
        "Robot's reaction when it is asked to repeat the question when there is no question."
        if( self.sQuestion == "" ):
            sentenceNoQuestion = self.aAllSentences[self.tts.getLanguage()]["noQuestion"][0]
            sentenceNoQuestion += self.enumerateChoices( True ) # True to ask that the introduction is played
            if( len( self.aChoices ) - len( self.aDefaultChoices ) == 0 ): # if there is no choice
                sentenceNoQuestion += self.enumerateDefaultChoices( True ) # True to ask that the introduction is played
            # launch TTS
            idTTS = -1
            if( sentenceNoQuestion != ""):
                if( self.bInTactileSensorMenu ):
                    idTTS = self.tts.post.say( sentenceNoQuestion + "\\Pau=300\\" )
                else:
                    idTTS = self.tts.post.say( sentenceNoQuestion )
                self.aIdsTTS.append( idTTS )
                self.logger.debug( "Robot says: " + str(sentenceNoQuestion) )
                if( not self.bInTactileSensorMenu ):
                    # launch TTS movement animation
                    if( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ):
                        self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                        try:
                            self.getTimeline().goTo(self.nFrameNumber)
                        except: # if NAOqi < 1.14
                            try:
                                self.gotoAndStop(self.nFrameNumber)
                            except:
                                pass
            # wait for the end of the TTS
            if( idTTS != -1 ):
                try:
                    self.tts.wait( idTTS, 0 )
                except:
                    self.logger.debug( "Warning: Could not wait the TTS." )

# RECO OUTPUT PROCESSING --------------------------------------------------------------------------------------

    def onWordRecognized(self, pDataName, pValue, pMessage):
        "Handler for when a word is recognised by the speech recognition system."
        aState = pValue
        self.logger.debug( "The word '" + str(aState[0]) + "' has been recognised with a threshold of " + str(aState[1]) + "." )
        # interrupt loops:
            # - stop reco
            # - stop leds
            # - stop asking the question on and on
        try:
            self.memory.unsubscribeToEvent( "WordRecognized", self.getName() )
            self.logger.debug( "Speech recognition stopped." )
            self.memory.unsubscribeToEvent( "SpeechDetected", self.getName() )
        except:
            pass
        self.bRecoIsHearingOrAnalysing = False
        self.bRecoIsWaitingForVoice = False
        if( aState[0] != "" ):
            if( aState[1] >= self.rUnderstoodThreshold ):
                if( self.rUnderstoodThreshold <= self.arUnderstoodThreshold[1] - 0.02 ):
                    self.rUnderstoodThreshold += 0.02
                else:
                    self.rUnderstoodThreshold = self.arUnderstoodThreshold[1]
                if( self.bInConfirmation ):
                    if( aState[0] in self.asNegativeWords ):
                        thread.start_new_thread( self.ledsNegative, () )
                    else:
                        thread.start_new_thread( self.ledsUnderstood, (True, False) )
                else:
                    thread.start_new_thread( self.ledsUnderstood, (True, False) )
                self.reactionWordUnderstood( aState )
            else:
                if( self.rUnderstoodThreshold >= self.arUnderstoodThreshold[0] + 0.05 ):
                    self.rUnderstoodThreshold -= 0.05
                else:
                    self.rUnderstoodThreshold = self.arUnderstoodThreshold[0]
                aCurrentChoice = ""
                for choice in self.aChoices:
                    if( aCurrentChoice == "" ):
                        if( aState[0] in choice ):
                            aCurrentChoice = choice
                if( self.sPreviousAnswer in aCurrentChoice ): # if answer in the same choice as previously
                    # then ask confirmation
                    aState[1] = self.rConfirmationThreshold - 0.01
                    thread.start_new_thread( self.ledsUnderstood, (True, False) )
                    self.reactionWordUnderstood( aState )
                else:
                    # else not understood
                    if( self.bInConfirmation ):
                        thread.start_new_thread( self.ledsUnderstood, (True, False) )
                    else:
                        self.sPreviousAnswer = aState[0]
                        thread.start_new_thread( self.ledsNotUnderstood, () )
                    self.reactionNothingUnderstood()
        else:
            if( self.bInConfirmation ):
                thread.start_new_thread( self.ledsUnderstood, (True, False) )
            else:
                thread.start_new_thread( self.ledsNotUnderstood, () )
            self.reactionNothingUnderstood()
        if( pMessage == "" ):
            self.sRecoInterruption = "wordRecognised"
        else:
            self.sRecoInterruption = pMessage

    def onSpeechDetected(self, pDataName, pValue, pMessage):
        "Handler for when something has been heard by the speech recognition system."
        aState = pValue
        if( aState == 1):
            if( self.bRecoIsWaitingForVoice ):
                # make eyes leds switch from an animation to an other
                self.bRecoIsHearingOrAnalysing = True
                self.bRecoIsWaitingForVoice = False
                try:
                    self.timeToReply(time.time() - self.beginTime)
                except:
                    pass

    def reactionWordUnderstood(self, word):
        "Reaction depending on the word recognised (help, repeat, word in choices, etc...) and its recognition confidence."
        if( self.bInConfirmation ):
            self.bInConfirmation = False
            if( word[0] in self.asNegativeWords ):
                # update number of failures
                self.nCountFailure += 1
                if( self.sPreviousAnswer in self.asHelpWords ):
                    if( self.nCountFailure >= self.nMaxCountFailure ): # if maximum number of failures
                        # skip the question
                        self.goOut( self.asExitWords[0], "notUnderstood" )
                else:
                    self.helpAfterFailure()
            else:
                if( (self.sPreviousAnswer in self.asHelpWords) or (word[0] in self.asHelpWords) ):
                    self.helpWhenAsked()
                elif( self.sPreviousAnswer in self.asRepeatWords or (word[0] in self.asRepeatWords) ):
                    self.repeatWhenNoQuestion()
                    # repeat the question
                else:
                    self.goOut( self.sPreviousAnswer, "wordRecognised" )
                self.sPreviousAnswer = ""
        else:
            self.sPreviousAnswer = word[0]
            if( word[1] >= self.rConfirmationThreshold ):
                if( self.rConfirmationThreshold <= self.arConfirmationThreshold[1] - 0.02 ):
                    self.rConfirmationThreshold += 0.02
                else:
                    self.rConfirmationThreshold = self.arConfirmationThreshold[1]
                if( self.sPreviousAnswer in self.asHelpWords ):
                    self.helpWhenAsked()
                elif( self.sPreviousAnswer in self.asRepeatWords ):
                    self.repeatWhenNoQuestion()
                    # repeat the question
                else:
                    self.goOut( self.sPreviousAnswer, "wordRecognised" )
                self.sPreviousAnswer = ""
            else:
                if( self.rConfirmationThreshold >= self.arConfirmationThreshold[0] + 0.05 ):
                    self.rConfirmationThreshold -= 0.05
                else:
                    self.rConfirmationThreshold = self.arConfirmationThreshold[0]
                self.bInConfirmation = True

    def reactionNothingUnderstood(self):
        "Reaction when nothing has been understood or without an enough confidence."
        if( self.bInConfirmation ):
            # if the robot did not understand, we assume that the user agree
            self.bInConfirmation = False
            if( self.sPreviousAnswer in self.asHelpWords ): # if help asked
                self.helpWhenAsked()
            elif( self.sPreviousAnswer in self.asRepeatWords ): # if repeat asked
                self.repeatWhenNoQuestion()
                # repeat the question
            else: # if not repeat nor help asked
                self.goOut( self.sPreviousAnswer, "wordRecognised" )
        else:
            # update number of failures
            self.nCountFailure += 1
            if( self.nCountFailure <= 1 ): # if first failure
                sentence = self.aAllSentences[self.tts.getLanguage()]["notUnderstood"][0]
            else: # if second failure or more
                sentenceNotUnderstoodAnims = self.aAllSentences[self.tts.getLanguage()]["notUnderstoodAnims"]
                index = random.randint( 0, len( sentenceNotUnderstoodAnims ) - 1 )
                sentence = sentenceNotUnderstoodAnims[index]
                if( self.nFrameNumber != self.aFrameNumbers["notUnderstood"] + 10*index ):
                    self.nFrameNumber = self.aFrameNumbers["notUnderstood"] + 10*index
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
            self.helpAfterFailure( sentence )

# HELP ------------------------------------------------------------------------------------------------------

    def enumerateChoices(self, bIntroToSay):
        "Enumerate choices (only the first word of each choice is taken into account)."
        sentenceHelpEnumChoices = self.aAllSentences[self.tts.getLanguage()]["helpEnumChoices"]
        sentenceHelpEnumMarks = self.aAllSentences[self.tts.getLanguage()]["enumMarks"]
        enumWords = ""
        maxNbEnumChoices = 3
        indexes = []
        for i in range( min(maxNbEnumChoices, len( self.aChoices ) - len( self.aDefaultChoices )) ):
            if( len( self.aChoices ) - len( self.aDefaultChoices ) <= maxNbEnumChoices ):
                index = len( self.aDefaultChoices ) + i
            else:
                index = random.randint( len( self.aDefaultChoices ), len( self.aChoices ) - 1 )
                while( index in indexes ):
                    index = random.randint( len( self.aDefaultChoices ), len( self.aChoices ) - 1 )
            indexes.append( index )
            if( len( indexes ) != 1 ): # if it is not the first choice
                if( len( indexes ) != min(maxNbEnumChoices, len( self.aChoices ) - len( self.aDefaultChoices )) ): # if it is not the last choice
                    enumWords += sentenceHelpEnumMarks[0]
                else:
                    enumWords += sentenceHelpEnumMarks[1]
            enumWords += self.aChoices[index][0]
        sentenceTemplate = sentenceHelpEnumChoices[2]
        if( len( self.aChoices ) - len( self.aDefaultChoices ) <= maxNbEnumChoices ): # if there are 3 or less choices
            sentenceTemplate = sentenceHelpEnumChoices[1]
        if( not bIntroToSay ):
            sentenceTemplate = sentenceHelpEnumChoices[3]
        if( len( self.aChoices ) - len( self.aDefaultChoices ) == 0 ): # if there is no choice
            sentence = sentenceHelpEnumChoices[0]
        else:
            sentence = sentenceTemplate % enumWords
        return sentence

    def enumerateDefaultChoices(self, bIntroToSay):
        "Enumerate default choices (only the first word of each choice is taken into account)."
        sentenceHelpEnumChoices = self.aAllSentences[self.tts.getLanguage()]["helpEnumChoices"]
        sentenceHelpEnumDefault = self.aAllSentences[self.tts.getLanguage()]["helpEnumDefault"]
        sentenceHelpEnumMarks = self.aAllSentences[self.tts.getLanguage()]["enumMarks"]
        enumWords = ""
        indexes = []
        for i in range( len( self.aDefaultChoices ) ):
            indexes.append( i )
            if( len( indexes ) != 1 ): # if it is not the first choice
                if( len( indexes ) != len( self.aDefaultChoices ) ): # if it is not the last choice
                    enumWords += sentenceHelpEnumMarks[0]
                else:
                    enumWords += sentenceHelpEnumMarks[1]
            enumWords += self.aDefaultChoices[i][0]
        sentenceTemplate = sentenceHelpEnumDefault[0]
        if( not bIntroToSay ):
            sentenceTemplate = sentenceHelpEnumChoices[3]
        if( len( self.aDefaultChoices ) == 0 ): # if there is no default choice
            sentence = ""
        else:
            sentence = sentenceTemplate % enumWords
        return sentence

    def explanationTactileSensor(self):
        "Explain the possible interaction with the tactile sensor."
        sentenceHelpTactile = self.aAllSentences[self.tts.getLanguage()]["helpTactile"]
        if( self.bInTactileSensorMenu ):
            sentence = sentenceHelpTactile[1]
        else:
            sentence = sentenceHelpTactile[0]
        return sentence

    def helpWhenAsked(self, sentence = ""):
        "Help when the user asked it: enumerate choices, enumerate default choices and explain tactile sensor possible interaction."
        if( not self.bInTactileSensorMenu ):
            # enumeration of choices
            sentence += self.enumerateChoices( True ) # True to ask that the introduction is played
            # enumeration of default choices
            sentence += self.enumerateDefaultChoices( True ) # True to ask that the introduction is played
        # explanation about alternative modality (tactil sensor, arm motion)
        sentence += self.explanationTactileSensor()
        # launch TTS
        idTTS = -1
        if( sentence != "" ):
            if( self.bInTactileSensorMenu ):
                idTTS = self.tts.post.say( sentence + "\\Pau=300\\" )
            else:
                idTTS = self.tts.post.say( sentence )
            self.aIdsTTS.append( idTTS )
            self.logger.debug( "Robot says: " + str(sentence) )
            # launch TTS movement animation
            if( self.bInTactileSensorMenu ):
                if( self.nFrameNumber != self.aFrameNumbers["helpTactileSensor"] ):
                    self.nFrameNumber = self.aFrameNumbers["helpTactileSensor"]
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
            else:
                if( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ):
                    self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                    try:
                        self.getTimeline().goTo(self.nFrameNumber)
                    except: # if NAOqi < 1.14
                        try:
                            self.gotoAndStop(self.nFrameNumber)
                        except:
                            pass
        # wait for the end of the TTS
        if( idTTS != -1 ):
            try:
                self.tts.wait( idTTS, 0 )
            except:
                self.logger.debug( "Warning: Could not wait the TTS." )
        # repeat the question

    def helpAfterFailure(self, sentence = ""):
        "Help when the speech recognition failed (nothing understood or incorrect answer understood)."
        if( self.nCountFailure < self.nMaxCountFailure ): # if reasonable number of failures
            if( self.bActivateHelpWhenFailure ):
                if( self.nCountFailure in [1, 2] ): # if first or second failure
                    # enumeration of choices, or default words if there is no choice
                    if( len( self.aChoices ) - len( self.aDefaultChoices ) > 0 ): # if there is at least one choice
                        sentence += self.enumerateChoices( self.nCountFailure == 1 ) # the introduction is played if it is the first failure
                    else:
                        sentence += self.enumerateDefaultChoices( self.nCountFailure == 1 ) # the introduction is played if it is the first failure
                    if( self.nCountFailure == 2 ): # if second failure
                        # explanation about alternative modality (tactil sensor, arm motion)
                        sentence += self.explanationTactileSensor()
                # launch TTS
                idTTS = -1
                if( sentence != "" ):
                    idTTS = self.tts.post.say( sentence )
                    self.aIdsTTS.append( idTTS )
                    self.logger.debug( "Robot says: " + str(sentence) )
                    # launch TTS movement animation
                    listPossibleFrames = range( len( self.aAllSentences[self.tts.getLanguage()]["notUnderstoodAnims"] ) )
                    for i in range(len(listPossibleFrames)):
                        listPossibleFrames[i] = listPossibleFrames[i] * 10 + self.aFrameNumbers["notUnderstood"]
                    if( ( self.nFrameNumber != self.aFrameNumbers["bodyTalk"] ) and not ( self.nFrameNumber in listPossibleFrames ) ):
                        try:
                            self.getTimeline().goTo(self.aFrameNumbers["bodyTalk"])
                        except: # if NAOqi < 1.14
                            try:
                                self.gotoAndStop(self.aFrameNumbers["bodyTalk"])
                            except:
                                pass
                    self.nFrameNumber = self.aFrameNumbers["bodyTalk"]
                # wait for the end of the TTS
                if( idTTS != -1 ):
                    try:
                        self.tts.wait( idTTS, 0 )
                    except:
                        self.logger.debug( "Warning: Could not wait the TTS." )
            # repeat the question
        else: # if maximum number of failures
            # skip the question
            self.goOut( self.asExitWords[0], "notUnderstood" )

# LEDS ---------------------------------------------------------------------------------------------------

    def setLeds(self, eyesLight, earsLight, brainLight):
        "Set all LEDS (eyes, ears and brain lights)."
        rDuration = 1
        if( self.bActivateEyesLight ):
            # set eyes leds
            self.leds.post.fadeRGB( "FaceLeds", eyesLight, rDuration )
        if( self.bActivateEarsLight ):
            # set ears leds
            self.leds.fadeRGB( "EarLeds", earsLight, rDuration )
        if( self.bActivateBrainLight ):
            # set brain leds light
            self.setLedsBrain( brainLight, 500 )

    def ledsUnderstood(self, bFlashEars, bFlashBrain):
        "Sequence of LEDS for eyes, ears and brain when the robot understood what it heard."
        self.bBrainAnimPaused = True
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x00FF00, rDuration )
        if( self.bActivateEarsLight ):
            if( bFlashEars ):
                self.leds.fadeRGB( "EarLeds", 0x00FF00, rDuration )
        if( self.bActivateBrainLight ):
            if( bFlashBrain ):
                self.setLedsBrain( 0.5, int(rDuration * 1000) )
        time.sleep( 0.3 )
        rDuration = 0.2
        if( self.bActivateEyesLight ):
            if( self.bInTactileSensorMenu ):
                self.leds.fadeRGB( "FaceLeds", 0xFFFFFF, rDuration )
            else:
                self.leds.fadeRGB( "FaceLeds", 0x000000, rDuration )
        if( self.bActivateEarsLight ):
            if( bFlashEars ):
                self.leds.fadeRGB( "EarLeds", 0x000000, rDuration )
        if( self.bActivateBrainLight ):
            if( bFlashBrain ):
                self.setLedsBrain( 0., int(rDuration * 1000) )
        time.sleep( 0.1 )
        if( not self.bInTactileSensorMenu ):
            self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        time.sleep( 0.1 )
        self.bBrainAnimPaused = False

    def ledsNotUnderstood(self):
        "Sequence of LEDS for eyes and ears when the robot did not understand what it heard."
        self.bBrainAnimPaused = True
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFF0000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0xFF0000, rDuration )
        time.sleep( 0.05 )
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x000000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0x000000, rDuration )
        time.sleep( 0.05 )
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFF0000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0xFF0000, rDuration )
        time.sleep( 0.05 )
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x000000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0x000000, rDuration )
        time.sleep( 0.3 )
        self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        self.bBrainAnimPaused = False

    def ledsNegative(self):
        "Sequence of LEDS for eyes and ears when the robot understood 'no'."
        self.bBrainAnimPaused = True
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFF0000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0xFF0000, rDuration )
        time.sleep( 0.3 )
        rDuration = 0.2
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x000000, rDuration )
        if( self.bActivateEarsLight ):
            self.leds.fadeRGB( "EarLeds", 0x000000, rDuration )
        time.sleep( 0.1 )
        self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        time.sleep( 0.1 )
        self.bBrainAnimPaused = False

    def loopLedsReco(self):
        "LEDS (eyes and ears) process during the speech recognition."
        self.beginTime = time.time()
        if( self.bInConfirmation ):
            timerReco = self.beginTime + self.nTimeoutRecoConfirmation
        else:
            timerReco = self.beginTime + self.nTimeoutReco
        self.bHasAlreadyHearingEyes = False
        nEarLedsNextIndex = 0
        nEyesLed = -1
        while( self.bRecoIsWaitingForVoice or self.bRecoIsHearingOrAnalysing ):
            if( self.bMustStop ):
                try:
                    self.timeToReply(time.time() - self.beginTime)
                except:
                    pass
                break
            if( self.bRecoIsWaitingForVoice ):
                if( timerReco < time.time() ):
                    try:
                        self.timeToReply(timerReco - self.beginTime)
                    except:
                        pass
                    self.sRecoInterruption = "timeout"
                    break
            nEarLedsNextIndex = self.ledsEarsTurnOneStep( nEarLedsNextIndex )
            nEyesLed += 1
            self.ledsEyesTurnOneStep( 0x0055FF, nEyesLed%8 )
            time.sleep( 0.2 )

    def ledsEarsTurnOneStep(self, nEarLedsNextIndex):
        "One step of ears LEDS sequence (turn) when the robot is in speech recognition."
        if( self.bActivateEarsLight ):
            nNbrLedByEars = 10
            rTime = 0.7
            strTemplate = "Ears/Led/%s/%dDeg/Actuator/Value"
            nAngle = (360/nNbrLedByEars) * nEarLedsNextIndex
            # update index before sending movement in case of a fast/concurrent call of the function
            nEarLedsNextIndex -= 1 # more beautiful to turn in this way
            if( nEarLedsNextIndex < 0 ):
                nEarLedsNextIndex = nNbrLedByEars-1
            self.leds.post.fade( strTemplate % ( "Left", nAngle ), 1.0, rTime )
            self.leds.post.fade( strTemplate % ( "Right", nAngle ), 1.0, rTime )
            self.leds.post.fade( strTemplate % ( "Left", nAngle ), 0.0, rTime*1.2 )
            self.leds.post.fade( strTemplate % ( "Right", nAngle ), 0.0, rTime*1.2 )
        return nEarLedsNextIndex

    def ledsEyesTurnOneStep(self, nColor, nLed):
        "One step of eyes LEDS sequence (turn) when the robot is in speech recognition."
        if( self.bActivateEyesLight ):
            rTime = 0.7
            if( self.bRecoIsHearingOrAnalysing ):
                if( not self.bHasAlreadyHearingEyes ):
                    self.leds.fadeRGB( "FaceLeds", 0xF4FF22, 0.1 )
                    # start headcheck animation
                    if( self.nFrameNumber != self.aFrameNumbers["headCheck"] ):
                        self.nFrameNumber = self.aFrameNumbers["headCheck"]
                        try:
                            self.getTimeline().goTo(self.nFrameNumber)
                        except: # if NAOqi < 1.14
                            try:
                                self.gotoAndStop(self.nFrameNumber)
                            except:
                                pass
                    self.bHasAlreadyHearingEyes = True
            elif( self.bRecoIsWaitingForVoice ):
                self.leds.post.fadeRGB( "FaceLed%d" % (nLed) , nColor, rTime )
                self.leds.post.fadeRGB( "FaceLed%d" % (nLed) , 0x000000, rTime*1.25 )

    def ledsChangeOnTactile(self):
        self.bBrainAnimPaused = True
        rDuration = 0.05
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0x0055FF, rDuration )
        self.setLedsBrain( 0.5, int(rDuration * 1000) )
        time.sleep( 0.3 )
        rDuration = 0.2
        if( self.bActivateEyesLight ):
            self.leds.fadeRGB( "FaceLeds", 0xFFFFFF, rDuration )
        self.setLedsBrain( 0., int(rDuration * 1000) )
        time.sleep( 0.2 )
        self.bBrainAnimPaused = False

    def loopLedsBrainTurn(self):
        self.setLeds( 0xFFFFFF, 0xFFFFFF, 0. )
        rIntensity = 0.5
        nTime = 50
        bAlreadyPaused = False
        while( self.bInTactileSensorMenu ):
            if( not self.bBrainAnimPaused ):
                if( self.nFront == 1 or self.nMiddle == 1 or self.nRear == 1 ):
                    if( not bAlreadyPaused ):
                        bAlreadyPaused = True
                        self.setLedsBrain( 0., 50 )
                else:
                    bAlreadyPaused = False
                    if( self.bActivateBrainLight ):
                        for i in range( 12 ):
                            if( not self.bBrainAnimPaused and self.dcm != None):
                                riseTime = self.dcm.getTime(nTime)
                                strDeviceName = self.getBrainLedName(i)
                                self.dcm.set( [ strDeviceName, "Merge",  [[ rIntensity, riseTime ]] ] )
                                time.sleep( nTime/1000. )
                                if( not self.bBrainAnimPaused ):
                                    self.dcm.set( [ strDeviceName, "Merge",  [[ 0.0, riseTime + int(nTime)/4 ]] ] )
            time.sleep( nTime/1000. )
        self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )

    def loopLedsBrainTwinkle(self):
        rIntensity = 0.5
        bOnStep = True
        bAlreadyPaused = False
        while( not self.bInTactileSensorMenu and self.bIsRunning ):
            if( not self.bBrainAnimPaused ):
                if( self.nFront == 1 or self.nMiddle == 1 or self.nRear == 1 ):
                    if( not bAlreadyPaused ):
                        bAlreadyPaused = True
                        self.setLedsBrain( 0., 50 )
                else:
                    bAlreadyPaused = False
                    if( bOnStep ):
                        self.setLedsBrain( rIntensity, 700 )
                        bOnStep = False
                    else:
                        self.setLedsBrain( 0.0, 700 )
                        bOnStep = True
            time.sleep( 1 )

    def setLedsBrain(self, rIntensity, rTimeMs):
        "One step of brain LEDS sequence (twinkle) when the robot is in speech recognition."
        if( self.bActivateBrainLight and self.dcm != None):
            riseTime = self.dcm.getTime( rTimeMs )
            for i in range( 12 ):
                strDeviceName = self.getBrainLedName(i)
                self.dcm.set( [ strDeviceName, "Merge",  [[ rIntensity, riseTime ]] ] )

# TACTILE SENSOR MENU -------------------------------------------------------------------------------------

    def onAlternativeModalityAction(self, p):
        "Process actions from alternative modalities (sequence from the tactile sensor, simple click on the torso button...)."
        if( not self.bIsRunning ): # if the box is not running
            return # then go out without doing a thing
        if( not self.bInTactileSensorMenu ): # if we are not in the tactile sensor menu (so if we are in the question-recognition-reaction loop)
            if( p in ["TapFront", "TapMiddle", "TapRear", "LongFront", "LongMiddle", "LongRear"] ):
                bTTSRunning = False # to know if TTS is running
                for idTTS in self.aIdsTTS:
                    if( self.tts.isRunning( idTTS )):
                        bTTSRunning = True
                if( bTTSRunning ): # if TTS is running
                    # skip the TTS
                    self.skipTTS()
                else: # if TTS was not running (so if in recognition)
                    # prepare to start the tactile sensor menu
                    self.bInTactileSensorMenu = True
                    # and stop the question-recognition-reaction loop
                    self.goOutOfQuestionRecoReaction()
                    self.sRecoInterruption = "onTactileSensor"
                    # start the tactile sensor menu
                    self.sayCurrentChoice()
                    # start counting timeout
                    self.rTimeWhenActionMadeInTactileMenu = time.time()
                    thread.start_new_thread( self.loopCheckTimeoutInTactileMenu, (self.rTimeWhenActionMadeInTactileMenu,) )
            elif( p in ["Tap", "CalmDown"] ):
                # skip the TTS
                self.skipTTS()
                # then stop everything and cancel the question
                self.goOut( self.asExitWords[0], "onTactileSensor" )
                self.sRecoInterruption = "onTactileSensor"
                self.setLeds( 0xFFFFFF, 0xFFFFFF, 0.5 )
        else: # if we are in the tactile sensor menu
            self.rTimeWhenActionMadeInTactileMenu = -1.
            if( p in ["TapFront"] ):
                bTTSRunning = False # to know if TTS is running
                for idTTS in self.aIdsTTS:
                    if( self.tts.isRunning( idTTS ) ):
                        bTTSRunning = True
                if( self.bIsSayingChoice or not bTTSRunning ): # else just skip the TTS (in the sayCurrentChoice function)
                    # change choice
                    self.nIndexChoice += 1
                    if( self.nIndexChoice >= len( self.aChoices ) ):
                        self.nIndexChoice = 0
                # say the choice in the tactile sensor menu
                self.sayCurrentChoice()
                self.timeoutManagingInTactileMenu()
            elif( p in ["TapRear"] ):
                bTTSRunning = False # to know if TTS is running
                for idTTS in self.aIdsTTS:
                    if( self.tts.isRunning( idTTS )):
                        bTTSRunning = True
                if( self.bIsSayingChoice or not bTTSRunning ): # else just skip the TTS (in the sayCurrentChoice function)
                    # change choice
                    self.nIndexChoice -= 1
                    if( self.nIndexChoice < 0 ):
                        self.nIndexChoice = len( self.aChoices ) - 1
                # say the choice in the tactile sensor menu
                self.sayCurrentChoice()
                self.timeoutManagingInTactileMenu()
            elif( p in ["TapMiddle", "LongMiddle"] ):
                self.rTimeWhenActionMadeInTactileMenu = time.time()
                rTimeForThisAction = self.rTimeWhenActionMadeInTactileMenu
                bWasSayingChoice = self.bIsSayingChoice
                bTTSRunning = False # to know if TTS is running
                for idTTS in self.aIdsTTS:
                    if( self.tts.isRunning( idTTS )):
                        bTTSRunning = True
                # skip the TTS if it is running
                self.skipTTS()
                if( bWasSayingChoice or not bTTSRunning ):
                    # validate choice
                    thread.start_new_thread( self.ledsUnderstood, (False, True) )
                    if( self.aChoices[self.nIndexChoice][0] == self.asRepeatWords[0] ):
                        self.repeatWhenNoQuestion()
                        # launch TTS
                        idTTS = -1
                        if( self.sQuestion != ""):
                            idTTS = self.tts.post.say( self.sQuestion + "\\Pau=300\\" )
                            self.aIdsTTS.append( idTTS )
                            self.logger.debug( "Robot says: " + str(self.sQuestion) )
                        # wait for the end of the TTS
                        if( idTTS != -1 ):
                            try:
                                self.tts.wait( idTTS, 0 )
                            except:
                                self.logger.debug( "Warning: Could not wait the TTS." )
                    else:
                        self.reactionWordUnderstood( [ self.aChoices[self.nIndexChoice][0], 1.0 ] )
                if( self.bIsRunning and rTimeForThisAction == self.rTimeWhenActionMadeInTactileMenu ): #$$$
                    self.rTimeWhenActionMadeInTactileMenu = -1.
                    # say the choice in the tactile sensor menu
                    self.sayCurrentChoice()
                    self.timeoutManagingInTactileMenu()
            elif( p == "LongFront" ):
                if( not self.bPressed ):
                    self.bPressed = True
                    bLastElementSaid = False
                    while( self.bPressed ):
                        if( self.nFront == 0 ):
                            self.bPressed = False
                            break
                        bTTSRunning = False # to know if TTS is running
                        for idTTS in self.aIdsTTS:
                            if( self.tts.isRunning( idTTS )):
                                bTTSRunning = True
                        if( self.bIsSayingChoice or not bTTSRunning ):
                            # change choice
                            self.nIndexChoice += 1
                            if( self.nIndexChoice >= len( self.aChoices ) - 1 ):
                                self.nIndexChoice = len( self.aChoices ) - 1
                                if( not bLastElementSaid ):
                                    bLastElementSaid = True
                                    # say the choice in the tactile sensor menu
                                    thread.start_new_thread( self.sayCurrentChoice, () )
                            else:
                                # say the choice in the tactile sensor menu
                                thread.start_new_thread( self.sayCurrentChoice, () )
                        else:
                            if( self.nIndexChoice == len( self.aChoices ) - 1 ):
                                bLastElementSaid = True
                            # say the choice in the tactile sensor menu
                            thread.start_new_thread( self.sayCurrentChoice, () )
                        for i in range(8):
                            if( self.nFront == 0 ):
                                self.bPressed = False
                                break
                            time.sleep(0.1)
                    for idTTS in self.aIdsTTS:
                        if( self.tts.isRunning( idTTS ) ):
                            try:
                                self.tts.wait( idTTS, 0 )
                            except:
                                self.logger.debug( "Warning: Could not wait the TTS." )
                    self.timeoutManagingInTactileMenu()
            elif( p == "LongRear" ):
                if( not self.bPressed ):
                    self.bPressed = True
                    bFirstElementSaid = False
                    while( self.bPressed ):
                        if( self.nRear == 0 ):
                            self.bPressed = False
                            break
                        bTTSRunning = False # to know if TTS is running
                        for idTTS in self.aIdsTTS:
                            if( self.tts.isRunning( idTTS )):
                                bTTSRunning = True
                        if( self.bIsSayingChoice or not bTTSRunning ):
                            # change choice
                            self.nIndexChoice -= 1
                            if( self.nIndexChoice <= 0 ):
                                self.nIndexChoice = 0
                                if( not bFirstElementSaid ):
                                    bFirstElementSaid = True
                                    # say the choice in the tactile sensor menu
                                    thread.start_new_thread( self.sayCurrentChoice, () )
                            else:
                                # say the choice in the tactile sensor menu
                                thread.start_new_thread( self.sayCurrentChoice, () )
                        else:
                            if( self.nIndexChoice == 0 ):
                                bFirstElementSaid = True
                            # say the choice in the tactile sensor menu
                            thread.start_new_thread( self.sayCurrentChoice, () )
                        for i in range(8):
                            if( self.nRear == 0 ):
                                self.bPressed = False
                                break
                            time.sleep(0.1)
                    for idTTS in self.aIdsTTS:
                        if( self.tts.isRunning( idTTS ) ):
                            try:
                                self.tts.wait( idTTS, 0 )
                            except:
                                self.logger.debug( "Warning: Could not wait the TTS." )
                    self.timeoutManagingInTactileMenu()
            elif( p in ["Tap", "CalmDown"] ):
                # then stop everything and cancel the question
                self.goOut( self.asExitWords[0], "onTactileSensor" )

    def sayCurrentChoice(self):
        "In the tactile sensor menu, make the robot say the current selected choice"
        self.bIsSayingChoice = True
        rTimeCurrent = time.time()
        self.rTimeLastChoiceSaid = rTimeCurrent
        # stop previous TTS
        self.skipTTS()
        # launch TTS
        idTTS = -1
        if( self.aChoices[ self.nIndexChoice ][0] != "" ):
            if( self.nFrameNumber != self.aFrameNumbers["headDown"] ):
                self.nFrameNumber = self.aFrameNumbers["headDown"]
                try:
                    self.getTimeline().goTo(self.nFrameNumber)
                except: # if NAOqi < 1.14
                    try:
                        self.gotoAndStop(self.nFrameNumber)
                    except:
                        pass
            sentence = self.aChoices[ self.nIndexChoice ][0] + "?"
            idTTS = self.tts.post.say( sentence )
            self.aIdsTTS.append( idTTS )
            self.logger.debug( "Robot says: " + str(sentence) )
            # launch flash leds
            thread.start_new_thread( self.ledsChangeOnTactile, () )
        if( idTTS != -1 ):
            try:
                self.tts.wait( idTTS, 0 )
            except:
                self.logger.debug( "Warning: Could not wait the TTS." )
        if( self.rTimeLastChoiceSaid == rTimeCurrent ):
            self.rTimeLastChoiceSaid = -1.
            self.bIsSayingChoice = False

    def timeoutManagingInTactileMenu(self):
        # check if there has been an other action with tts made while this one was processed
        bTTSRunning = False # to know if TTS is running
        for idTTS in self.aIdsTTS:
            if( self.tts.isRunning( idTTS )):
                bTTSRunning = True
        if( not bTTSRunning ):
            # start counting timeout
            self.rTimeWhenActionMadeInTactileMenu = time.time()
            thread.start_new_thread( self.loopCheckTimeoutInTactileMenu, (self.rTimeWhenActionMadeInTactileMenu,) )

    def loopCheckTimeoutInTactileMenu(self, rTimeForThisAction):
        nTimeout = time.time() + self.nTimeoutTactile
        if( self.rTimeWhenActionMadeInTactileMenu == rTimeForThisAction ):
            while( time.time() < nTimeout and self.rTimeWhenActionMadeInTactileMenu == rTimeForThisAction and self.bIsRunning ):
                time.sleep( 0.1 )
            if( self.rTimeWhenActionMadeInTactileMenu != rTimeForThisAction ):
                self.nCountNoReply = 0
            elif( self.bIsRunning ):
                self.rTimeWhenActionMadeInTactileMenu = -1.
                self.nCountNoReply += 1
                if( self.nCountNoReply >= self.nMaxCountNoReply ):
                    self.goOut( self.asExitWords[0], "timeout" )
                else:
                    bTTSRunning = False # to know if TTS is running
                    for idTTS in self.aIdsTTS:
                        if( self.tts.isRunning( idTTS )):
                            bTTSRunning = True
                    if( not bTTSRunning ):
                        # say the choice in the tactile sensor menu
                        self.sayCurrentChoice()
                        # start counting timeout
                        self.rTimeWhenActionMadeInTactileMenu = time.time()
                        thread.start_new_thread( self.loopCheckTimeoutInTactileMenu, (self.rTimeWhenActionMadeInTactileMenu,) )

# TACTILE SENSOR HANDLER -------------------------------------------------------------------------------

    def initSeqDetected(self):
        "Initialize the sequence handler."
        self.bSeqStarted = False
        self.aDetectedSeqs = []
        self.aDetectedSeqs.extend(self.aSeqs)
        for seq in self.aDetectedSeqs:
            seq["index"] = 0
            seq["previousStepTime"] = 0

    def convertToArrayOfPossibleStates(self, states):
        "Check if the states described in the sequences using a string are in the right syntax, and then convert them to an array of the possible states."
        aStates = []
        aStates3 = [[1, 1, 1]]
        aStates2 = [[0, 1, 1], [1, 0, 1], [1, 1, 0]]
        aStates1 = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]
        aStates0 = [[0, 0, 0]]
        try:
            if( int(states) == states ): # if states is an integer
                states = str(states)
        except:
            pass
        if( self.isString(states) ):
            if( not states in ["*", "0+", "0", "0-", "1+", "1", "1-", "2+", "2", "2-", "3+", "3", "3-", "F+", "F", "F-", "M+", "M", "M-", "R+", "R", "R-"] ):
                raise Exception( "Error in sequences states description syntax: description expected in " + str(["*", "0+", "0", "0-", "1+", "1", "1-", "2+", "2", "2-", "3+", "3", "3-", "F+", "F", "F-", "M+", "M", "M-", "R+", "R", "R-"]) + " but " + str(p) + " found with this type: " + str(type(p)) )
            if( states in ["*", "0+", "1+", "2+", "3+", "3", "3-", "F+", "M+", "R+"] ):
                aStates.extend(aStates3)
            if( states in ["*", "0+", "1+", "2+", "2", "2-", "3-"] ):
                aStates.extend(aStates2)
            if( states in ["*", "0+", "1+", "1", "1-", "2-", "3-"] ):
                aStates.extend(aStates1)
            if( states in ["*", "0+", "0", "0-", "1-", "2-", "3-", "F-", "M-", "R-"] ):
                aStates.extend(aStates0)
            if( states in ["F", "F+", "F-"] ):
                aStates.append([1, 0, 0])
            if( states in ["M", "M+", "M-"] ):
                aStates.append([0, 1, 0])
            if( states in ["R", "R+", "R-"] ):
                aStates.append([0, 0, 1])
            if( states in ["F+", "M+"] ):
                aStates.append([1, 1, 0])
            if( states in ["R+", "M+"] ):
                aStates.append([0, 1, 1])
            if( states in ["F+", "R+"] ):
                aStates.append([1, 0, 1])
        elif( self.isArray(states) ):
            if( self.isArray(states[0]) ):
                aStates = states
            elif( int(states[0]) == states[0] ):
                aStates = [states]
            else:
                raise Exception( "Error in sequences states description syntax: description expected in " + str(["*", "0+", "0", "0-", "1+", "1", "1-", "2+", "2", "2-", "3+", "3", "3-", "F+", "F", "F-", "M+", "M", "M-", "R+", "R", "R-"]) + " but " + str(p) + " found with this type: " + str(type(p)) )
        else:
            raise Exception( "Error in sequences states description syntax:\nstring, array or int expected but " + str(type(p)) + " found" )
        return aStates

    def checkIfSeqsCorrespondingLeft(self, param):
        "If the sequence handler is done (there is no sequence detected left or the first in the list corresponds), then reinitialize the sequence handler, and give the corresponding sequence if there is one."
        if( self.aDetectedSeqs == [] ):
            # then no sequence corresponding in the list
            self.initSeqDetected()
        else:
            if( self.aDetectedSeqs[0]["index"] == -1 ): # if first sequence in left ones corresponds
                # then it is this sequence which is played
                thread.start_new_thread( self.onAlternativeModalityAction, (self.aDetectedSeqs[0]["name"],) )
                self.initSeqDetected()
        self.mutexCheckIfSeqsCorrespondingLeft.unlock()

    def loopCheckTimeoutMax(self, nTimeoutMax, seq, currentState, currentTime):
        "When timeout ellapsed, check the sequence status and process it."
        nPreviousIndex = seq["index"]
        time.sleep(nTimeoutMax + 0.1)
        aSeqsTemp = []
        aSeqsTemp.extend( self.aDetectedSeqs )
        currentState = [self.nFront, self.nMiddle, self.nRear]
        currentTime = time.time()
        if( nPreviousIndex == seq["index"] and not self.mutexProcessCurrentState.test() and not (1 in currentState) ): # if no change in the sequence step but timeout ellapsed and sequence handler is not processing (so if there is no action from the user and the sequence is still at the same point)
            if( seq in aSeqsTemp and seq["index"] != -1 ): # but if sequence is still in the possible ones and not completed
                if( currentState in seq["statesAndTimeout"][seq["index"]] ): # last check if the current state corresponds to the next one
                    # then we go to the next step
                    seq["previousStepTime"] = currentTime
                    seq["index"] += 2
                    if( seq["index"] > len( seq["statesAndTimeout"] ) ): # if there is no more step
                        seq["index"] = -1 # then the sequence is completed
                    else: # if there is at least one step left
                        nTimeoutMin = 0
                        nTimeoutMax = 5
                        if( self.isArray(seq["statesAndTimeout"][seq["index"]-1]) ):
                            if( seq["statesAndTimeout"][seq["index"]-1][0] < 0 ):
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][0]
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][1]
                            else:
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][0]
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][1]
                        else:
                            if( seq["statesAndTimeout"][seq["index"]-1] < 0 ):
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1]
                            else:
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1]
                        thread.start_new_thread( self.loopCheckTimeoutMax, (nTimeoutMax, seq, currentState, currentTime) )
                else:
                    # then remove the sequence from the possible ones
                    aSeqsTemp.remove(seq)
                    self.aDetectedSeqs = aSeqsTemp
                self.mutexCheckIfSeqsCorrespondingLeft.lock( self.checkIfSeqsCorrespondingLeft, None )

    def loopCheckTimeoutMin(self, nTimeoutMin, seq):
        "Wait that the minimum timeout ellapse to check if the new tactile sensor state corresponds to the expected one for this sequence."
        if( nTimeoutMin != 0 ):
            nPreviousIndex = seq["index"]
            time.sleep(nTimeoutMin - time.time() + seq["previousStepTime"])
            currentTime = time.time()
            currentState = [self.nFront, self.nMiddle, self.nRear]
            self.mutexProcessCurrentState.lock( self.processCurrentState, [0, currentState, currentTime] )

    def updateDetectedSeqs(self, seq, aSeqsTemp, currentState, currentTime):
        "Update a detected sequence."
        if( seq["index"] > 0 ): # if not the first step
            nTimeoutMin = 0
            nTimeoutMax = 5
            if( self.isArray(seq["statesAndTimeout"][seq["index"]-1]) ):
                if( seq["statesAndTimeout"][seq["index"]-1][0] < 0 ):
                    nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][0]
                    nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][1]
                else:
                    nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][0]
                    nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][1]
            else:
                if( seq["statesAndTimeout"][seq["index"]-1] < 0 ):
                    nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1]
                else:
                    nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1]
            if( currentTime > nTimeoutMax + seq["previousStepTime"] ): # if timeout of this step ellapsed
                aSeqsTemp.remove(seq) # then it is not this sequence which is played
            elif( not (currentState in seq["statesAndTimeout"][seq["index"]]) ): # if the current state does not correspond to one of the described ones but the timeout of this step did not ellaspe
                # then we check that this state could be an intermediate one
                aIntermediateStates = [[], [], []]
                for i in range( len( currentState ) ):
                    for j in range( len( seq["statesAndTimeout"][seq["index"]] ) ):
                        aIntermediateStates[i].append( seq["statesAndTimeout"][seq["index"]][j][i] )
                    for j in range( len( seq["statesAndTimeout"][seq["index"]-2] ) ):
                        aIntermediateStates[i].append( seq["statesAndTimeout"][seq["index"]-2][j][i] )
                bIsIntermediate = True
                for i in range( len( currentState ) ):
                    bIsIntermediate = bIsIntermediate and ( currentState[i] in aIntermediateStates[i] )
                if( not bIsIntermediate ):
                    aSeqsTemp.remove(seq) # then it is not this sequence which is played
            else: # if the current state correspond to one of the described ones
                if( currentTime > nTimeoutMin + seq["previousStepTime"] ): # if the minimum time to wait the next step is ellapsed
                    # then we go to the next step
                    seq["previousStepTime"] = currentTime
                    seq["index"] += 2
                    if( seq["index"] > len( seq["statesAndTimeout"] ) ): # if there is no more step
                        seq["index"] = -1 # then the sequence is completed
                    else: # if there is at least one step left
                        # start clock to timeout
                        nTimeoutMin = 0
                        nTimeoutMax = 5
                        if( self.isArray(seq["statesAndTimeout"][seq["index"]-1]) ):
                            if( seq["statesAndTimeout"][seq["index"]-1][0] < 0 ):
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][0]
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][1]
                            else:
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][0]
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][1]
                        else:
                            if( seq["statesAndTimeout"][seq["index"]-1] < 0 ):
                                nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1]
                            else:
                                nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1]
                        thread.start_new_thread( self.loopCheckTimeoutMin, (nTimeoutMin, seq) )
                        thread.start_new_thread( self.loopCheckTimeoutMax, (nTimeoutMax, seq, currentState, currentTime) )
                else: # if the minimum time to wait the next step is not ellapsed
                    # then we are going to wait until it is to check then
                    thread.start_new_thread( self.loopCheckTimeoutMin, (nTimeoutMin, seq) )
        elif( seq["index"] == 0 ): # for the first step
            if( currentState in seq["statesAndTimeout"][seq["index"]] ): # if the current state correspond to one of the described ones
                # then we go to the next step
                seq["previousStepTime"] = currentTime
                seq["index"] += 2
                if( seq["index"] > len( seq["statesAndTimeout"] ) ): # if there is no more step
                    seq["index"] = -1 # then the sequence is completed
                else: # if there is at least one step left
                    # start clock to timeout
                    nTimeoutMin = 0
                    nTimeoutMax = 5
                    if( self.isArray(seq["statesAndTimeout"][seq["index"]-1]) ):
                        if( seq["statesAndTimeout"][seq["index"]-1][0] < 0 ):
                            nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][0]
                            nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][1]
                        else:
                            nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1][0]
                            nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1][1]
                    else:
                        if( seq["statesAndTimeout"][seq["index"]-1] < 0 ):
                            nTimeoutMin = - seq["statesAndTimeout"][seq["index"]-1]
                        else:
                            nTimeoutMax = seq["statesAndTimeout"][seq["index"]-1]
                    thread.start_new_thread( self.loopCheckTimeoutMin, (nTimeoutMin, seq) )
                    thread.start_new_thread( self.loopCheckTimeoutMax, (nTimeoutMax, seq, currentState, currentTime) )
            else: # if the current state does not correspond to the first described
                aSeqsTemp.remove(seq) # then it is not this sequence which has just been started

    def updateSeqsHandler(self, currentState, currentTime):
        "Update list of detected sequences."
        aSeqsTemp = []
        aSeqsTemp.extend( self.aDetectedSeqs )
        for seq in self.aDetectedSeqs:
            self.updateDetectedSeqs( seq, aSeqsTemp, currentState, currentTime )
        self.aDetectedSeqs = aSeqsTemp
        self.mutexCheckIfSeqsCorrespondingLeft.lock( self.checkIfSeqsCorrespondingLeft, None )

    def processCurrentState(self, param):
        "Process the current tactile sensor state."
        pValue = param[0]
        currentState = param[1]
        currentTime = param[2]
        if( pValue == 1 and not self.bSeqStarted ):
            self.bSeqStarted = True
            for seq in self.aDetectedSeqs:
                seq["previousStepTime"] = currentTime
        # update sequences handler
        if( self.bSeqStarted ):
            self.updateSeqsHandler(currentState, currentTime)
        self.mutexProcessCurrentState.unlock()

    def onFrontTactilTouched(self, param):
        "Handle an action (touch or release) on the front tactile sensor."
        self.logger.debug( "Change detected on the front tactile sensor: " + str(param[0]) )
        pValue = param[0]
        currentTime = param[1]
        currentState = [pValue, self.nMiddle, self.nRear]
        self.nFront = pValue
        self.mutexProcessCurrentState.lock( self.processCurrentState, [pValue, currentState, currentTime] )
        self.mutexTactilTouched.unlock()

    def onMiddleTactilTouched(self, param):
        "Handle an action (touch or release) on the middle tactile sensor."
        self.logger.debug( "Change detected on the middle tactile sensor: " + str(param[0]) )
        pValue = param[0]
        currentTime = param[1]
        currentState = [self.nFront, pValue, self.nRear]
        self.nMiddle = pValue
        self.mutexProcessCurrentState.lock( self.processCurrentState, [pValue, currentState, currentTime] )
        self.mutexTactilTouched.unlock()

    def onRearTactilTouched(self, param):
        "Handle an action (touch or release) on the rear tactile sensor."
        self.logger.debug( "Change detected on the rear tactile sensor: " + str(param[0]) )
        pValue = param[0]
        currentTime = param[1]
        currentState = [self.nFront, self.nMiddle, pValue]
        self.nRear = pValue
        self.mutexProcessCurrentState.lock( self.processCurrentState, [pValue, currentState, currentTime] )
        self.mutexTactilTouched.unlock()

    def onTactilTouched(self, pDataName, pValue, pMessage):
        "Handle an action (touch or release) on the tactile sensor."
        self.mutexTactilTouched.lock( getattr( self, "on" + pDataName ), [pValue, time.time()] )

# OUTPUTS ACTIVATION --------------------------------------------------------------------------------------

    def goOut(self, outputName, cancelReason = ""):
        "Activate the right output (a choice output or the other output)."
        try:
            self.memory.unsubscribeToEvent( "FrontTactilTouched", self.getName() )
            self.memory.unsubscribeToEvent( "MiddleTactilTouched", self.getName() )
            self.memory.unsubscribeToEvent( "RearTactilTouched", self.getName() )
        except:
            pass

        self.bGoOut = True
        self.bInTactileSensorMenu = False
        if( outputName in self.asExitWords ):
            try:
                self.other( cancelReason )
                self.logger.debug( "Output 'other' stimulated because cancel asked: " + str(cancelReason) + "." )
            except:
                try:
                    self.onStopped( cancelReason )
                    self.logger.debug( "Output 'onStopped' stimulated because cancel asked: " + str(cancelReason) + "." )
                except:
                    try:
                        self.onStopped()
                        self.logger.debug( "Output 'onStopped' stimulated because cancel asked." )
                    except:
                        choregraphe = ALProxy( "ALChoregraphe" )
                        choregraphe.onPythonError( self.getName(), "goOut", "Invalid output: the main output name needs to be 'other', and it needs to be dynamic (because it can be either a string, or an integer)." )
        else:
            nOutput = -1
            for i in range( len (self.aChoices) - len (self.aDefaultChoices) ):
                if( nOutput == -1 ):
                    if( outputName in self.aChoices[i+len( self.aDefaultChoices )] ):
                        nOutput = i
            if( nOutput != -1):
                if( self.bExternChoices ):
                    if( self.bRepeatValidatedChoice ):
                        self.skipTTS()
                        self.tts.say( outputName )
                        self.logger.debug( "Robot says: " + str(outputName) )
                    try:
                        self.other( self.aChoiceIndexes[nOutput] )
                        self.logger.debug( "Output 'other' stimulated with: " + str(self.aChoiceIndexes[nOutput]) + " (corresponding to the choice '" + str(self.aChoices[nOutput+len( self.aDefaultChoices )][0]) + "')." )
                    except:
                        try:
                            self.onStopped( self.aChoiceIndexes[nOutput] )
                            self.logger.debug( "Output 'onStopped' stimulated with: " + str(self.aChoiceIndexes[nOutput]) + " (corresponding to the choice '" + str(self.aChoices[nOutput+len( self.aDefaultChoices )][0]) + "')." )
                        except:
                            choregraphe = ALProxy( "ALChoregraphe" )
                            choregraphe.onPythonError( self.getName(), "goOut", "Invalid type of output: using the input 'choicesList', the main output needs to be dynamic (because it can be either a string, or an integer)." )
                else:
                    if( self.bRepeatValidatedChoice ):
                        self.skipTTS()
                        self.tts.say( outputName )
                        self.logger.debug( "Robot says: " + str(outputName) )
                    try:
                        func = getattr( self, "output_" + str(self.aChoiceIndexes[nOutput]+1) ) #+1 because the first one is output_1 corresponding to the element 0 in the list.
                        func(outputName)
                        self.logger.debug( "Output 'output_" + str(self.aChoiceIndexes[nOutput]+1) + "' stimulated with: " + str(outputName) + "." )
                    except:
                        choregraphe = ALProxy( "ALChoregraphe" )
                        choregraphe.onPythonError( self.getName(), "goOut", "Invalid output: the output 'output_" + str(self.aChoiceIndexes[nOutput]+1) + "' was expected to be stimulated with: " + str(outputName) + " but could not." )
        self.onUnload()
        # come back to an initial position and stop movement animation
        if( self.nFrameNumber != self.aFrameNumbers["end"] ):
            self.nFrameNumber = self.aFrameNumbers["end"]
            try:
                self.getTimeline().goTo(self.nFrameNumber)
            except: # if NAOqi < 1.14
                try:
                    self.gotoAndStop(self.nFrameNumber)
                except:
                    pass

# UNLOAD --------------------------------------------------------------------------------------------------

    def goOutOfQuestionRecoReaction(self):
        "Set some variables to go out of the question-recognition-reaction loop and reinitialize other variables which are going to be used again only on the next start of this box."
        self.bGoOut = True
        self.bMustStop = True
        self.nCountFailure = 0
        self.nCountNoReply = 0
        self.bInConfirmation = False
        self.bVocabularyLoaded = False
        self.skipTTS()
        for idTTS in self.aIdsTTS:
            try:
                self.aIdsTTS.remove( idTTS )
            except:
                self.logger.debug( "Warning: The task ID corresponding to the Text-To-Speech could not have been removed from the ID tasks list." )
        try:
            self.memory.unsubscribeToEvent( "WordRecognized", self.getName() )
            self.bRecoIsWaitingForVoice = False
            self.bRecoIsHearingOrAnalysing = False
            self.logger.debug( "Speech recognition stopped." )
            self.memory.unsubscribeToEvent( "SpeechDetected", self.getName() )
        except:
            pass

    def onUnload(self):
        "Reinitialize variables to default state."
        self.goOutOfQuestionRecoReaction()
        self.bExternChoices = False
        self.bInTactileSensorMenu = False
        try:
            self.memory.unsubscribeToEvent( "FrontTactilTouched", self.getName() )
            self.memory.unsubscribeToEvent( "MiddleTactilTouched", self.getName() )
            self.memory.unsubscribeToEvent( "RearTactilTouched", self.getName() )
        except:
            pass
        self.bIsRunning = False]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <keyword>نعم</keyword>
                                                        <keyword>لا</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </arabic>
                                                    <brazilian>
                                                        <keyword>sim</keyword>
                                                        <keyword>não</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </brazilian>
                                                    <chinese>
                                                        <keyword>是</keyword>
                                                        <keyword>不是</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </chinese>
                                                    <czech>
                                                        <keyword>ano</keyword>
                                                        <keyword>ne</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </czech>
                                                    <danish>
                                                        <keyword>ja</keyword>
                                                        <keyword>nej</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </danish>
                                                    <dutch>
                                                        <keyword>ja</keyword>
                                                        <keyword>nee</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </dutch>
                                                    <english>
                                                        <keyword></keyword>
                                                        <keyword>Na</keyword>
                                                        <keyword>Le</keyword>
                                                        <keyword></keyword>
                                                    </english>
                                                    <finnish>
                                                        <keyword>kyllä</keyword>
                                                        <keyword>ei</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </finnish>
                                                    <french>
                                                        <keyword>oui</keyword>
                                                        <keyword>non</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </french>
                                                    <german>
                                                        <keyword>ja</keyword>
                                                        <keyword>nein</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </german>
                                                    <greek>
                                                        <keyword>ναί</keyword>
                                                        <keyword>κανένα</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </greek>
                                                    <italian>
                                                        <keyword>sì</keyword>
                                                        <keyword>no</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </italian>
                                                    <japanese>
                                                        <keyword>はい</keyword>
                                                        <keyword>いいえ</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </japanese>
                                                    <korean>
                                                        <keyword>예</keyword>
                                                        <keyword>아니</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </korean>
                                                    <norwegian>
                                                        <keyword>ja</keyword>
                                                        <keyword>Nei</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </norwegian>
                                                    <polish>
                                                        <keyword>tak</keyword>
                                                        <keyword>nie</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </polish>
                                                    <portuguese>
                                                        <keyword>sim</keyword>
                                                        <keyword>não</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </portuguese>
                                                    <russian>
                                                        <keyword>да</keyword>
                                                        <keyword>нет</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </russian>
                                                    <spanish>
                                                        <keyword>si</keyword>
                                                        <keyword>no</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </spanish>
                                                    <swedish>
                                                        <keyword>ja</keyword>
                                                        <keyword>ingen</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </swedish>
                                                    <turkish>
                                                        <keyword>evet</keyword>
                                                        <keyword>hayır</keyword>
                                                        <keyword></keyword>
                                                        <keyword></keyword>
                                                    </turkish>
                                                    <language>english</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="0" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is&#x0A;received on this input. The signal can be&#x0A;either a string so that the robot asks a&#x0A;question before the recognition of a&#x0A;choice, or a bang so that the speech&#x0A;recognition starts immediately without any&#x0A;question." id="2" />
                                                <Input name="choicesList" type="0" type_size="1" nature="1" inner="0" tooltip="To have extern choices list (for example,&#x0A;depending on extern variables).&#x0A;!! Warning !! : Must be set before each&#x0A;time the box is started (with onStart&#x0A;input). Otherwise, the choices displayed&#x0A;on the box will be selected." id="3" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip='Box behavior stops when a signal is&#x0A;received on this input, the &apos;other&apos; output is&#x0A;stimulated by &quot;onStop&quot;.' id="4" />
                                                <Output name="other" type="0" type_size="1" nature="1" inner="0" tooltip='When the user skipped the question, this output gives how it has been&#x0A;skipped. Gives also the number of the choice chosen in case of external&#x0A;choices.&#x0A;This output can be:&#x0A;- &quot;timeout&quot; if the user has not replied.&#x0A;- &quot;notUnderstood&quot; if the interaction with the speech recognition failed.&#x0A;- &quot;onStop&quot; if the onStop input has been activated.&#x0A;- &quot;wordRecognised&quot; if the exit command has been understood.&#x0A;- &quot;onTactileSensor&quot; if the user has tapped the tactile sensor of the robot.&#x0A;- an integer being the number of the external choice in the input list.' id="5" />
                                                <Output name="output_1" type="0" type_size="1" nature="2" inner="0" tooltip="This IO has been automatically added by box. Read box tooltip for more information." id="6" />
                                                <Output name="output_2" type="0" type_size="1" nature="2" inner="0" tooltip="This IO has been automatically added by box. Read box tooltip for more information." id="7" />
                                                <Output name="output_3" type="0" type_size="1" nature="2" inner="0" tooltip="This IO has been automatically added by box. Read box tooltip for more information." id="8" />
                                                <Parameter name="Minimum threshold to understand" inherits_from_parent="0" content_type="2" value="0.2" default_value="0.2" min="0" max="1" tooltip="Minimum threshold to get in order to be understood by the robot." id="9" />
                                                <Parameter name="Minimum threshold to be sure" inherits_from_parent="0" content_type="2" value="0.3" default_value="0.3" min="0" max="1" tooltip="Minimum threshold to get so that the robot would be sure about the user&apos;s&#x0A;answer. Below this threshold, the robot asks a confirmation about what has been&#x0A;understood." id="10" />
                                                <Parameter name="Speech recognition timeout when confirmation" inherits_from_parent="0" content_type="1" value="6" default_value="6" min="1" max="20" tooltip="When the robot asks if what he understood is correct, after this time, if there has been&#x0A;nothing heard, the speech recognition is stopped and the answer understood is&#x0A;considered as correct." id="11" />
                                                <Parameter name="Speech recognition timeout" inherits_from_parent="0" content_type="1" value="6" default_value="6" min="1" max="20" tooltip="After this time, if there has been nothing heard, the speech recognition is stopped&#x0A;and the question is repeated or is skipped." id="12" />
                                                <Parameter name="Maximum number of repetition when no reply" inherits_from_parent="0" content_type="1" value="3" default_value="3" min="1" max="20" tooltip='After this number of times when the user did not reply, the question is skipped, and&#x0A;the output other is stimulated with &quot;timeout&quot;.' id="13" />
                                                <Parameter name="Repeat validated choice" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="If this option is activated, the robot repeats the validated choice when it exits the box." id="14" />
                                                <Parameter name="Activate ears light" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="Activate ears light animation (turn, flash, etc...)." id="15" />
                                                <Parameter name="Activate eyes light" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="Activate eyes light animation (turn, flash, etc...)." id="16" />
                                                <Parameter name="Activate brain light" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="Activate brain light animation (turn, flash, etc...)." id="17" />
                                                <Parameter name="Tactile sensor menu timeout" inherits_from_parent="0" content_type="1" value="10" default_value="10" min="1" max="20" tooltip="After this time, if there has been no action made on the tactile sensor or the torso&#x0A;button, the choice currently selected is repeated or the question is skipped." id="18" />
                                                <Parameter name="Maximum number of repetition when failure" inherits_from_parent="0" content_type="1" value="5" default_value="5" min="1" max="20" tooltip='After this number of times when the robot did not understand the user, the question&#x0A;is skipped, and the output other is stimulated with &quot;notUnderstood&quot;.' id="19" />
                                                <Parameter name="Activate help when failure" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="When this parameter is activated, when the robot did not understand the user, he&#x0A;says some help enumerating available choices and attracting attention on the&#x0A;other available modalities (head tactile sensor)." id="20" />
                                                <Parameter name="Activate help command" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip='Enable the help command. So you can say &quot;help&quot; during the speech recognition&#x0A;and the robot will tell you more information.&#x0A;You will still be able to ask help by clicking the torso button.' id="21" />
                                                <Parameter name="Activate repeat command" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip='Activate the repeat command. So you can say &quot;repeat&quot; during the speech&#x0A;recognition and the robot will repeat the question.' id="22" />
                                                <Parameter name="Activate exit command" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip='Enable the exit command. So you can say &quot;exit&quot; during the speech recognition&#x0A;and the box will be stopped and the &apos;other&apos; output will be stimulated with&#x0A;&quot;wordRecognised&quot;.&#x0A;You will still be able to exit the box with&#x0A;the tactile sensor.' id="23" />
                                                <Parameter name="Sentences file" inherits_from_parent="0" content_type="4" value="/Aldebaran/choice_sentences_light.xml" default_value="/Aldebaran/choice_sentences_light.xml" tooltip="File containing all necessary sentences in each supported language." id="24" />
                                            </Box>
                                            <Box name="Localized Text" id="5" localization="8" tooltip="Send on the output the text associated with the robot&apos;s current voice language.&#x0A;You can display and edit the text associated with any language by&#x0A;selecting the language in the combobox.&#x0A;&#x0A;!!Warning!! The text sent on the output is NOT the displayed one but the one&#x0A;associated with the robot&apos;s current voice language." plugin="localizationbox_plugin" x="59" y="54">
                                                <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		try: # disable autoBind
			GeneratedClass.__init__(self, False)
		except TypeError: # if NAOqi < 1.14
			GeneratedClass.__init__( self )

		self.tts = ALProxy("ALTextToSpeech")
		self.sentences = {
			"Arabic" : "  ",
			"Czech" : " Máš rád čokoládu? ",
			"Danish" : " Kan du lide chokolade? ",
			"German" : " Mögen Sie Schokolade? ",
			"Greek" : "  ",
			"English" : " Hoffech chi drefnu apwyntiad ",
			"Spanish" : " ¿Te gusta el chocolate? ",
			"Finnish" : " Pidätkö suklaasta? ",
			"French" : " Aimes-tu le chocolat ? ",
			"Italian" : " Ti piace il cioccolato? ",
			"Japanese" : " チョコレートが好きですか ",
			"Korean" : " 당신은 초콜렛을 좋아합니까? ",
			"Dutch" : " Hou je van chocolade? ",
			"Norwegian" : "  ",
			"Polish" : " Lubisz czekoladę? ",
			"Brazilian" : " Você gosta de chocolate? ",
			"Portuguese" : " Gostas de chocolate? ",
			"Russian" : " Вы любите шоколад? ",
			"Swedish" : " Gillar du choklad? ",
			"Turkish" : " Çikolata sever misin? ",
			"Chinese" : "  "
		}

	def onInput_onStart(self):
		sDefaultLang = self.tts.getLanguage()
		self.onStopped(self.sentences[sDefaultLang])]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <![CDATA[]]>
</arabic>
                                                    <czech>
                                                        <![CDATA[Máš rád čokoládu?]]>
</czech>
                                                    <danish>
                                                        <![CDATA[Kan du lide chokolade?]]>
</danish>
                                                    <german>
                                                        <![CDATA[Mögen Sie Schokolade?]]>
</german>
                                                    <greek>
                                                        <![CDATA[]]>
</greek>
                                                    <english>
                                                        <![CDATA[Hoffech chi drefnu apwyntiad]]>
</english>
                                                    <spanish>
                                                        <![CDATA[¿Te gusta el chocolate?]]>
</spanish>
                                                    <finnish>
                                                        <![CDATA[Pidätkö suklaasta?]]>
</finnish>
                                                    <french>
                                                        <![CDATA[Aimes-tu le chocolat ?]]>
</french>
                                                    <italian>
                                                        <![CDATA[Ti piace il cioccolato?]]>
</italian>
                                                    <japanese>
                                                        <![CDATA[チョコレートが好きですか]]>
</japanese>
                                                    <korean>
                                                        <![CDATA[당신은 초콜렛을 좋아합니까?]]>
</korean>
                                                    <dutch>
                                                        <![CDATA[Hou je van chocolade?]]>
</dutch>
                                                    <norwegian>
                                                        <![CDATA[]]>
</norwegian>
                                                    <polish>
                                                        <![CDATA[Lubisz czekoladę?]]>
</polish>
                                                    <brazilian>
                                                        <![CDATA[Você gosta de chocolate?]]>
</brazilian>
                                                    <portuguese>
                                                        <![CDATA[Gostas de chocolate?]]>
</portuguese>
                                                    <russian>
                                                        <![CDATA[Вы любите шоколад?]]>
</russian>
                                                    <swedish>
                                                        <![CDATA[Gillar du choklad?]]>
</swedish>
                                                    <turkish>
                                                        <![CDATA[Çikolata sever misin?]]>
</turkish>
                                                    <chinese>
                                                        <![CDATA[]]>
</chinese>
                                                    <language>5</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Data is sent on the output when this input is stimulated." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Data sent when asked." id="3" />
                                            </Box>
                                            <Link inputowner="1" indexofinput="2" outputowner="5" indexofoutput="3" />
                                            <Link inputowner="5" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="0" indexofinput="4" outputowner="1" indexofoutput="5" />
                                            <Link inputowner="0" indexofinput="5" outputowner="1" indexofoutput="6" />
                                            <Link inputowner="0" indexofinput="5" outputowner="1" indexofoutput="7" />
                                            <Link inputowner="0" indexofinput="6" outputowner="1" indexofoutput="8" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Speech" type="Lock" timeout="0" />
                            <Resource name="Speech recognition" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Move Along" id="10" localization="8" tooltip="Move along a trajectory given by an attached .pmt file.&#x0A;&#x0A;V1.0.0&#x0A;" x="109" y="1389">
                            <bitmap>media/images/box/movement/walk_forward.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.motion = ALProxy("ALMotion")
        self.navigation = ALProxy("ALNavigation")

    def onLoad(self):
        pass

    def onUnload(self):
        self.motion.move(0., 0., 0.)

    def onInput_onStart(self):
        relativePath = self.getParameter("Planar Move Trajectory")
        if len(relativePath) == 0:
            self.failure()
            return

        fm = ALProxy("ALFrameManager")
        behaviorPath = fm.getBehaviorPath(self.behaviorId)
        trajectoryPath = behaviorPath + relativePath

        trajectoryData = str()
        with open(trajectoryPath, 'r') as trajectoryFile:
            trajectoryData = trajectoryFile.read()
        trajectory = eval(trajectoryData)

        if trajectory[0] != "Composed": # dealing with trajectories with radius
            trajectory = trajectory[0]

        result = self.navigation.moveAlong(trajectory)
        if (result):
            self.success()
        else:
            self.failure()

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Output name="success" type="1" type_size="1" nature="1" inner="0" tooltip="Stimulated if the trajectory was correctly executed." id="4" />
                            <Output name="failure" type="1" type_size="1" nature="1" inner="0" tooltip="Stimulated if the trajectory was stopped to avoid collisions." id="5" />
                            <Parameter name="Planar Move Trajectory" inherits_from_parent="0" content_type="4" value="" default_value="" tooltip="" id="6" />
                        </Box>
                        <Box name="Follow Nao to appointment  (2)" id="11" localization="8" tooltip="Nao asks user to follow them to appointment " x="232" y="1564">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="0" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed.&#x0A;&#x0A;!Warning! This feature is not available yet in Japanese, Chinese and Korean." id="6" />
                            <Parameter name="Body language mode" inherits_from_parent="0" content_type="3" value="contextual" default_value="contextual" custom_choice="0" tooltip="Change the body language mode during the speech.&#x0A;disabled: The robot will only play the animations given by the user. ex: ^start(...) or ^tag(...)&#x0A;random: During time the robot has no animation to play, he will launch random neutral animations.&#x0A;contextual: During time the robot has no animation to play, he will try to launch a new one accordingly to the saying text. Every time the robot can&apos;t find a contextual animation he will launch a random neutral animation." id="7">
                                <Choice value="disabled" />
                                <Choice value="random" />
                                <Choice value="contextual" />
                            </Parameter>
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Animated Say Text" id="2" localization="8" tooltip="Say the text received on its input and move during its speech." x="422" y="93">
                                                <bitmap>media/images/box/interaction/say.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.animSpeech = ALProxy('ALAnimatedSpeech')

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.animSpeech.stop(id)
            except:
                pass

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            configuration =\
            {"bodyLanguageMode":self.getParameter("Body language mode")}
            id = self.animSpeech.post.say(str(sentence), configuration)
            self.ids.append(id)
            self.animSpeech.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                                                <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                                                <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                                                <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                                                <Parameter name="Body language mode" inherits_from_parent="1" content_type="3" value="contextual" default_value="contextual" custom_choice="0" tooltip="Change the body language mode during the speech.&#x0A;disabled: The robot will only play the animations given by the user. ex: ^start(...) or ^tag(...)&#x0A;random: During time the robot has no animation to play, he will launch random neutral animations.&#x0A;contextual: During time the robot has no animation to play, he will try to launch a new one accordingly to the saying text. Every time the robot can&apos;t find a contextual animation he will launch a random neutral animation." id="7">
                                                    <Choice value="disabled" />
                                                    <Choice value="random" />
                                                    <Choice value="contextual" />
                                                </Parameter>
                                            </Box>
                                            <Box name="Localized Text" id="5" localization="8" tooltip="Send on the output the text associated with the robot&apos;s current voice language.&#x0A;You can display and edit the text associated with any language by&#x0A;selecting the language in the combobox.&#x0A;&#x0A;!!Warning!! The text sent on the output is NOT the displayed one but the one&#x0A;associated with the robot&apos;s current voice language." plugin="localizationbox_plugin" x="133" y="105">
                                                <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		try: # disable autoBind
			GeneratedClass.__init__(self, False)
		except TypeError: # if NAOqi < 1.14
			GeneratedClass.__init__( self )

		self.tts = ALProxy("ALTextToSpeech")
		self.sentences = {
			"Arabic" : "  ",
			"Czech" : " ^start(animations/Stand/Gestures/Hey_1) Ahoj ^wait(animations/Stand/Gestures/Hey_1) ",
			"Danish" : " ^start(animations/Stand/Gestures/Hey_1) Hej ^wait(animations/Stand/Gestures/Hey_1) ",
			"German" : " ^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1) ",
			"Greek" : "  ",
			"English" : " Enjoy your time  ",
			"Spanish" : " ^start(animations/Stand/Gestures/Hey_1) Hola ^wait(animations/Stand/Gestures/Hey_1) ",
			"Finnish" : " ^start(animations/Stand/Gestures/Hey_1) Hei ^wait(animations/Stand/Gestures/Hey_1) ",
			"French" : " ^start(animations/Stand/Gestures/Hey_1) Bonjour ^wait(animations/Stand/Gestures/Hey_1) ",
			"Italian" : " ^start(animations/Stand/Gestures/Hey_1) Ciao ^wait(animations/Stand/Gestures/Hey_1) ",
			"Japanese" : " ^start(animations/Stand/Gestures/Hey_1) こんにちは ^wait(animations/Stand/Gestures/Hey_1) ",
			"Korean" : " ^start(animations/Stand/Gestures/Hey_1) 안녕하세요 ^wait(animations/Stand/Gestures/Hey_1) ",
			"Dutch" : " ^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1) ",
			"Norwegian" : "  ",
			"Polish" : " ^start(animations/Stand/Gestures/Hey_1) Cześć ^wait(animations/Stand/Gestures/Hey_1) ",
			"Brazilian" : " ^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1) ",
			"Portuguese" : " ^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1) ",
			"Russian" : " ^start(animations/Stand/Gestures/Hey_1) Привет ^wait(animations/Stand/Gestures/Hey_1) ",
			"Swedish" : " ^start(animations/Stand/Gestures/Hey_1) Hallå ^wait(animations/Stand/Gestures/Hey_1) ",
			"Turkish" : " ^start(animations/Stand/Gestures/Hey_1) Merhaba ^wait(animations/Stand/Gestures/Hey_1) ",
			"Chinese" : "  "
		}

	def onInput_onStart(self):
		sDefaultLang = self.tts.getLanguage()
		self.onStopped(self.sentences[sDefaultLang])]]>
</content>
                                                </script>
                                                <pluginContent>
                                                    <arabic>
                                                        <![CDATA[]]>
</arabic>
                                                    <czech>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Ahoj ^wait(animations/Stand/Gestures/Hey_1)]]>
</czech>
                                                    <danish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hej ^wait(animations/Stand/Gestures/Hey_1)]]>
</danish>
                                                    <german>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1)]]>
</german>
                                                    <greek>
                                                        <![CDATA[]]>
</greek>
                                                    <english>
                                                        <![CDATA[Enjoy your time ]]>
</english>
                                                    <spanish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hola ^wait(animations/Stand/Gestures/Hey_1)]]>
</spanish>
                                                    <finnish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hei ^wait(animations/Stand/Gestures/Hey_1)]]>
</finnish>
                                                    <french>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Bonjour ^wait(animations/Stand/Gestures/Hey_1)]]>
</french>
                                                    <italian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Ciao ^wait(animations/Stand/Gestures/Hey_1)]]>
</italian>
                                                    <japanese>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) こんにちは ^wait(animations/Stand/Gestures/Hey_1)]]>
</japanese>
                                                    <korean>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) 안녕하세요 ^wait(animations/Stand/Gestures/Hey_1)]]>
</korean>
                                                    <dutch>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallo ^wait(animations/Stand/Gestures/Hey_1)]]>
</dutch>
                                                    <norwegian>
                                                        <![CDATA[]]>
</norwegian>
                                                    <polish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Cześć ^wait(animations/Stand/Gestures/Hey_1)]]>
</polish>
                                                    <brazilian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1)]]>
</brazilian>
                                                    <portuguese>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Olá ^wait(animations/Stand/Gestures/Hey_1)]]>
</portuguese>
                                                    <russian>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Привет ^wait(animations/Stand/Gestures/Hey_1)]]>
</russian>
                                                    <swedish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Hallå ^wait(animations/Stand/Gestures/Hey_1)]]>
</swedish>
                                                    <turkish>
                                                        <![CDATA[^start(animations/Stand/Gestures/Hey_1) Merhaba ^wait(animations/Stand/Gestures/Hey_1)]]>
</turkish>
                                                    <chinese>
                                                        <![CDATA[]]>
</chinese>
                                                    <language>5</language>
                                                </pluginContent>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Data is sent on the output when this input is stimulated." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Data sent when asked." id="3" />
                                            </Box>
                                            <Link inputowner="0" indexofinput="4" outputowner="2" indexofoutput="4" />
                                            <Link inputowner="5" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="2" indexofinput="2" outputowner="5" indexofoutput="3" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Link inputowner="3" indexofinput="2" outputowner="2" indexofoutput="4" />
                        <Link inputowner="5" indexofinput="2" outputowner="3" indexofoutput="4" />
                        <Link inputowner="13" indexofinput="2" outputowner="12" indexofoutput="4" />
                        <Link inputowner="19" indexofinput="2" outputowner="2" indexofoutput="4" />
                        <Link inputowner="23" indexofinput="2" outputowner="22" indexofoutput="4" />
                        <Link inputowner="24" indexofinput="2" outputowner="23" indexofoutput="4" />
                        <Link inputowner="25" indexofinput="2" outputowner="0" indexofoutput="2" />
                        <Link inputowner="33" indexofinput="2" outputowner="32" indexofoutput="4" />
                        <Link inputowner="34" indexofinput="2" outputowner="33" indexofoutput="4" />
                        <Link inputowner="35" indexofinput="2" outputowner="34" indexofoutput="4" />
                        <Link inputowner="35" indexofinput="2" outputowner="34" indexofoutput="3" />
                        <Link inputowner="36" indexofinput="2" outputowner="32" indexofoutput="4" />
                        <Link inputowner="36" indexofinput="2" outputowner="33" indexofoutput="4" />
                        <Link inputowner="6" indexofinput="2" outputowner="25" indexofoutput="4" />
                        <Link inputowner="37" indexofinput="2" outputowner="26" indexofoutput="4" />
                        <Link inputowner="6" indexofinput="2" outputowner="25" indexofoutput="3" />
                        <Link inputowner="9" indexofinput="2" outputowner="6" indexofoutput="4" />
                        <Link inputowner="9" indexofinput="2" outputowner="6" indexofoutput="5" />
                        <Link inputowner="9" indexofinput="2" outputowner="6" indexofoutput="6" />
                        <Link inputowner="2" indexofinput="2" outputowner="9" indexofoutput="4" />
                        <Link inputowner="12" indexofinput="2" outputowner="8" indexofoutput="8" />
                        <Link inputowner="31" indexofinput="2" outputowner="30" indexofoutput="5" />
                        <Link inputowner="30" indexofinput="2" outputowner="1" indexofoutput="5" />
                        <Link inputowner="32" indexofinput="2" outputowner="30" indexofoutput="6" />
                        <Link inputowner="1" indexofinput="2" outputowner="1" indexofoutput="4" />
                        <Link inputowner="22" indexofinput="2" outputowner="4" indexofoutput="5" />
                        <Link inputowner="26" indexofinput="2" outputowner="4" indexofoutput="6" />
                        <Link inputowner="4" indexofinput="2" outputowner="1" indexofoutput="6" />
                        <Link inputowner="4" indexofinput="2" outputowner="4" indexofoutput="4" />
                        <Link inputowner="1" indexofinput="2" outputowner="12" indexofoutput="4" />
                        <Link inputowner="15" indexofinput="2" outputowner="14" indexofoutput="4" />
                        <Link inputowner="7" indexofinput="2" outputowner="16" indexofoutput="5" />
                        <Link inputowner="14" indexofinput="2" outputowner="16" indexofoutput="6" />
                        <Link inputowner="16" indexofinput="2" outputowner="16" indexofoutput="4" />
                        <Link inputowner="17" indexofinput="2" outputowner="17" indexofoutput="4" />
                        <Link inputowner="17" indexofinput="2" outputowner="57" indexofoutput="8" />
                        <Link inputowner="16" indexofinput="2" outputowner="17" indexofoutput="6" />
                        <Link inputowner="21" indexofinput="2" outputowner="20" indexofoutput="4" />
                        <Link inputowner="27" indexofinput="2" outputowner="21" indexofoutput="4" />
                        <Link inputowner="28" indexofinput="2" outputowner="27" indexofoutput="4" />
                        <Link inputowner="28" indexofinput="2" outputowner="27" indexofoutput="3" />
                        <Link inputowner="29" indexofinput="2" outputowner="20" indexofoutput="4" />
                        <Link inputowner="29" indexofinput="2" outputowner="21" indexofoutput="4" />
                        <Link inputowner="18" indexofinput="2" outputowner="38" indexofoutput="5" />
                        <Link inputowner="20" indexofinput="2" outputowner="38" indexofoutput="6" />
                        <Link inputowner="38" indexofinput="2" outputowner="17" indexofoutput="5" />
                        <Link inputowner="10" indexofinput="2" outputowner="7" indexofoutput="4" />
                        <Link inputowner="11" indexofinput="2" outputowner="10" indexofoutput="4" />
                        <Link inputowner="11" indexofinput="2" outputowner="10" indexofoutput="5" />
                        <Link inputowner="8" indexofinput="2" outputowner="5" indexofoutput="4" />
                        <Link inputowner="57" indexofinput="2" outputowner="5" indexofoutput="4" />
                    </Diagram>
                </BehaviorKeyframe>
            </BehaviorLayer>
        </Timeline>
    </Box>
</ChoregrapheProject>
